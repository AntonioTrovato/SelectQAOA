{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df92c7f16f61fcc",
   "metadata": {},
   "source": [
    "# SelectQAOA: Regression Test Case Selection Using QAOA\n",
    "Regression testing is an important part of the software development process in software engineering. It is a practice aimed at identifying any regression, which are the emergence of new defects or issues in a software application following changes, enhancements, or updates made to the source code. In other words, regression testing focuses on how changes made to the software can affect the correct behavior of existing features. Regression testing is particularly important in agile software development environments, where changes are made frequently and rapidly. This practice helps ensure that the software remains stable and reliable as it evolves over time. Ideal regression testing would re-run all the available test cases of a given software system. However, in addition to being potentially very costly, this could even be impractical in some case. In this scenario, test case selection is one of the most widely investigated test suite optimization approaches.\n",
    "Test case selection focuses on selecting a subset from an initial test suite to test software changes, i.e., to test whether unmodified parts of a program continue to work correctly after changes involving other parts. Various techniques, such as Integer Programming, symbolic execution, data flow analysis, dependence graph-based methods, and flow graph-based approaches, can be employed to identify the modified portions of the software. Once test cases covering the unchanged program segments are pinpointed using a specific technique, an optimization algorithm (e.g., additional greedy, DIV-GA,\n",
    "SelectQA, BootQA or SelectQAOA) can select a minimal set of these test cases based on certain testing criteria (e.g., branch coverage). The ultimate aim is to reduce the expenses associated with regression testing."
   ]
  },
  {
   "cell_type": "code",
   "id": "26cfee6323f1164",
   "metadata": {},
   "source": [
    "#this cell contains all the imports needed by the pipeline\n",
    "#to run it on the browser: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics\n",
    "import csv\n",
    "\n",
    "from scipy.stats import mannwhitneyu, shapiro\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.primitives import BackendSampler\n",
    "from qiskit_algorithms import QAOA\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_aer import Aer, AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "from qiskit_ibm_runtime.fake_provider import FakeVigoV2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cdist"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f36c35765771b1a0",
   "metadata": {},
   "source": [
    "## The pipeline dataset\n",
    "To experiment the performance of the proposed solution by this work and to compare its results to those of state-of-the-art solutions, 4 public programs have been downloaded from the SIR website. SIR is a repository of software-related artifacts meant to support rigorous controlled experimentation with program analysis and software testing techniques, and education in controlled experimentation. \n",
    "\n",
    "### Chosen SIR Programs\n",
    "The programs that will be used for experimentation have all been written in C and are:\n",
    "- flex (a program that generates a lexical analysis program, based on regular expressions and C statement contained in one or more input files);\n",
    "- grep (a useful program to search form matching patterns in a file);\n",
    "- gzip (a program that substitute a file, generally text files or web pages, with their compressed version)\n",
    "- sed (a powerful program for stream text editing).\n",
    "\n",
    "### Needed information\n",
    "The information needed by the quantum algorithm to work on every one of the 4 programs are:\n",
    "- a fault matrix: it indicates whether a precise test case already found, during previous execution, a bug in the source code or not;\n",
    "- execution cost: it indicates the execution cost of any test case of the suite;\n",
    "- statement coverage: it indicates statement coverage information for every test case. \n",
    "\n",
    "All this information have been gathered through previous experimentation on the four programs mentioned above and written in files organized in the SIR_Programs folder. So, the first goal of the project will be gathering data from these files for computational purposes."
   ]
  },
  {
   "cell_type": "code",
   "id": "7c35ee998a723ebe",
   "metadata": {},
   "source": [
    "#this cell contains all variable definitions that will be useful throughout the entire project\n",
    "sir_programs = [\"flex\",\"grep\",\"gzip\",\"sed\"]\n",
    "sir_programs_tests_number = {\"flex\":567,\"grep\":806,\"gzip\":214,\"sed\":360}\n",
    "sir_programs_end_lines = {\"flex\":14192,\"grep\":13281,\"gzip\":6701,\"sed\":7118}\n",
    "alpha = 0.5\n",
    "experiments = 30"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def json_keys_to_int(d):\n",
    "    if isinstance(d, dict):\n",
    "        return {int(k) if k.isdigit() else k: json_keys_to_int(v) for k, v in d.items()}\n",
    "    elif isinstance(d, list):\n",
    "        return [json_keys_to_int(i) for i in d]\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "\n",
    "with open(\"datasets/sir_programs/executed_lines_test_by_test.json\", \"r\") as file:\n",
    "    #dictionary that, for each sir program, associates at each LINE of that program the LIST of TESTS COVERING it\n",
    "    executed_lines_test_by_test = json_keys_to_int(json.load(file)) #{program1:{line:[tci,tcj,...,tck],line2:...}\n",
    "with open(\"datasets/sir_programs/faults_dictionary.json\", \"r\") as file:\n",
    "    #dictionary that associates at each SIR PROGRAM the LIST of PAST FAULT COVERAGE VALUES ORDERED BY TEST \n",
    "    faults_dictionary = json.load(file) #{program1:[fault_cov_tc1,fault_cov_tc2,...,fault_cov_tcn],program2:...}\n",
    "with open(\"datasets/sir_programs/test_coverage_line_by_line.json\", \"r\") as file:\n",
    "    #dictionary that, for each sir program, associates at each TEST of that program the LIST of LINES COVERED by it\n",
    "    test_coverage_line_by_line = json_keys_to_int(json.load(file)) #{program1:{tc1:[linei,linej,...,linek],tc2:...}\n",
    "with open(\"datasets/sir_programs/test_cases_costs.json\", \"r\") as file:\n",
    "    #dictionary that, for each sir program, associates at each TEST its EXECUTION COST\n",
    "    test_cases_costs = json_keys_to_int(json.load(file)) #{program1:{tc1:ex_cost1,tc2:ex_cost2,...,tcn:ex_costn},program2:...}\n",
    "with open(\"datasets/sir_programs/total_program_lines.json\", \"r\") as file:\n",
    "    #dictionary wich associates at each SIR PROGRAM its size in terms of NUMBER OF ITS LINES\n",
    "    total_program_lines = json.load(file) #{program1:tot_lines_program1,program2:tot_lines_program2,program3:...}"
   ],
   "id": "7ef8cfdb01630b6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ec65b50547d46586",
   "metadata": {},
   "source": [
    "## Quantum Approximate Optimization Algorithm (QAOA)\n",
    "The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm designed to tackle combinatorial optimization problems by combining classical and quantum computing techniques. It encodes the optimization problem into a Quantum Unconstrained Binary Optimization (QUBO) format and constructs a parameterized quantum circuit that alternates between applying the problem Hamiltonian, which represents the optimization goal, and a mixing Hamiltonian, which promotes exploration of the solution space. The parameters of this circuit are optimized using classical optimization methods to maximize the likelihood of measuring the optimal solution. Once the parameters are tuned, the circuit is executed on a quantum device or simulator to obtain candidate solutions, making QAOA particularly suitable for NP-hard problems like graph partitioning and maximum cut. This hybrid approach highlights the potential of quantum computing to provide advantages in solving complex optimization challenges.\n",
    "\n",
    "## QUBO Problems\n",
    "A Quadratic Unconstrained Binary Optimization (QUBO) problem is a type of mathematical problem where we seek to find the best combination of binary values (0 or 1) for a set of variables to minimize or maximize an objective function. In other words, we are looking for the optimal solution among all possible variable combinations that satisfies certain constraints and makes the objective function as small as possible.\n",
    "\n",
    "Weights for constraints (or penalty coefficients) are used in QUBO problems to assign a numerical value to the constraints and influence the optimization process. These weights are important because they allow for managing the priority and relative importance of constraints within the optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "id": "9224a4794535ffef",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def num_of_covered_lines(sir_program,test_cases):\n",
    "    covered_lines = set()\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        try:\n",
    "            for covered_line in test_coverage_line_by_line[sir_program][test_case]:\n",
    "                covered_lines.add(covered_line)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return len(covered_lines)\n",
    "\n",
    "clusters_dictionary = dict()\n",
    "\n",
    "for sir_program in sir_programs:\n",
    "    tot_test_cases = sir_programs_tests_number[sir_program]\n",
    "    \n",
    "    # from {..., test_case_i : [cov_stmts], ...} to [..., #_stmt_cov_i, ...]\n",
    "    test_cases_stmt_cov = []\n",
    "    for test_case in test_coverage_line_by_line[sir_program].keys():\n",
    "        test_cases_stmt_cov.append(len(test_coverage_line_by_line[sir_program][test_case]))\n",
    "    suite_stmt_cov = sum(test_cases_stmt_cov)\n",
    "    \n",
    "    # Normalize data\n",
    "    data = np.column_stack((list(test_cases_costs[sir_program].values()),faults_dictionary[sir_program],test_cases_stmt_cov))\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "    num_clusters = 0\n",
    "    \n",
    "    #ATTENTION: this number also depends on the QAOA simulator/machine you will use\n",
    "    if sir_program == \"flex\":\n",
    "        num_clusters = 55\n",
    "    elif sir_program == \"grep\":\n",
    "        num_clusters = 105\n",
    "    elif sir_program == \"gzip\":\n",
    "        num_clusters = 195\n",
    "    elif sir_program == \"sed\":\n",
    "        num_clusters = 195\n",
    "    \n",
    "    # Step 2: Perform K-Means Clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=43)\n",
    "    start = time.time()\n",
    "    clusters = kmeans.fit_predict(normalized_data)\n",
    "    \n",
    "    # Organize test cases by cluster\n",
    "    clustered_data = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        clustered_data[cluster_id].append(idx)\n",
    "        \n",
    "    # Step 4: Reassign points to ensure each cluster has at most 30 elements\n",
    "    max_elements_per_cluster = 30\n",
    "    for cluster_id, points in list(clustered_data.items()):\n",
    "        if len(points) > max_elements_per_cluster:\n",
    "            excess_points = points[max_elements_per_cluster:]\n",
    "            clustered_data[cluster_id] = points[:max_elements_per_cluster]\n",
    "            \n",
    "            # Reassign excess points\n",
    "            excess_data = normalized_data[excess_points]\n",
    "            remaining_clusters = [k for k in clustered_data if len(clustered_data[k]) < max_elements_per_cluster]\n",
    "            \n",
    "            # Find nearest cluster with space for each excess point\n",
    "            distances = cdist(excess_data, kmeans.cluster_centers_[remaining_clusters])\n",
    "            nearest_clusters = np.argmin(distances, axis=1)\n",
    "            \n",
    "            for i, excess_idx in enumerate(excess_points):\n",
    "                new_cluster = remaining_clusters[nearest_clusters[i]]\n",
    "                clustered_data[new_cluster].append(excess_idx)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"SelectQAOA Decomposition Time (ms): \" + str((end-start)*1000))\n",
    "    \n",
    "    clusters_dictionary[sir_program] = clustered_data\n",
    "        \n",
    "    # Step 3: Calculate the metrics for each cluster and validate\n",
    "    cluster_metrics = {}\n",
    "    for cluster_id in clustered_data.keys():\n",
    "        tot_cluster_exec_cost = 0\n",
    "        tot_cluster_past_fault_cov = 0\n",
    "        tot_cluster_stmt_cov = 0\n",
    "        for test_case in clustered_data[cluster_id]:\n",
    "            tot_cluster_exec_cost += test_cases_costs[sir_program][test_case]\n",
    "            tot_cluster_past_fault_cov += faults_dictionary[sir_program][test_case]\n",
    "        tot_cluster_past_fault_cov = tot_cluster_past_fault_cov/tot_test_cases\n",
    "        tot_cluster_stmt_cov = num_of_covered_lines(sir_program,clustered_data[cluster_id])/total_program_lines[sir_program]\n",
    "        cluster_metrics[cluster_id] = {\n",
    "            \"tot_exec_cost\": tot_cluster_exec_cost,\n",
    "            \"tot_past_fault_cov\": tot_cluster_past_fault_cov,\n",
    "            \"tot_stmt_cov\": tot_cluster_stmt_cov  # Avg stmt coverage per test case in cluster\n",
    "        }\n",
    "        print(f\"Cluster {cluster_id + 1} metrics:\")\n",
    "        print(f\"Test Cases: {clustered_data[cluster_id]}\")\n",
    "        print(f\" - Num. Test Cases: {len(clustered_data[cluster_id]):.2f}\")\n",
    "        print(f\" - Execution Cost: {tot_cluster_exec_cost:.2f}\")\n",
    "        print(f\" - Past Fault Coverage (%): {tot_cluster_past_fault_cov}\")\n",
    "        print(f\" - Statement Coverage (%): {tot_cluster_stmt_cov:.2f}\\n\")\n",
    "    \n",
    "    for cluster_id in clustered_data.keys():\n",
    "        print(\"Test cases of cluster \" + str(cluster_id) + \": \" + str(len(clustered_data[cluster_id])))\n",
    "    \n",
    "    print(\"======================================================================================\")\n",
    "    \n",
    "    print(\"Program Name: \" + sir_program)\n",
    "    \n",
    "    for cluster_id in clustered_data.keys():\n",
    "        if len(clustered_data[cluster_id]) > max_elements_per_cluster:\n",
    "            print(\"Test cases of cluster \" + str(cluster_id) + \": \" + str(len(clustered_data[cluster_id])))\n",
    "    \n",
    "    # Plotting the clusters in 3D space\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Extracting data for plotting\n",
    "    exec_costs = np.array(list(test_cases_costs[sir_program].values()))\n",
    "    fault_covs = np.array(faults_dictionary[sir_program])\n",
    "    stmt_covs = np.array(test_cases_stmt_cov)\n",
    "    \n",
    "    # Plot each cluster with a different color\n",
    "    colors = plt.cm.get_cmap(\"tab10\", num_clusters)  # A colormap with as many colors as clusters\n",
    "    for cluster_id in clustered_data.keys():\n",
    "        cluster_indices = clustered_data[cluster_id]\n",
    "        \n",
    "        # Plot each cluster's points\n",
    "        ax.scatter(\n",
    "            exec_costs[cluster_indices], \n",
    "            fault_covs[cluster_indices], \n",
    "            stmt_covs[cluster_indices], \n",
    "            color=colors(cluster_id), \n",
    "            label=f\"Cluster {cluster_id + 1}\"\n",
    "        )\n",
    "    \n",
    "    # Label the axes\n",
    "    ax.set_xlabel(\"Execution Cost\")\n",
    "    ax.set_ylabel(\"Past Fault Coverage\")\n",
    "    ax.set_zlabel(\"Statement Coverage\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Test Case Clustering Visualization\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "print(clusters_dictionary)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97b42e5ea26ae8a4",
   "metadata": {},
   "source": [
    "def make_linear_terms(sir_program, cluster_test_cases, alpha):\n",
    "    max_cost = max(test_cases_costs[sir_program].values())\n",
    "    \n",
    "    estimated_costs = []\n",
    "\n",
    "    #linear coefficients, that are the diagonal of the matrix encoding the QUBO\n",
    "    for test_case in cluster_test_cases:\n",
    "        estimated_costs.append((alpha * (test_cases_costs[sir_program][test_case]/max_cost)) - (1 - alpha) * faults_dictionary[sir_program][test_case])\n",
    "    \n",
    "    return np.array(estimated_costs)\n",
    "\n",
    "def make_quadratic_terms(sir_program, variables, cluster_test_cases, linear_terms, penalty):\n",
    "    quadratic_terms = {}\n",
    "    \n",
    "    #k is a stmt\n",
    "    for k in executed_lines_test_by_test[sir_program].keys():\n",
    "        #k_test_cases is the list of test cases covering k\n",
    "        k_test_cases = executed_lines_test_by_test[sir_program][k]\n",
    "        for i in k_test_cases:\n",
    "            if i not in cluster_test_cases or i not in variables:\n",
    "                continue\n",
    "            for j in k_test_cases:\n",
    "                if j not in cluster_test_cases or j not in variables:\n",
    "                    continue\n",
    "                if i < j:\n",
    "                    linear_terms[variables.index(i)] -= penalty\n",
    "                    try:\n",
    "                        quadratic_terms[variables.index(i),variables.index(j)] += 2 * penalty\n",
    "                    except:\n",
    "                        quadratic_terms[variables.index(i),variables.index(j)] = 2 * penalty\n",
    "    \n",
    "    return quadratic_terms"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "abead0754d567232",
   "metadata": {},
   "source": [
    "def create_QUBO_problem(linear_terms, quadratic_terms):\n",
    "    \"\"\"This function is the one that has to encode the QUBO problem that QAOA will have to solve. The QUBO problem specifies the optimization to solve and a quadratic binary unconstrained problem\"\"\"\n",
    "    qubo = QuadraticProgram()\n",
    "    \n",
    "    for i in range(0,len(linear_terms)):\n",
    "        qubo.binary_var('x%s' % (i))\n",
    "\n",
    "    qubo.minimize(linear=linear_terms,quadratic=quadratic_terms)\n",
    "\n",
    "    return qubo\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ab8c0bce740db9c",
   "metadata": {},
   "source": [
    "penalties_dictionary = {\"flex\":None,\"grep\":None,\"gzip\":None,\"sed\":None}\n",
    "\n",
    "#to obtain a QUBO problem from a quadratic problem with constraints, we have to insert those constraints into the Hamiltonian to solve (which is the one encoded by the QUBO problem). When we insert constraint into the Hamiltonian, we have to specify also penalties\n",
    "for sir_program in sir_programs:\n",
    "    max_penalty = 0\n",
    "    max_cost = max(test_cases_costs[sir_program].values())\n",
    "    for i in range(sir_programs_tests_number[sir_program]):\n",
    "        cost = (alpha * (test_cases_costs[sir_program][i]/max_cost)) - ((1 - alpha) * faults_dictionary[sir_program][i])\n",
    "        if cost > max_penalty:\n",
    "            max_penalty = cost\n",
    "    penalties_dictionary[sir_program] = max_penalty + 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c7f468b9deadab3",
   "metadata": {},
   "source": [
    "qubos_dictionary = {\"flex\":[],\"grep\":[],\"gzip\":[],\"sed\":[]}\n",
    "#make a dictionary that saves, for each program, the correspondent QUBO\n",
    "for sir_program in sir_programs:\n",
    "    print(\"SIR Program:\\n\")\n",
    "    for cluster_id in clusters_dictionary[sir_program]:\n",
    "        print(\"Cluster ID: \" + str(cluster_id))\n",
    "        variables = []\n",
    "        for idx in range(0, len(clusters_dictionary[sir_program][cluster_id])):\n",
    "            variables.append(idx)\n",
    "        linear_terms = make_linear_terms(sir_program, clusters_dictionary[sir_program][cluster_id], alpha)\n",
    "        quadratic_terms = make_quadratic_terms(sir_program, variables, clusters_dictionary[sir_program][cluster_id], linear_terms, penalties_dictionary[sir_program])\n",
    "        qubo = create_QUBO_problem(linear_terms, quadratic_terms)\n",
    "        qubos_dictionary[sir_program].append(qubo)\n",
    "        print(qubo)\n",
    "        print(\"/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/--/\")\n",
    "    print(\"======================================================================================\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "abaf9693911723af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T21:17:33.960271Z",
     "start_time": "2025-01-26T21:17:33.956014Z"
    }
   },
   "source": [
    "def covered_lines(sir_program,test_cases_list):\n",
    "    covered_lines = set()\n",
    "    \n",
    "    for test_case in test_cases_list:\n",
    "        try:\n",
    "            for covered_line in test_coverage_line_by_line[sir_program][test_case]:\n",
    "                covered_lines.add(covered_line)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return len(covered_lines)\n",
    "\n",
    "def build_pareto_front(sir_program,selected_tests):\n",
    "    pareto_front = []\n",
    "    max_fault_coverage = 0\n",
    "    max_stmt_coverage = 0\n",
    "    \n",
    "    for index in range(1,len(selected_tests)+1):\n",
    "        #exract the first index selected tests\n",
    "        candidate_solution = selected_tests[:index]\n",
    "        candidate_solution_fault_coverage = 0\n",
    "        candidate_solution_stmt_coverage = 0\n",
    "        for selected_test in candidate_solution:\n",
    "            candidate_solution_fault_coverage += faults_dictionary[sir_program][selected_test]\n",
    "            candidate_solution_stmt_coverage += covered_lines(sir_program,candidate_solution)\n",
    "        #if the actual pareto front dominates the candidate solution, get to the next candidate\n",
    "        if max_fault_coverage >= candidate_solution_fault_coverage and max_stmt_coverage >= candidate_solution_stmt_coverage:\n",
    "            continue\n",
    "        #eventually update the pareto front information\n",
    "        if candidate_solution_stmt_coverage > max_stmt_coverage:\n",
    "            max_stmt_coverage = candidate_solution_stmt_coverage\n",
    "        if candidate_solution_fault_coverage > max_fault_coverage:\n",
    "            max_fault_coverage = candidate_solution_fault_coverage\n",
    "        #add the candidate solution to the pareto front\n",
    "        pareto_front.append(candidate_solution)\n",
    "    \n",
    "    return pareto_front"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "4fd49476f04815bb",
   "metadata": {},
   "source": [
    "## Statevector Simulator"
   ]
  },
  {
   "cell_type": "code",
   "id": "306aa159e2a51733",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "algorithm_globals.random_seed = 10598\n",
    "backend = Aer.get_backend(\"statevector_simulator\")\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=backend), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "\n",
    "#I want to run the sampler 30 times to obtain different results for each sir program\n",
    "for sir_program in sir_programs:\n",
    "    #the fronts will be saved into files\n",
    "    print(\"SIR Program: \" + sir_program)\n",
    "    file_path = \"results/selectqaoa/statevector_sim/\" + sir_program + \"-data.json\"\n",
    "    json_data = {}\n",
    "    response = None\n",
    "    qpu_run_times = []\n",
    "    pareto_fronts_building_times = []\n",
    "    for i in range(experiments):\n",
    "        final_selected_tests = []\n",
    "        cluster_dict_index = 0\n",
    "        for qubo in qubos_dictionary[sir_program]:\n",
    "            print(\"QUBO Problem: \" + str(qubo) + \"\\n Cluster Number: \" + str(cluster_dict_index))\n",
    "            print(\"Cluster's Test Cases: \" +str(list(clusters_dictionary[sir_program].values())[cluster_dict_index]))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(qubo)\n",
    "            print(\"RESULTS: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            qpu_run_times.append((e - s) * 1000)\n",
    "            #let's extract the selected tests\n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_tests = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_tests))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_tests:\n",
    "                selected_tests.append(list(clusters_dictionary[sir_program].values())[cluster_dict_index][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            print(\"Experiment Number: \" + str(i))\n",
    "            cluster_dict_index += 1\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_selected_tests:\n",
    "                    final_selected_tests.append(selected_test)\n",
    "        i+=1\n",
    "        #now we have to build the pareto front\n",
    "        print(\"Final Selected Test Cases: \" + str(final_selected_tests))\n",
    "        print(\"Length of the final list of selected test cases: \" + str(len(final_selected_tests)))\n",
    "        start = time.time()\n",
    "        pareto_front = build_pareto_front(sir_program, final_selected_tests)\n",
    "        end = time.time()\n",
    "        json_data[\"pareto_front_\" + str(i)] = pareto_front\n",
    "        pareto_front_building_time = (end - start) * 1000\n",
    "        pareto_fronts_building_times.append(pareto_front_building_time)\n",
    "\n",
    "    #compute the average time needed for the construction of a pareto frontier and run time\n",
    "    mean_qpu_run_time = statistics.mean(qpu_run_times)\n",
    "    mean_pareto_fronts_building_time = statistics.mean(pareto_fronts_building_times)\n",
    "    json_data[\"mean_qpu_run_time(ms)\"] = mean_qpu_run_time\n",
    "    json_data[\"stdev_qpu_run_time(ms)\"] = statistics.stdev(qpu_run_times)\n",
    "    json_data[\"all_qpu_run_times(ms)\"] = qpu_run_times\n",
    "    json_data[\"mean_pareto_fronts_building_time(ms)\"] = mean_pareto_fronts_building_time\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(json_data, file)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76def72ed924c617",
   "metadata": {},
   "source": [
    "## Ideal Aer Simulator\n",
    "\n",
    "### QAOA Optimal Depth Analysis\n",
    "The first use of QAOA with aer simulator backend is to spot its optimal depth value. To do so, we run 30 times (for each SIR program) QAOA for each of the chosen reps values: 1, 2, 4, 8, 16. Then, using the Kruskal-Wallis H-test, we statistically analyze if there are relevant differences in the results. We use QAOA with aer simulator to obtain an Optimal Ideal configuration of QAOA for solving the TCS problem."
   ]
  },
  {
   "cell_type": "code",
   "id": "8b4789c23259bf42",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-27T09:29:05.941372Z",
     "start_time": "2025-01-26T21:17:51.626875Z"
    }
   },
   "source": [
    "#I want to run the sampler 30 times to get different results for each sir program\n",
    "for sir_program in sir_programs:\n",
    "    reps = [1,2,4,8,16]\n",
    "    for rep in reps:\n",
    "        sim_ideal = AerSimulator()\n",
    "        algorithm_globals.random_seed = 10598\n",
    "        qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_ideal), optimizer=COBYLA(100), reps=rep)\n",
    "        qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "        #the fronts will be saved into files\n",
    "        print(\"SIR Program: \" + sir_program)\n",
    "        file_path = \"results/selectqaoa/ideal/\" + sir_program + \"-data-rep-\" + str(rep) + \".json\"\n",
    "        json_data = {}\n",
    "        response = None\n",
    "        qpu_run_times = []\n",
    "        pareto_fronts_building_times = []\n",
    "        for i in range(experiments):\n",
    "            final_selected_tests = []\n",
    "            cluster_dict_index = 0\n",
    "            for qubo in qubos_dictionary[sir_program]:\n",
    "                print(\"QUBO Problem: \" + str(qubo) + \"\\n Cluster Number: \" + str(cluster_dict_index))\n",
    "                print(\"Cluster's Test Cases: \" +str(list(clusters_dictionary[sir_program].values())[cluster_dict_index]))\n",
    "                #for each iteration get the result\n",
    "                s = time.time()\n",
    "                qaoa_result = qaoa.solve(qubo)\n",
    "                print(\"RESULTS: \" + str(qaoa_result))\n",
    "                e = time.time()\n",
    "                qpu_run_times.append((e - s) * 1000)\n",
    "                #let's extract the selected tests\n",
    "                variable_values = qaoa_result.x\n",
    "                indexes_selected_tests = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "                print(\"Indexes of selected tests to convert. \" + str(indexes_selected_tests))\n",
    "                selected_tests = []\n",
    "                for index in indexes_selected_tests:\n",
    "                    selected_tests.append(list(clusters_dictionary[sir_program].values())[cluster_dict_index][index])\n",
    "                print(\"Selected tests: \" + str(selected_tests))\n",
    "                print(\"Experiment Number: \" + str(i))\n",
    "                cluster_dict_index += 1\n",
    "                for selected_test in selected_tests:\n",
    "                    if selected_test not in final_selected_tests:\n",
    "                        final_selected_tests.append(selected_test)\n",
    "            i+=1\n",
    "            #now we have to build the pareto front\n",
    "            print(\"Final Selected Test Cases: \" + str(final_selected_tests))\n",
    "            print(\"Length of the final list of selected test cases: \" + str(len(final_selected_tests)))\n",
    "            start = time.time()\n",
    "            pareto_front = build_pareto_front(sir_program, final_selected_tests)\n",
    "            end = time.time()\n",
    "            json_data[\"pareto_front_\" + str(i)] = pareto_front\n",
    "            pareto_front_building_time = (end - start) * 1000\n",
    "            pareto_fronts_building_times.append(pareto_front_building_time)\n",
    "\n",
    "    #compute the average time needed for the construction of a pareto frontier and run time\n",
    "    mean_qpu_run_time = statistics.mean(qpu_run_times)\n",
    "    mean_pareto_fronts_building_time = statistics.mean(pareto_fronts_building_times)\n",
    "    json_data[\"mean_qpu_run_time(ms)\"] = mean_qpu_run_time\n",
    "    json_data[\"stdev_qpu_run_time(ms)\"] = statistics.stdev(qpu_run_times)\n",
    "    json_data[\"all_qpu_run_times(ms)\"] = qpu_run_times\n",
    "    json_data[\"mean_pareto_fronts_building_time(ms)\"] = mean_pareto_fronts_building_time\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(json_data, file)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/kd67nwcs41113fgwjn39d7fm0000gn/T/ipykernel_9939/403574147.py:7: DeprecationWarning: The class ``qiskit.primitives.backend_sampler.BackendSampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `BackendSampler` class is `BackendSamplerV2`.\n",
      "  qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_ideal), optimizer=COBYLA(100), reps=rep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIR Program: flex\n",
      "QUBO Problem: minimize 70.38563106303513*x0*x2 - 35.1928149508474*x0 + 4.6791867798879533e-07*x1 + 2.311405517775977e-07*x2 + 3.157041682815968e-07*x3 + 4.735562524223953e-07*x4 + 3.833550614847962e-07*x5 + 3.833550614847962e-07*x6 (7 variables, 0 constraints, '')\n",
      " Cluster Number: 0\n",
      "Cluster's Test Cases: [0, 2, 11, 542, 551, 552, 553]\n",
      "RESULTS: fval=-35.1928149508474, x0=1.0, x1=0.0, x2=0.0, x3=0.0, x4=0.0, x5=0.0, x6=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0]\n",
      "Selected tests: [0]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4986518924632677*x0 - 0.49865199393960746*x1 - 0.49865195447658645*x2 - 0.49863967583947005*x3 - 0.49863963637644904*x4 - 0.49863970402734226*x5 - 0.4986396645643212*x6 - 0.498639895704873*x7 (8 variables, 0 constraints, '')\n",
      " Cluster Number: 1\n",
      "Cluster's Test Cases: [1, 204, 244, 329, 369, 459, 499, 519]\n",
      "RESULTS: fval=-3.9891544173919176, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Selected tests: [1, 204, 244, 329, 369, 459, 499, 519]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 2821.458296612482*x3*x10 - 0.4991933871251894*x0 - 0.49925980902716605*x1 - 0.4991294457559635*x10 - 0.49858233043233147*x11 - 0.49927110108875655*x12 - 0.49912940629294245*x13 - 0.49866111553504106*x14 - 0.4991725844755294*x15 - 0.49917269158944366*x16 - 0.4986664599556041*x17 - 0.49917266340157146*x18 - 0.49866643176773195*x19 - 0.4987486783411437*x2 - 0.4991726408512737*x20 - 0.49917261266340157*x21 - 0.49920049610655015*x22 - 0.49865657165004756*x23 - 0.49890493499171984*x24 - 1411.2284194298802*x3 - 0.49913406856699905*x4 - 0.4992710729008844*x5 - 0.499134029103978*x6 - 0.4991994869807265*x7 - 0.4991994813431521*x8 - 0.49927115182692644*x9 (25 variables, 0 constraints, '')\n",
      " Cluster Number: 2\n",
      "Cluster's Test Cases: [3, 10, 43, 66, 70, 106, 110, 122, 157, 196, 200, 230, 236, 240, 282, 288, 333, 343, 373, 383, 398, 408, 452, 482, 525]\n",
      "RESULTS: fval=-1422.7064326358982, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=0.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, x23=1.0, x24=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Selected tests: [3, 10, 43, 66, 70, 106, 110, 122, 157, 196, 230, 236, 240, 282, 288, 333, 343, 373, 383, 398, 408, 452, 482, 525]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4991824615059371*x0 - 0.49843645255628766*x1 - 0.4991434043902611*x10 - 0.49897400091610583*x11 - 0.4989668017335541*x12 - 0.4989667622705331*x13 - 0.49928558401747647*x14 - 0.49895148444381804*x15 - 0.498951444980797*x16 - 0.49895151263169024*x17 - 0.49931215390578204*x18 - 0.49931215390578204*x19 - 0.4991433818399634*x2 - 0.4989786237271414*x3 - 0.4991433762023889*x4 - 0.49897861808956695*x5 - 0.4989714245445897*x6 - 0.49897138508156863*x7 - 0.4991434100278355*x8 - 0.49897865191501356*x9 (20 variables, 0 constraints, '')\n",
      " Cluster Number: 3\n",
      "Cluster's Test Cases: [4, 40, 45, 52, 55, 62, 91, 131, 170, 177, 180, 192, 221, 261, 271, 346, 386, 476, 540, 541]\n",
      "RESULTS: fval=-9.980743088686092, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Selected tests: [4, 40, 45, 52, 55, 62, 91, 131, 170, 177, 180, 192, 221, 261, 271, 346, 386, 476, 540, 541]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49930301539762517*x0 - 0.4989767633275783*x1 - 0.499211077833762*x10 - 0.4986087932067228*x11 - 0.4986549198407385*x12 - 0.49860876501885065*x13 - 0.49865489165286636*x14 - 0.4992110270955921*x15 - 0.4986548691025686*x16 - 0.49921099890771997*x17 - 0.4974815320108523*x18 - 0.4992064550227265*x19 - 0.4991419047954618*x2 - 0.4992064268348543*x20 - 0.49920061449561326*x21 - 0.49929764278919*x22 - 0.4991418653324407*x3 - 0.4991418596948663*x4 - 0.49895323209189246*x5 - 0.49921099890771997*x6 - 0.49921097071984777*x7 - 0.49865481272682427*x8 - 0.49929776117825303*x9 (23 variables, 0 constraints, '')\n",
      " Cluster Number: 4\n",
      "Cluster's Test Cases: [5, 34, 80, 120, 155, 256, 277, 287, 293, 316, 332, 340, 353, 380, 393, 397, 403, 407, 419, 462, 502, 522, 539]\n",
      "RESULTS: fval=-11.476241197984567, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Selected tests: [5, 34, 80, 120, 155, 256, 277, 287, 293, 316, 332, 340, 353, 380, 393, 397, 403, 407, 419, 462, 502, 522, 539]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4993186709418273*x0 - 0.49863624255664*x1 - 0.4989541115535041*x10 - 0.4989901300165604*x11 - 0.49898238962686303*x12 - 0.4989823614389909*x13 - 0.4991550685317642*x14 - 0.49898556358126916*x15 - 0.49928207180860434*x16 - 0.4989550643035834*x2 - 0.4989978534935344*x3 - 0.4990641119058525*x4 - 0.49895873436453964*x5 - 0.4989586949015186*x6 - 0.49895872872696523*x7 - 0.49865192065113983*x8 - 0.4989279024699623*x9 (17 variables, 0 constraints, '')\n",
      " Cluster Number: 5\n",
      "Cluster's Test Cases: [6, 20, 30, 32, 42, 101, 141, 151, 167, 185, 231, 302, 341, 381, 430, 442, 527]\n",
      "RESULTS: fval=-8.482759620873118, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Selected tests: [6, 20, 30, 32, 42, 101, 141, 151, 167, 185, 231, 302, 341, 381, 430, 442, 527]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49928508791092635*x0 - 0.4992765751735316*x1 - 0.49859865121031677*x10 - 0.4991535745745393*x11 - 0.49896413516084703*x12 - 0.4985986230224446*x13 - 0.49915355202424155*x14 - 0.4985986004721469*x15 - 0.4991535238363694*x16 - 0.49748622247278107*x17 - 0.4991489799513759*x18 - 0.49896420281174025*x19 - 0.4989405644621402*x2 - 0.49914895176350377*x20 - 0.49896416334871924*x21 - 0.4992821789225186*x22 - 0.49914126211197635*x23 - 0.4992660554596385*x24 - 0.49894051372397025*x3 - 0.49894059265001234*x4 - 0.4991535238363694*x5 - 0.49915349564849726*x6 - 0.49859854409640253*x7 - 0.4991536027624115*x8 - 0.4989641746238681*x9 (25 variables, 0 constraints, '')\n",
      " Cluster Number: 6\n",
      "Cluster's Test Cases: [7, 37, 96, 136, 226, 275, 285, 290, 330, 336, 350, 370, 376, 390, 395, 400, 405, 414, 460, 466, 500, 506, 516, 520, 546]\n",
      "RESULTS: fval=-12.474029352031287, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, x23=1.0, x24=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Selected tests: [7, 37, 96, 136, 226, 275, 285, 290, 330, 336, 350, 370, 376, 390, 395, 400, 405, 414, 460, 466, 500, 506, 516, 520, 546]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49931885134420917*x0 - 0.4986681737782319*x1 - 0.4986056530777633*x2 - 0.4986095599168458*x3 - 0.49893956661146543*x4 - 0.4992016461717346*x5 - 0.4993061555265847*x6 (7 variables, 0 constraints, '')\n",
      " Cluster Number: 7\n",
      "Cluster's Test Cases: [8, 412, 413, 415, 435, 565, 566]\n",
      "RESULTS: fval=-3.492649606426835, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6]\n",
      "Selected tests: [8, 412, 413, 415, 435, 565, 566]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4990037560339664*x0 - 0.49917720728656495*x1 - 0.4992376477220676*x10 - 0.49865435608329517*x11 - 0.49865431662027415*x12 - 0.4986543842711673*x13 - 0.4986543448081463*x14 - 0.49888823085867307*x15 - 0.4985742856136147*x2 - 0.49917715654839506*x3 - 0.49857423487544483*x4 - 0.4991772354744371*x5 - 0.4985743138014869*x6 - 0.4991771847362672*x7 - 0.498574263063317*x8 - 0.4991713723970262*x9 (16 variables, 0 constraints, '')\n",
      " Cluster Number: 8\n",
      "Cluster's Test Cases: [9, 77, 85, 117, 125, 207, 215, 247, 255, 267, 315, 337, 377, 467, 507, 545]\n",
      "RESULTS: fval=-7.981924290194145, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Selected tests: [9, 77, 85, 117, 125, 207, 215, 247, 255, 267, 315, 337, 377, 467, 507, 545]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4993381882245164*x0 - 0.49888034389204045*x1 - 0.4993025813043938*x10 - 0.4993025531165216*x11 - 0.49930851203269794*x2 - 0.49865665621366406*x3 - 0.49858925337373594*x4 - 0.49930712518938725*x5 - 0.4993070970015151*x6 - 0.4989901356541348*x7 - 0.49930715337725945*x8 - 0.49899015820443254*x9 (12 variables, 0 constraints, '')\n",
      " Cluster Number: 9\n",
      "Cluster's Test Cases: [12, 31, 39, 162, 168, 276, 286, 312, 396, 427, 461, 501]\n",
      "RESULTS: fval=-5.9892797575843, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Selected tests: [12, 31, 39, 162, 168, 276, 286, 312, 396, 427, 461, 501]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49930237271413974*x0 - 0.4988755181283253*x1 - 0.49920536133328636*x10 - 0.49916718931679643*x11 - 0.49928547690356223*x12 - 0.4992854374405412*x13 - 0.4993079651879779*x14 - 0.4992881829392904*x15 - 0.4992881434762693*x16 - 0.49928821112716254*x17 - 0.4992881716641415*x18 - 0.4992053387829886*x2 - 0.4991671667664987*x3 - 0.4992053331454142*x4 - 0.4991671611289243*x5 - 0.4992900997145978*x6 - 0.49929006025157674*x7 - 0.49920536697086076*x8 - 0.4991671949543709*x9 (19 variables, 0 constraints, '')\n",
      " Cluster Number: 10\n",
      "Cluster's Test Cases: [13, 33, 47, 48, 57, 58, 71, 111, 172, 173, 182, 183, 201, 241, 317, 326, 366, 456, 496]\n",
      "RESULTS: fval=-9.485279751946724, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "Selected tests: [13, 33, 47, 48, 57, 58, 71, 111, 172, 173, 182, 183, 201, 241, 317, 326, 366, 456, 496]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4987730721257179*x0 - 0.49912498079701206*x1 - 0.4990825185863782*x2 - 0.49919153800077515*x3 - 0.499186971565484*x4 (5 variables, 0 constraints, '')\n",
      " Cluster Number: 11\n",
      "Cluster's Test Cases: [14, 18, 166, 301, 441]\n",
      "RESULTS: fval=-2.4953590810753674, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4]\n",
      "Selected tests: [14, 18, 166, 301, 441]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.499131013001656*x0 - 0.4990897572319509*x1 - 0.4993510982699694*x2 - 0.4990872541489024*x3 - 0.4991915436383496*x4 - 0.49919156618864735*x5 - 0.4991916620274127*x6 (7 variables, 0 constraints, '')\n",
      " Cluster Number: 12\n",
      "Cluster's Test Cases: [15, 17, 21, 161, 311, 426, 436]\n",
      "RESULTS: fval=-3.4942338945068885, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6]\n",
      "Selected tests: [15, 17, 21, 161, 311, 426, 436]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0.0013371762799055705*x0 + 0.0009127063880765301*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 13\n",
      "Cluster's Test Cases: [16, 532]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4993070913639407*x0 - 0.4992962052077094*x1 - 0.499178819632853*x10 - 0.499216850709982*x11 - 0.4991788252704274*x12 - 0.49921687326027975*x13 - 0.49917884782072514*x14 - 0.4992168788978542*x15 - 0.49917885345829954*x16 - 0.4992964419858356*x17 - 0.4992964137979634*x18 - 0.4989522624290899*x2 - 0.49895225679151545*x3 - 0.49895229061696206*x4 - 0.49897873647863006*x5 - 0.49894763961805433*x6 - 0.4992916162221204*x7 - 0.4992915767590994*x8 - 0.4992168450724076*x9 (19 variables, 0 constraints, '')\n",
      " Cluster Number: 14\n",
      "Cluster's Test Cases: [19, 26, 53, 63, 178, 187, 193, 211, 251, 297, 298, 307, 308, 422, 423, 432, 433, 451, 491]\n",
      "RESULTS: fval=-9.48414532539375, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "Selected tests: [19, 26, 53, 63, 178, 187, 193, 211, 251, 297, 298, 307, 308, 422, 423, 432, 433, 451, 491]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0.00031149853775413127*x0 + 0.00036618864733448434*x1 + 0.00032578415136887357*x2 + 0.0003347535322927311*x3 (4 variables, 0 constraints, '')\n",
      " Cluster Number: 15\n",
      "Cluster's Test Cases: [22, 23, 24, 526]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, x2=0.0, x3=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49914187097001517*x0 - 0.4989532546421902*x1 - 0.4991372425214052*x10 - 0.4992712476656918*x11 - 0.49912955286987776*x12 - 0.4986548409146965*x13 - 0.4986610873471689*x14 - 0.49920511891758573*x15 - 0.49866119446108315*x16 - 0.49920509072971353*x17 - 0.49866116627321094*x18 - 0.4986611437229132*x19 - 0.49858695324336705*x2 - 0.4986041703956873*x20 - 0.498650297029703*x21 - 0.499200467918678*x22 - 0.49860414220781507*x23 - 0.4989532039040203*x3 - 0.49858691378034603*x4 - 0.4991418991578873*x5 - 0.4985869476057926*x6 - 0.4974742651774074*x7 - 0.4991372819844262*x8 - 0.49895328283006235*x9 (24 variables, 0 constraints, '')\n",
      " Cluster Number: 16\n",
      "Cluster's Test Cases: [25, 86, 100, 126, 140, 145, 150, 164, 210, 216, 250, 266, 270, 283, 292, 322, 352, 362, 392, 402, 470, 483, 492, 510]\n",
      "RESULTS: fval=-11.971822636270746, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, x23=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Selected tests: [25, 86, 100, 126, 140, 145, 150, 164, 210, 216, 250, 266, 270, 283, 292, 322, 352, 362, 392, 402, 470, 483, 492, 510]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.499199492618301*x0 - 0.49926696874669674*x1 - 0.499194864169691*x10 - 0.4991890518304499*x11 - 0.49917261266340157*x12 - 0.4991651879778725*x13 - 0.4986759141679292*x14 - 0.49916515979000037*x15 - 0.4986758859800571*x16 - 0.4991680687784081*x17 - 0.4986618371445686*x18 - 0.49916804059053593*x19 - 0.4991995264437476*x2 - 0.4986618089566964*x20 - 0.4991606835559001*x21 - 0.49919689933406153*x22 - 0.4985970952397731*x3 - 0.4986432218737888*x4 - 0.49859705577675206*x5 - 0.49864318241076777*x6 - 0.49919952080617314*x7 - 0.4986432162362144*x8 - 0.499194903632712*x9 (23 variables, 0 constraints, '')\n",
      " Cluster Number: 17\n",
      "Cluster's Test Cases: [27, 38, 82, 90, 103, 130, 143, 147, 153, 212, 252, 272, 278, 323, 342, 363, 382, 463, 473, 503, 513, 523, 530]\n",
      "RESULTS: fval=-11.476440198724498, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Selected tests: [27, 38, 82, 90, 103, 130, 143, 147, 153, 212, 252, 272, 278, 323, 342, 363, 382, 463, 473, 503, 513, 523, 530]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49916095979704733*x0 - 0.49916099362249394*x1 - 0.49915637081145836*x10 - 0.49865013917761886*x11 - 0.49915633134843734*x12 - 0.4986500997145978*x13 - 0.4991489743138015*x14 - 0.49848259046545224*x15 - 0.4984825961030267*x16 - 0.4991220661710299*x17 - 0.4991886741129629*x18 - 0.4984826186533244*x19 - 0.4986643627779148*x2 - 0.49848262429089885*x20 - 0.4991221338219231*x21 - 0.4991887417638561*x22 - 0.4991220943589021*x23 - 0.49918870230083506*x24 - 0.49858592720482015*x25 - 0.49918288996159405*x26 - 0.49926606109721294*x27 - 0.4992659539832987*x28 - 0.4986547619886544*x3 - 0.4991534505479018*x4 - 0.49916095415947287*x5 - 0.49866432331489374*x6 - 0.49865472252563336*x7 - 0.4991609879849195*x8 - 0.49916094852189846*x9 (29 variables, 0 constraints, '')\n",
      " Cluster Number: 18\n",
      "Cluster's Test Cases: [28, 83, 92, 93, 113, 123, 132, 133, 148, 158, 213, 223, 253, 263, 273, 299, 309, 355, 367, 424, 434, 445, 457, 485, 497, 505, 517, 531, 548]\n",
      "RESULTS: fval=-14.469522054895881, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, x23=1.0, x24=1.0, x25=1.0, x26=1.0, x27=1.0, x28=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "Selected tests: [28, 83, 92, 93, 113, 123, 132, 133, 148, 158, 213, 223, 253, 263, 273, 299, 309, 355, 367, 424, 434, 445, 457, 485, 497, 505, 517, 531, 548]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49865649836157994*x0 - 0.49865661675064304*x1 - 0.498656577287622*x2 - 0.49865190937599096*x3 - 0.49865186991296995*x4 - 0.4986521010535217*x5 (6 variables, 0 constraints, '')\n",
      " Cluster Number: 19\n",
      "Cluster's Test Cases: [29, 74, 114, 214, 254, 274]\n",
      "RESULTS: fval=-2.991925572742328, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5]\n",
      "Selected tests: [29, 74, 114, 214, 254, 274]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49931750396391955*x0 - 0.49931648356294706*x1 - 0.49866348331630317*x10 - 0.49860096261583453*x11 - 0.49893947077270007*x12 - 0.49896403932208166*x13 - 0.4989348761495367*x14 - 0.49896507663577744*x15 - 0.49860258623727144*x2 - 0.49896962052077093*x3 - 0.4989695923328988*x4 - 0.49893944258482786*x5 - 0.4989394482224023*x6 - 0.498969699446813*x7 - 0.4989696712589408*x8 - 0.49896964870864313*x9 (16 variables, 0 constraints, '')\n",
      " Cluster Number: 20\n",
      "Cluster's Test Cases: [35, 36, 160, 281, 291, 300, 310, 351, 391, 401, 417, 418, 425, 438, 440, 481]\n",
      "RESULTS: fval=-7.983031605651669, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Selected tests: [35, 36, 160, 281, 291, 300, 310, 351, 391, 401, 417, 418, 425, 438, 440, 481]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4988906042775096*x0 - 0.49859398893626017*x1 - 0.4989593488601529*x10 - 0.4985978506747472*x2 - 0.49896391529544415*x3 - 0.49896392093301856*x4 - 0.49930720411542934*x5 - 0.4993071759275572*x6 - 0.49930712518938725*x7 - 0.4989639434833163*x8 - 0.4989902540431979*x9 (11 variables, 0 constraints, '')\n",
      " Cluster Number: 21\n",
      "Cluster's Test Cases: [41, 163, 165, 303, 313, 331, 371, 406, 428, 437, 443]\n",
      "RESULTS: fval=-5.488845331736021, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Selected tests: [41, 163, 165, 303, 313, 331, 371, 406, 428, 437, 443]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4963334907156196*x0 - 0.49633356400408724*x1 - 0.4963335245410662*x2 - 0.49633355836651283*x3 (4 variables, 0 constraints, '')\n",
      " Cluster Number: 22\n",
      "Cluster's Test Cases: [44, 104, 144, 154]\n",
      "RESULTS: fval=-1.985334137627286, x0=1.0, x1=1.0, x2=1.0, x3=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3]\n",
      "Selected tests: [44, 104, 144, 154]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4993136591381558*x0 - 0.4993136535005814*x1 - 0.499313687326028*x2 - 0.4993136816884535*x3 (4 variables, 0 constraints, '')\n",
      " Cluster Number: 23\n",
      "Cluster's Test Cases: [46, 56, 171, 181]\n",
      "RESULTS: fval=-1.9972546816532186, x0=1.0, x1=1.0, x2=1.0, x3=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3]\n",
      "Selected tests: [46, 56, 171, 181]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49847064444522743*x0 - 0.498470638807653*x1 - 0.4991104527676967*x2 - 0.4985641436172087*x3 - 0.4991104020295268*x4 - 0.49847067263309963*x5 - 0.49847066699552517*x6 - 0.49911048095556887*x7 - 0.499110430217399*x8 - 0.49863963637644904*x9 (10 variables, 0 constraints, '')\n",
      " Cluster Number: 24\n",
      "Cluster's Test Cases: [49, 59, 65, 95, 105, 174, 184, 195, 235, 347]\n",
      "RESULTS: fval=-4.987528168845355, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Selected tests: [49, 59, 65, 95, 105, 174, 184, 195, 235, 347]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4989277897184736*x0 - 0.4989277840808992*x1 - 0.499155040343892*x10 - 0.49930106479687114*x11 - 0.499301036608999*x12 - 0.49915506289418976*x13 - 0.4989777668158275*x14 - 0.4989777386279553*x15 - 0.4992965603748987*x16 - 0.4989861611641591*x17 - 0.499296239033156*x2 - 0.49929619957013494*x3 - 0.49929623339558155*x4 - 0.49929619393256053*x5 - 0.49892781790634577*x6 - 0.49895237518057856*x7 - 0.4989231669074381*x8 - 0.4991550347063176*x9 (18 variables, 0 constraints, '')\n",
      " Cluster Number: 25\n",
      "Cluster's Test Cases: [50, 60, 81, 121, 146, 156, 175, 188, 190, 295, 305, 321, 361, 420, 471, 511, 521, 543]\n",
      "RESULTS: fval=-8.98414926605828, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Selected tests: [50, 60, 81, 121, 146, 156, 175, 188, 190, 295, 305, 321, 361, 420, 471, 511, 521, 543]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4991806180190973*x0 - 0.49918061238152284*x1 - 0.49918064620696945*x2 - 0.49918073077058595*x3 - 0.4991759952080617*x4 - 0.4993245791198337*x5 - 0.49932458475740815*x6 - 0.49932460730770584*x7 - 0.4993246129452803*x8 (9 variables, 0 constraints, '')\n",
      " Cluster Number: 26\n",
      "Cluster's Test Cases: [51, 61, 176, 186, 191, 296, 306, 421, 431]\n",
      "RESULTS: fval=-4.493196986716465, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Selected tests: [51, 61, 176, 186, 191, 296, 306, 421, 431]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49674405271132094*x0 - 0.49674404707374653*x1 - 0.49674408089919314*x2 - 0.49674416546280964*x3 - 0.4967394299002854*x4 (5 variables, 0 constraints, '')\n",
      " Cluster Number: 27\n",
      "Cluster's Test Cases: [54, 64, 179, 189, 194]\n",
      "RESULTS: fval=-2.483715776047356, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4]\n",
      "Selected tests: [54, 64, 179, 189, 194]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4991712483703886*x0 - 0.49862813008703005*x1 - 0.49917119763221873*x2 - 0.49862807934886016*x3 - 0.4991712765582608*x4 - 0.4986281582749022*x5 - 0.4991712258200909*x6 - 0.4986180839293894*x7 - 0.49861804446636837*x8 - 0.49861811211726154*x9 (10 variables, 0 constraints, '')\n",
      " Cluster Number: 28\n",
      "Cluster's Test Cases: [67, 97, 107, 137, 197, 227, 237, 348, 388, 478]\n",
      "RESULTS: fval=-4.98842355660477, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Selected tests: [67, 97, 107, 137, 197, 227, 237, 348, 388, 478]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49911589302702514*x0 - 0.49865653218702655*x1 - 0.4991158422888552*x2 - 0.4986564927240055*x3 - 0.4986565265494521*x4 - 0.49865648708643107*x5 - 0.4991159212148973*x6 - 0.4991158704767274*x7 - 0.49866398506042775*x8 - 0.4986639568725556*x9 (10 variables, 0 constraints, '')\n",
      " Cluster Number: 29\n",
      "Cluster's Test Cases: [68, 84, 108, 124, 149, 159, 198, 238, 454, 494]\n",
      "RESULTS: fval=-4.988417507487404, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Selected tests: [68, 84, 108, 124, 149, 159, 198, 238, 454, 494]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4986278143828618*x0 - 0.49862776364469186*x1 - 0.49862784257073395*x2 - 0.49862779183256406*x3 (4 variables, 0 constraints, '')\n",
      " Cluster Number: 30\n",
      "Cluster's Test Cases: [69, 109, 199, 239]\n",
      "RESULTS: fval=-1.9945112124308517, x0=1.0, x1=1.0, x2=1.0, x3=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3]\n",
      "Selected tests: [69, 109, 199, 239]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49919356752757127*x0 - 0.4986496430710687*x1 - 0.4985924329657165*x10 - 0.49912994186251364*x11 - 0.4985757964835629*x12 - 0.4991299023994926*x13 - 0.4985757570205419*x14 - 0.499160565166837*x15 - 0.49912997005038584*x16 - 0.4986712913568937*x17 - 0.49857582467143513*x18 - 0.4991605369789648*x19 - 0.49919352806455025*x2 - 0.49912993058736477*x20 - 0.49867126316902155*x21 - 0.49912224093583735*x22 - 0.49864960360804766*x3 - 0.4986496374334942*x4 - 0.4991889447165357*x5 - 0.49859247242873755*x6 - 0.4986450202600331*x7 - 0.49863859906275326*x8 - 0.49918890525351467*x9 (23 variables, 0 constraints, '')\n",
      " Cluster Number: 31\n",
      "Cluster's Test Cases: [72, 102, 112, 142, 152, 202, 220, 232, 233, 242, 260, 325, 345, 365, 385, 453, 455, 472, 475, 493, 495, 512, 515]\n",
      "RESULTS: fval=-11.474215375074873, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Selected tests: [72, 102, 112, 142, 152, 202, 220, 232, 233, 242, 260, 325, 345, 365, 385, 453, 455, 472, 475, 493, 495, 512, 515]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4991534900109228*x0 - 0.4991182889961594*x1 - 0.4986597005038582*x10 - 0.49911057679433424*x11 - 0.49918871357598393*x12 - 0.498585938479969*x13 - 0.4991827151967866*x14 - 0.49858589901694794*x15 - 0.498639596913428*x16 - 0.4991827828476798*x17 - 0.49858596666784116*x18 - 0.4986396645643212*x19 - 0.4991182382579895*x2 - 0.49918274338465873*x20 - 0.4992544195060075*x21 - 0.4985640928790388*x3 - 0.49914886719988727*x4 - 0.49911831718403155*x5 - 0.49865973996687923*x6 - 0.4985641718050809*x7 - 0.4991488277368662*x8 - 0.49911826644586166*x9 (22 variables, 0 constraints, '')\n",
      " Cluster Number: 32\n",
      "Cluster's Test Cases: [73, 75, 115, 135, 203, 205, 222, 225, 243, 245, 262, 265, 327, 335, 357, 375, 387, 447, 465, 477, 487, 544]\n",
      "RESULTS: fval=-10.976511017934532, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "Selected tests: [73, 75, 115, 135, 203, 205, 222, 225, 243, 245, 262, 265, 327, 335, 357, 375, 387, 447, 465, 477, 487, 544]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4992772629576125*x0 - 0.4992772122194426*x1 - 0.49914114372291324*x10 - 0.4985940283992812*x11 - 0.4992820323455833*x12 - 0.49914111553504104*x13 - 0.4993117085374018*x14 - 0.49927729114548464*x2 - 0.49927724040731475*x3 - 0.4985985722842747*x4 - 0.49914576653394876*x5 - 0.4992820041577111*x6 - 0.4991457383460766*x7 - 0.49921104964588986*x8 - 0.49928207180860434*x9 (15 variables, 0 constraints, '')\n",
      " Cluster Number: 33\n",
      "Cluster's Test Cases: [76, 116, 206, 246, 280, 320, 356, 360, 372, 446, 450, 480, 486, 490, 561]\n",
      "RESULTS: fval=-7.487244238046579, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Selected tests: [76, 116, 206, 246, 280, 320, 356, 360, 372, 446, 450, 480, 486, 490, 561]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49912339663859623*x0 - 0.4986179711779007*x1 - 0.49866841619393254*x10 - 0.4986686078714633*x11 - 0.4986685233078468*x12 - 0.49912750643035836*x13 - 0.49866857968359113*x14 - 0.49866849511997463*x15 - 0.4986684725696769*x16 - 0.49866844438180474*x17 - 0.4991275740812515*x18 - 0.49866390049681125*x19 - 0.49912334590042634*x2 - 0.4991275346182305*x20 - 0.4986638723089391*x21 - 0.49866410344949086*x22 - 0.4986567971530249*x23 - 0.4986179204397308*x3 - 0.49912342482646843*x4 - 0.4986179993657729*x5 - 0.4991233740882985*x6 - 0.49861794862760295*x7 - 0.49911601705366265*x8 - 0.49866844438180474*x9 (24 variables, 0 constraints, '')\n",
      " Cluster Number: 34\n",
      "Cluster's Test Cases: [78, 88, 118, 128, 208, 218, 248, 258, 268, 279, 289, 324, 334, 358, 364, 374, 399, 409, 448, 464, 488, 504, 524, 562]\n",
      "RESULTS: fval=-11.97146067016666, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, x23=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Selected tests: [78, 88, 118, 128, 208, 218, 248, 258, 268, 279, 289, 324, 334, 358, 364, 374, 399, 409, 448, 464, 488, 504, 524, 562]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49862772981924525*x0 - 0.49862767908107536*x1 - 0.49862775800711745*x2 - 0.49862770726894756*x3 - 0.4986279384094993*x4 (5 variables, 0 constraints, '')\n",
      " Cluster Number: 35\n",
      "Cluster's Test Cases: [79, 119, 209, 249, 269]\n",
      "RESULTS: fval=-2.493138812585885, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4]\n",
      "Selected tests: [79, 119, 209, 249, 269]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4986428497938762*x0 - 0.49860643106303515*x1 - 0.4986295845812339*x10 - 0.49913507769282267*x11 - 0.49862965223212713*x12 - 0.49913503822980165*x13 - 0.4986296127691061*x14 - 0.49912768119516576*x15 - 0.4986427990557063*x2 - 0.4986063803248652*x3 - 0.49864287798174833*x4 - 0.4986064592509073*x5 - 0.49864282724357845*x6 - 0.49913504950495047*x7 - 0.498629624044255*x8 - 0.49913501004192945*x9 (16 variables, 0 constraints, '')\n",
      " Cluster Number: 36\n",
      "Cluster's Test Cases: [87, 98, 127, 138, 217, 228, 257, 328, 338, 368, 378, 458, 468, 498, 508, 518]\n",
      "RESULTS: fval=-7.980576955005109, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Selected tests: [87, 98, 127, 138, 217, 228, 257, 328, 338, 368, 378, 458, 468, 498, 508, 518]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4964753997392622*x0 - 0.49630556780945*x1 - 0.4964753490010923*x2 - 0.49630551707128007*x3 - 0.49647542792713434*x4 - 0.49630559599732216*x5 - 0.49647537718896445*x6 (7 variables, 0 constraints, '')\n",
      " Cluster Number: 37\n",
      "Cluster's Test Cases: [89, 99, 129, 139, 219, 229, 259]\n",
      "RESULTS: fval=-3.474818234734505, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6]\n",
      "Selected tests: [89, 99, 129, 139, 219, 229, 259]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4965033959338994*x0 - 0.4965033564708784*x1 - 0.4964987731228639*x2 - 0.4963289411930517*x3 - 0.4964987336598429*x4 (5 variables, 0 constraints, '')\n",
      " Cluster Number: 38\n",
      "Cluster's Test Cases: [94, 134, 224, 234, 264]\n",
      "RESULTS: fval=-2.4823332003805363, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4]\n",
      "Selected tests: [94, 134, 224, 234, 264]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4974695296148832*x0 - 0.49675599873154574*x1 - 0.4967560043691202*x2 - 0.49675602691941795*x3 - 0.4967561227581833*x4 - 0.4967514322962545*x5 (6 variables, 0 constraints, '')\n",
      " Cluster Number: 39\n",
      "Cluster's Test Cases: [169, 304, 314, 429, 439, 444]\n",
      "RESULTS: fval=-2.981245114689405, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5]\n",
      "Selected tests: [169, 304, 314, 429, 439, 444]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49634547619886543*x0 - 0.4963454480109933*x1 - 0.4965153870547197*x2 - 0.4963455551249075*x3 - 0.49651535886684756*x4 - 0.4963455269370353*x5 - 0.4963455043867376*x6 - 0.4965107642436842*x7 - 0.49634093231387194*x8 - 0.496510736055812*x9 (10 variables, 0 constraints, '')\n",
      " Cluster Number: 40\n",
      "Cluster's Test Cases: [284, 294, 344, 354, 384, 394, 404, 474, 484, 514]\n",
      "RESULTS: fval=-4.964120689193474, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Selected tests: [284, 294, 344, 354, 384, 394, 404, 474, 484, 514]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0.00013790070822028823*x0 (1 variables, 0 constraints, '')\n",
      " Cluster Number: 41\n",
      "Cluster's Test Cases: [318]\n",
      "RESULTS: fval=0.0, x0=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49863976040308655*x0 - 0.49863972094006553*x1 - 0.49863978859095875*x2 - 0.4986397491279377*x3 - 0.4989172418167084*x4 (5 variables, 0 constraints, '')\n",
      " Cluster Number: 42\n",
      "Cluster's Test Cases: [319, 359, 449, 489, 564]\n",
      "RESULTS: fval=-2.493476260878757, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4]\n",
      "Selected tests: [319, 359, 449, 489, 564]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.496487345759487*x0 - 0.49631751382967476*x1 - 0.4964873062964659*x2 - 0.49631747436665374*x3 - 0.49648737394735915*x4 - 0.49631754201754696*x5 - 0.4964873344843381*x6 - 0.49634050949578945*x7 (8 variables, 0 constraints, '')\n",
      " Cluster Number: 43\n",
      "Cluster's Test Cases: [339, 349, 379, 389, 469, 479, 509, 559]\n",
      "RESULTS: fval=-3.9712424001973154, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Selected tests: [339, 349, 379, 389, 469, 479, 509, 559]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.49861425037877455*x0 - 0.4992092287093478*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 44\n",
      "Cluster's Test Cases: [410, 563]\n",
      "RESULTS: fval=-0.9978234790881224, x0=1.0, x1=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1]\n",
      "Selected tests: [410, 563]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4990981854057292*x0 - 0.49909349494380045*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 45\n",
      "Cluster's Test Cases: [411, 416]\n",
      "RESULTS: fval=-0.9981916803495297, x0=1.0, x1=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1]\n",
      "Selected tests: [411, 416]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0.00546522814559036*x0 + 0.00550901518621613*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 46\n",
      "Cluster's Test Cases: [528, 547]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0.00010673619675134773*x0 (1 variables, 0 constraints, '')\n",
      " Cluster Number: 47\n",
      "Cluster's Test Cases: [529]\n",
      "RESULTS: fval=0.0, x0=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0 (1 variables, 0 constraints, '')\n",
      " Cluster Number: 48\n",
      "Cluster's Test Cases: [533]\n",
      "RESULTS: fval=0.0, x0=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0]\n",
      "Selected tests: [533]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 2.3536873260279765e-05*x0 + 2.3604524153482963e-05*x1 + 2.3649624748951764e-05*x2 + 2.3627074451217363e-05*x3 + 2.795109404178852e-05*x4 (5 variables, 0 constraints, '')\n",
      " Cluster Number: 49\n",
      "Cluster's Test Cases: [534, 535, 536, 537, 538]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, x2=0.0, x3=0.0, x4=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0.0001300024664388147*x0 + 0.0001300193791621155*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 50\n",
      "Cluster's Test Cases: [549, 550]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4986239808322469*x0 (1 variables, 0 constraints, '')\n",
      " Cluster Number: 51\n",
      "Cluster's Test Cases: [554]\n",
      "RESULTS: fval=-0.4986239808322469, x0=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0]\n",
      "Selected tests: [554]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize -0.4986548296395476*x0 - 0.49859244424086535*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 52\n",
      "Cluster's Test Cases: [555, 556]\n",
      "RESULTS: fval=-0.997247273880413, x0=1.0, x1=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1]\n",
      "Selected tests: [555, 556]\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 2.4224657341178957e-05*x0 + 2.416264402240936e-05*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 53\n",
      "Cluster's Test Cases: [557, 558]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "QUBO Problem: minimize 0.0009131630316056516*x0 (1 variables, 0 constraints, '')\n",
      " Cluster Number: 54\n",
      "Cluster's Test Cases: [560]\n",
      "RESULTS: fval=0.0, x0=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 0\n",
      "Final Selected Test Cases: [0, 1, 204, 244, 329, 369, 459, 499, 519, 3, 10, 43, 66, 70, 106, 110, 122, 157, 196, 230, 236, 240, 282, 288, 333, 343, 373, 383, 398, 408, 452, 482, 525, 4, 40, 45, 52, 55, 62, 91, 131, 170, 177, 180, 192, 221, 261, 271, 346, 386, 476, 540, 541, 5, 34, 80, 120, 155, 256, 277, 287, 293, 316, 332, 340, 353, 380, 393, 397, 403, 407, 419, 462, 502, 522, 539, 6, 20, 30, 32, 42, 101, 141, 151, 167, 185, 231, 302, 341, 381, 430, 442, 527, 7, 37, 96, 136, 226, 275, 285, 290, 330, 336, 350, 370, 376, 390, 395, 400, 405, 414, 460, 466, 500, 506, 516, 520, 546, 8, 412, 413, 415, 435, 565, 566, 9, 77, 85, 117, 125, 207, 215, 247, 255, 267, 315, 337, 377, 467, 507, 545, 12, 31, 39, 162, 168, 276, 286, 312, 396, 427, 461, 501, 13, 33, 47, 48, 57, 58, 71, 111, 172, 173, 182, 183, 201, 241, 317, 326, 366, 456, 496, 14, 18, 166, 301, 441, 15, 17, 21, 161, 311, 426, 436, 19, 26, 53, 63, 178, 187, 193, 211, 251, 297, 298, 307, 308, 422, 423, 432, 433, 451, 491, 25, 86, 100, 126, 140, 145, 150, 164, 210, 216, 250, 266, 270, 283, 292, 322, 352, 362, 392, 402, 470, 483, 492, 510, 27, 38, 82, 90, 103, 130, 143, 147, 153, 212, 252, 272, 278, 323, 342, 363, 382, 463, 473, 503, 513, 523, 530, 28, 83, 92, 93, 113, 123, 132, 133, 148, 158, 213, 223, 253, 263, 273, 299, 309, 355, 367, 424, 434, 445, 457, 485, 497, 505, 517, 531, 548, 29, 74, 114, 214, 254, 274, 35, 36, 160, 281, 291, 300, 310, 351, 391, 401, 417, 418, 425, 438, 440, 481, 41, 163, 165, 303, 313, 331, 371, 406, 428, 437, 443, 44, 104, 144, 154, 46, 56, 171, 181, 49, 59, 65, 95, 105, 174, 184, 195, 235, 347, 50, 60, 81, 121, 146, 156, 175, 188, 190, 295, 305, 321, 361, 420, 471, 511, 521, 543, 51, 61, 176, 186, 191, 296, 306, 421, 431, 54, 64, 179, 189, 194, 67, 97, 107, 137, 197, 227, 237, 348, 388, 478, 68, 84, 108, 124, 149, 159, 198, 238, 454, 494, 69, 109, 199, 239, 72, 102, 112, 142, 152, 202, 220, 232, 233, 242, 260, 325, 345, 365, 385, 453, 455, 472, 475, 493, 495, 512, 515, 73, 75, 115, 135, 203, 205, 222, 225, 243, 245, 262, 265, 327, 335, 357, 375, 387, 447, 465, 477, 487, 544, 76, 116, 206, 246, 280, 320, 356, 360, 372, 446, 450, 480, 486, 490, 561, 78, 88, 118, 128, 208, 218, 248, 258, 268, 279, 289, 324, 334, 358, 364, 374, 399, 409, 448, 464, 488, 504, 524, 562, 79, 119, 209, 249, 269, 87, 98, 127, 138, 217, 228, 257, 328, 338, 368, 378, 458, 468, 498, 508, 518, 89, 99, 129, 139, 219, 229, 259, 94, 134, 224, 234, 264, 169, 304, 314, 429, 439, 444, 284, 294, 344, 354, 384, 394, 404, 474, 484, 514, 319, 359, 449, 489, 564, 339, 349, 379, 389, 469, 479, 509, 559, 410, 563, 411, 416, 533, 554, 555, 556]\n",
      "Length of the final list of selected test cases540\n",
      "QUBO Problem: minimize 70.38563106303513*x0*x2 - 35.1928149508474*x0 + 4.6791867798879533e-07*x1 + 2.311405517775977e-07*x2 + 3.157041682815968e-07*x3 + 4.735562524223953e-07*x4 + 3.833550614847962e-07*x5 + 3.833550614847962e-07*x6 (7 variables, 0 constraints, '')\n",
      " Cluster Number: 0\n",
      "Cluster's Test Cases: [0, 2, 11, 542, 551, 552, 553]\n",
      "RESULTS: fval=-35.1928149508474, x0=1.0, x1=0.0, x2=0.0, x3=0.0, x4=0.0, x5=0.0, x6=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0]\n",
      "Selected tests: [0]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.4986518924632677*x0 - 0.49865199393960746*x1 - 0.49865195447658645*x2 - 0.49863967583947005*x3 - 0.49863963637644904*x4 - 0.49863970402734226*x5 - 0.4986396645643212*x6 - 0.498639895704873*x7 (8 variables, 0 constraints, '')\n",
      " Cluster Number: 1\n",
      "Cluster's Test Cases: [1, 204, 244, 329, 369, 459, 499, 519]\n",
      "RESULTS: fval=-3.9891544173919176, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Selected tests: [1, 204, 244, 329, 369, 459, 499, 519]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize 2821.458296612482*x3*x10 - 0.4991933871251894*x0 - 0.49925980902716605*x1 - 0.4991294457559635*x10 - 0.49858233043233147*x11 - 0.49927110108875655*x12 - 0.49912940629294245*x13 - 0.49866111553504106*x14 - 0.4991725844755294*x15 - 0.49917269158944366*x16 - 0.4986664599556041*x17 - 0.49917266340157146*x18 - 0.49866643176773195*x19 - 0.4987486783411437*x2 - 0.4991726408512737*x20 - 0.49917261266340157*x21 - 0.49920049610655015*x22 - 0.49865657165004756*x23 - 0.49890493499171984*x24 - 1411.2284194298802*x3 - 0.49913406856699905*x4 - 0.4992710729008844*x5 - 0.499134029103978*x6 - 0.4991994869807265*x7 - 0.4991994813431521*x8 - 0.49927115182692644*x9 (25 variables, 0 constraints, '')\n",
      " Cluster Number: 2\n",
      "Cluster's Test Cases: [3, 10, 43, 66, 70, 106, 110, 122, 157, 196, 200, 230, 236, 240, 282, 288, 333, 343, 373, 383, 398, 408, 452, 482, 525]\n",
      "RESULTS: fval=-1419.7124446354753, x0=1.0, x1=0.0, x2=1.0, x3=1.0, x4=0.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=0.0, x11=0.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=0.0, x17=0.0, x18=1.0, x19=1.0, x20=0.0, x21=1.0, x22=1.0, x23=1.0, x24=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 2, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24]\n",
      "Selected tests: [3, 43, 66, 106, 110, 122, 157, 196, 236, 240, 282, 288, 373, 383, 408, 452, 482, 525]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.4991824615059371*x0 - 0.49843645255628766*x1 - 0.4991434043902611*x10 - 0.49897400091610583*x11 - 0.4989668017335541*x12 - 0.4989667622705331*x13 - 0.49928558401747647*x14 - 0.49895148444381804*x15 - 0.498951444980797*x16 - 0.49895151263169024*x17 - 0.49931215390578204*x18 - 0.49931215390578204*x19 - 0.4991433818399634*x2 - 0.4989786237271414*x3 - 0.4991433762023889*x4 - 0.49897861808956695*x5 - 0.4989714245445897*x6 - 0.49897138508156863*x7 - 0.4991434100278355*x8 - 0.49897865191501356*x9 (20 variables, 0 constraints, '')\n",
      " Cluster Number: 3\n",
      "Cluster's Test Cases: [4, 40, 45, 52, 55, 62, 91, 131, 170, 177, 180, 192, 221, 261, 271, 346, 386, 476, 540, 541]\n",
      "RESULTS: fval=-9.980743088686092, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Selected tests: [4, 40, 45, 52, 55, 62, 91, 131, 170, 177, 180, 192, 221, 261, 271, 346, 386, 476, 540, 541]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.49930301539762517*x0 - 0.4989767633275783*x1 - 0.499211077833762*x10 - 0.4986087932067228*x11 - 0.4986549198407385*x12 - 0.49860876501885065*x13 - 0.49865489165286636*x14 - 0.4992110270955921*x15 - 0.4986548691025686*x16 - 0.49921099890771997*x17 - 0.4974815320108523*x18 - 0.4992064550227265*x19 - 0.4991419047954618*x2 - 0.4992064268348543*x20 - 0.49920061449561326*x21 - 0.49929764278919*x22 - 0.4991418653324407*x3 - 0.4991418596948663*x4 - 0.49895323209189246*x5 - 0.49921099890771997*x6 - 0.49921097071984777*x7 - 0.49865481272682427*x8 - 0.49929776117825303*x9 (23 variables, 0 constraints, '')\n",
      " Cluster Number: 4\n",
      "Cluster's Test Cases: [5, 34, 80, 120, 155, 256, 277, 287, 293, 316, 332, 340, 353, 380, 393, 397, 403, 407, 419, 462, 502, 522, 539]\n",
      "RESULTS: fval=-11.476241197984567, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Selected tests: [5, 34, 80, 120, 155, 256, 277, 287, 293, 316, 332, 340, 353, 380, 393, 397, 403, 407, 419, 462, 502, 522, 539]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.4993186709418273*x0 - 0.49863624255664*x1 - 0.4989541115535041*x10 - 0.4989901300165604*x11 - 0.49898238962686303*x12 - 0.4989823614389909*x13 - 0.4991550685317642*x14 - 0.49898556358126916*x15 - 0.49928207180860434*x16 - 0.4989550643035834*x2 - 0.4989978534935344*x3 - 0.4990641119058525*x4 - 0.49895873436453964*x5 - 0.4989586949015186*x6 - 0.49895872872696523*x7 - 0.49865192065113983*x8 - 0.4989279024699623*x9 (17 variables, 0 constraints, '')\n",
      " Cluster Number: 5\n",
      "Cluster's Test Cases: [6, 20, 30, 32, 42, 101, 141, 151, 167, 185, 231, 302, 341, 381, 430, 442, 527]\n",
      "RESULTS: fval=-8.482759620873118, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Selected tests: [6, 20, 30, 32, 42, 101, 141, 151, 167, 185, 231, 302, 341, 381, 430, 442, 527]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.49928508791092635*x0 - 0.4992765751735316*x1 - 0.49859865121031677*x10 - 0.4991535745745393*x11 - 0.49896413516084703*x12 - 0.4985986230224446*x13 - 0.49915355202424155*x14 - 0.4985986004721469*x15 - 0.4991535238363694*x16 - 0.49748622247278107*x17 - 0.4991489799513759*x18 - 0.49896420281174025*x19 - 0.4989405644621402*x2 - 0.49914895176350377*x20 - 0.49896416334871924*x21 - 0.4992821789225186*x22 - 0.49914126211197635*x23 - 0.4992660554596385*x24 - 0.49894051372397025*x3 - 0.49894059265001234*x4 - 0.4991535238363694*x5 - 0.49915349564849726*x6 - 0.49859854409640253*x7 - 0.4991536027624115*x8 - 0.4989641746238681*x9 (25 variables, 0 constraints, '')\n",
      " Cluster Number: 6\n",
      "Cluster's Test Cases: [7, 37, 96, 136, 226, 275, 285, 290, 330, 336, 350, 370, 376, 390, 395, 400, 405, 414, 460, 466, 500, 506, 516, 520, 546]\n",
      "RESULTS: fval=-12.474029352031287, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, x23=1.0, x24=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Selected tests: [7, 37, 96, 136, 226, 275, 285, 290, 330, 336, 350, 370, 376, 390, 395, 400, 405, 414, 460, 466, 500, 506, 516, 520, 546]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.49931885134420917*x0 - 0.4986681737782319*x1 - 0.4986056530777633*x2 - 0.4986095599168458*x3 - 0.49893956661146543*x4 - 0.4992016461717346*x5 - 0.4993061555265847*x6 (7 variables, 0 constraints, '')\n",
      " Cluster Number: 7\n",
      "Cluster's Test Cases: [8, 412, 413, 415, 435, 565, 566]\n",
      "RESULTS: fval=-3.492649606426835, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6]\n",
      "Selected tests: [8, 412, 413, 415, 435, 565, 566]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.4990037560339664*x0 - 0.49917720728656495*x1 - 0.4992376477220676*x10 - 0.49865435608329517*x11 - 0.49865431662027415*x12 - 0.4986543842711673*x13 - 0.4986543448081463*x14 - 0.49888823085867307*x15 - 0.4985742856136147*x2 - 0.49917715654839506*x3 - 0.49857423487544483*x4 - 0.4991772354744371*x5 - 0.4985743138014869*x6 - 0.4991771847362672*x7 - 0.498574263063317*x8 - 0.4991713723970262*x9 (16 variables, 0 constraints, '')\n",
      " Cluster Number: 8\n",
      "Cluster's Test Cases: [9, 77, 85, 117, 125, 207, 215, 247, 255, 267, 315, 337, 377, 467, 507, 545]\n",
      "RESULTS: fval=-7.981924290194145, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Selected tests: [9, 77, 85, 117, 125, 207, 215, 247, 255, 267, 315, 337, 377, 467, 507, 545]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.4993381882245164*x0 - 0.49888034389204045*x1 - 0.4993025813043938*x10 - 0.4993025531165216*x11 - 0.49930851203269794*x2 - 0.49865665621366406*x3 - 0.49858925337373594*x4 - 0.49930712518938725*x5 - 0.4993070970015151*x6 - 0.4989901356541348*x7 - 0.49930715337725945*x8 - 0.49899015820443254*x9 (12 variables, 0 constraints, '')\n",
      " Cluster Number: 9\n",
      "Cluster's Test Cases: [12, 31, 39, 162, 168, 276, 286, 312, 396, 427, 461, 501]\n",
      "RESULTS: fval=-5.9892797575843, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Selected tests: [12, 31, 39, 162, 168, 276, 286, 312, 396, 427, 461, 501]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.49930237271413974*x0 - 0.4988755181283253*x1 - 0.49920536133328636*x10 - 0.49916718931679643*x11 - 0.49928547690356223*x12 - 0.4992854374405412*x13 - 0.4993079651879779*x14 - 0.4992881829392904*x15 - 0.4992881434762693*x16 - 0.49928821112716254*x17 - 0.4992881716641415*x18 - 0.4992053387829886*x2 - 0.4991671667664987*x3 - 0.4992053331454142*x4 - 0.4991671611289243*x5 - 0.4992900997145978*x6 - 0.49929006025157674*x7 - 0.49920536697086076*x8 - 0.4991671949543709*x9 (19 variables, 0 constraints, '')\n",
      " Cluster Number: 10\n",
      "Cluster's Test Cases: [13, 33, 47, 48, 57, 58, 71, 111, 172, 173, 182, 183, 201, 241, 317, 326, 366, 456, 496]\n",
      "RESULTS: fval=-9.485279751946724, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "Selected tests: [13, 33, 47, 48, 57, 58, 71, 111, 172, 173, 182, 183, 201, 241, 317, 326, 366, 456, 496]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.4987730721257179*x0 - 0.49912498079701206*x1 - 0.4990825185863782*x2 - 0.49919153800077515*x3 - 0.499186971565484*x4 (5 variables, 0 constraints, '')\n",
      " Cluster Number: 11\n",
      "Cluster's Test Cases: [14, 18, 166, 301, 441]\n",
      "RESULTS: fval=-2.4953590810753674, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4]\n",
      "Selected tests: [14, 18, 166, 301, 441]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.499131013001656*x0 - 0.4990897572319509*x1 - 0.4993510982699694*x2 - 0.4990872541489024*x3 - 0.4991915436383496*x4 - 0.49919156618864735*x5 - 0.4991916620274127*x6 (7 variables, 0 constraints, '')\n",
      " Cluster Number: 12\n",
      "Cluster's Test Cases: [15, 17, 21, 161, 311, 426, 436]\n",
      "RESULTS: fval=-3.4942338945068885, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6]\n",
      "Selected tests: [15, 17, 21, 161, 311, 426, 436]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize 0.0013371762799055705*x0 + 0.0009127063880765301*x1 (2 variables, 0 constraints, '')\n",
      " Cluster Number: 13\n",
      "Cluster's Test Cases: [16, 532]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.4993070913639407*x0 - 0.4992962052077094*x1 - 0.499178819632853*x10 - 0.499216850709982*x11 - 0.4991788252704274*x12 - 0.49921687326027975*x13 - 0.49917884782072514*x14 - 0.4992168788978542*x15 - 0.49917885345829954*x16 - 0.4992964419858356*x17 - 0.4992964137979634*x18 - 0.4989522624290899*x2 - 0.49895225679151545*x3 - 0.49895229061696206*x4 - 0.49897873647863006*x5 - 0.49894763961805433*x6 - 0.4992916162221204*x7 - 0.4992915767590994*x8 - 0.4992168450724076*x9 (19 variables, 0 constraints, '')\n",
      " Cluster Number: 14\n",
      "Cluster's Test Cases: [19, 26, 53, 63, 178, 187, 193, 211, 251, 297, 298, 307, 308, 422, 423, 432, 433, 451, 491]\n",
      "RESULTS: fval=-9.48414532539375, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "Selected tests: [19, 26, 53, 63, 178, 187, 193, 211, 251, 297, 298, 307, 308, 422, 423, 432, 433, 451, 491]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize 0.00031149853775413127*x0 + 0.00036618864733448434*x1 + 0.00032578415136887357*x2 + 0.0003347535322927311*x3 (4 variables, 0 constraints, '')\n",
      " Cluster Number: 15\n",
      "Cluster's Test Cases: [22, 23, 24, 526]\n",
      "RESULTS: fval=0.0, x0=0.0, x1=0.0, x2=0.0, x3=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.49914187097001517*x0 - 0.4989532546421902*x1 - 0.4991372425214052*x10 - 0.4992712476656918*x11 - 0.49912955286987776*x12 - 0.4986548409146965*x13 - 0.4986610873471689*x14 - 0.49920511891758573*x15 - 0.49866119446108315*x16 - 0.49920509072971353*x17 - 0.49866116627321094*x18 - 0.4986611437229132*x19 - 0.49858695324336705*x2 - 0.4986041703956873*x20 - 0.498650297029703*x21 - 0.499200467918678*x22 - 0.49860414220781507*x23 - 0.4989532039040203*x3 - 0.49858691378034603*x4 - 0.4991418991578873*x5 - 0.4985869476057926*x6 - 0.4974742651774074*x7 - 0.4991372819844262*x8 - 0.49895328283006235*x9 (24 variables, 0 constraints, '')\n",
      " Cluster Number: 16\n",
      "Cluster's Test Cases: [25, 86, 100, 126, 140, 145, 150, 164, 210, 216, 250, 266, 270, 283, 292, 322, 352, 362, 392, 402, 470, 483, 492, 510]\n",
      "RESULTS: fval=-11.971822636270746, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, x23=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "Selected tests: [25, 86, 100, 126, 140, 145, 150, 164, 210, 216, 250, 266, 270, 283, 292, 322, 352, 362, 392, 402, 470, 483, 492, 510]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.499199492618301*x0 - 0.49926696874669674*x1 - 0.499194864169691*x10 - 0.4991890518304499*x11 - 0.49917261266340157*x12 - 0.4991651879778725*x13 - 0.4986759141679292*x14 - 0.49916515979000037*x15 - 0.4986758859800571*x16 - 0.4991680687784081*x17 - 0.4986618371445686*x18 - 0.49916804059053593*x19 - 0.4991995264437476*x2 - 0.4986618089566964*x20 - 0.4991606835559001*x21 - 0.49919689933406153*x22 - 0.4985970952397731*x3 - 0.4986432218737888*x4 - 0.49859705577675206*x5 - 0.49864318241076777*x6 - 0.49919952080617314*x7 - 0.4986432162362144*x8 - 0.499194903632712*x9 (23 variables, 0 constraints, '')\n",
      " Cluster Number: 17\n",
      "Cluster's Test Cases: [27, 38, 82, 90, 103, 130, 143, 147, 153, 212, 252, 272, 278, 323, 342, 363, 382, 463, 473, 503, 513, 523, 530]\n",
      "RESULTS: fval=-11.476440198724498, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, x5=1.0, x6=1.0, x7=1.0, x8=1.0, x9=1.0, x10=1.0, x11=1.0, x12=1.0, x13=1.0, x14=1.0, x15=1.0, x16=1.0, x17=1.0, x18=1.0, x19=1.0, x20=1.0, x21=1.0, x22=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Selected tests: [27, 38, 82, 90, 103, 130, 143, 147, 153, 212, 252, 272, 278, 323, 342, 363, 382, 463, 473, 503, 513, 523, 530]\n",
      "This Was The Experiment Number: 1\n",
      "QUBO Problem: minimize -0.49916095979704733*x0 - 0.49916099362249394*x1 - 0.49915637081145836*x10 - 0.49865013917761886*x11 - 0.49915633134843734*x12 - 0.4986500997145978*x13 - 0.4991489743138015*x14 - 0.49848259046545224*x15 - 0.4984825961030267*x16 - 0.4991220661710299*x17 - 0.4991886741129629*x18 - 0.4984826186533244*x19 - 0.4986643627779148*x2 - 0.49848262429089885*x20 - 0.4991221338219231*x21 - 0.4991887417638561*x22 - 0.4991220943589021*x23 - 0.49918870230083506*x24 - 0.49858592720482015*x25 - 0.49918288996159405*x26 - 0.49926606109721294*x27 - 0.4992659539832987*x28 - 0.4986547619886544*x3 - 0.4991534505479018*x4 - 0.49916095415947287*x5 - 0.49866432331489374*x6 - 0.49865472252563336*x7 - 0.4991609879849195*x8 - 0.49916094852189846*x9 (29 variables, 0 constraints, '')\n",
      " Cluster Number: 18\n",
      "Cluster's Test Cases: [28, 83, 92, 93, 113, 123, 132, 133, 148, 158, 213, 223, 253, 263, 273, 299, 309, 355, 367, 424, 434, 445, 457, 485, 497, 505, 517, 531, 548]\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f8ce86ed02c33d9",
   "metadata": {},
   "source": [
    "## The Kruskal-Wallis H-test\n",
    "The Kruskal-Wallis H-test is a non-parametric statistical test used to determine whether there are statistically significant differences between the medians of three or more independent groups. It is an extension of the Mann-Whitney U test for more than two groups and is used when the assumptions of ANOVA (e.g., normality and homogeneity of variance) are not met. The test ranks all data points across groups, calculates the sum of ranks for each group, and determines whether these ranks differ significantly. It outputs the H statistic and a p-value, where a small p-value indicates significant differences between groups."
   ]
  },
  {
   "cell_type": "code",
   "id": "7ecd625a6f0ddcfa",
   "metadata": {},
   "source": [
    "flex_non_dom_solutions = []\n",
    "grep_non_dom_solutions = []\n",
    "gzip_non_dom_solutions = []\n",
    "sed_non_dom_solutions = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e63c7b626dc9cd90",
   "metadata": {},
   "source": [
    "## Fake Vigo Noise Simulator"
   ]
  },
  {
   "cell_type": "code",
   "id": "8cb54e2582c97bf1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "device_backend = FakeVigoV2()\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=device_backend), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "\n",
    "#I want to run the sampler 30 times to obtain different results for each sir program\n",
    "for sir_program in sir_programs:\n",
    "    #the fronts will be saved into files\n",
    "    print(sir_program)\n",
    "    file_path = \"results/selectqaoa/fake_vigo/\" + sir_program + \"-data.json\"\n",
    "    json_data = {}\n",
    "    response = None\n",
    "    qpu_run_times = []\n",
    "    pareto_fronts_building_times = []\n",
    "    for i in range(experiments):\n",
    "        final_selected_tests = []\n",
    "        cluster_dict_index = 0\n",
    "        for qubo in qubos_dictionary[sir_program]:\n",
    "            print(\"Experiment Number: \" + str(i))\n",
    "            print(\"QUBO Problem: \" + str(qubo) + \"\\nNumber: \" + str(cluster_dict_index))\n",
    "            print(\"Cluster's Test Cases: \" +str(list(clusters_dictionary[sir_program].values())[cluster_dict_index]))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(qubo)\n",
    "            print(\"RESULTS: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            qpu_run_times.append((e - s) * 1000)\n",
    "            #let's extract the selected tests\n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_tests = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_tests))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_tests:\n",
    "                selected_tests.append(list(clusters_dictionary[sir_program].values())[cluster_dict_index][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            cluster_dict_index += 1\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_selected_tests:\n",
    "                    final_selected_tests.append(selected_test)\n",
    "        i+=1\n",
    "        #now we have to build the pareto front\n",
    "        print(\"Final Selected Test Cases: \" + str(final_selected_tests))\n",
    "        print(len(final_selected_tests))\n",
    "        start = time.time()\n",
    "        pareto_front = build_pareto_front(sir_program, final_selected_tests)\n",
    "        end = time.time()\n",
    "        json_data[\"pareto_front_\" + str(i)] = pareto_front\n",
    "        pareto_front_building_time = (end - start) * 1000\n",
    "        pareto_fronts_building_times.append(pareto_front_building_time)\n",
    "\n",
    "    #compute the average time needed for the construction of a pareto frontier and run time\n",
    "    mean_qpu_run_time = statistics.mean(qpu_run_times)\n",
    "    mean_pareto_fronts_building_time = statistics.mean(pareto_fronts_building_times)\n",
    "    json_data[\"mean_qpu_run_time(ms)\"] = mean_qpu_run_time\n",
    "    json_data[\"stdev_qpu_run_time(ms)\"] = statistics.stdev(qpu_run_times)\n",
    "    json_data[\"all_qpu_run_times(ms)\"] = qpu_run_times\n",
    "    json_data[\"mean_pareto_fronts_building_time(ms)\"] = mean_pareto_fronts_building_time\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(json_data, file)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cee2816526058aef",
   "metadata": {},
   "source": [
    "## Depolarizing Error Simulator"
   ]
  },
  {
   "cell_type": "code",
   "id": "188a16dd83242111",
   "metadata": {},
   "source": [
    "noise_dep = NoiseModel()\n",
    "\n",
    "# Define a 1% depolarizing error for single-qubit and two-qubit gates\n",
    "depolarizing_error_1q = depolarizing_error(0.01, 1)  # 1% depolarizing error for single-qubit gates\n",
    "depolarizing_error_2q = depolarizing_error(0.01, 2)  # 1% depolarizing error for two-qubit gates\n",
    "\n",
    "# Add the 1% depolarizing noise to the single-qubit gates (rx and rz)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_1q, ['rx', 'rz'])\n",
    "\n",
    "# Add the 1% depolarizing noise to the two-qubit gate (cx)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_2q, ['cx'])\n",
    "\n",
    "sim_dep = AerSimulator(noise_model=noise_dep)\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "\n",
    "#I want to run the sampler 30 times to obtain different results for each sir program\n",
    "for sir_program in sir_programs:\n",
    "    #the fronts will be saved into files\n",
    "    print(sir_program)\n",
    "    file_path = \"results/selectqaoa/depolarizing_sim/01/\" + sir_program + \"-data.json\"\n",
    "    json_data = {}\n",
    "    response = None\n",
    "    qpu_run_times = []\n",
    "    pareto_fronts_building_times = []\n",
    "    for i in range(experiments):\n",
    "        final_selected_tests = []\n",
    "        cluster_dict_index = 0\n",
    "        for qubo in qubos_dictionary[sir_program]:\n",
    "            print(\"Experiment Number: \" + str(i))\n",
    "            print(\"QUBO Problem: \" + str(qubo) + \"\\nNumber: \" + str(cluster_dict_index))\n",
    "            print(\"Cluster's Test Cases: \" +str(list(clusters_dictionary[sir_program].values())[cluster_dict_index]))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(qubo)\n",
    "            print(\"RESULTS: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            qpu_run_times.append((e - s) * 1000)\n",
    "            #let's extract the selected tests\n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_tests = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_tests))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_tests:\n",
    "                selected_tests.append(list(clusters_dictionary[sir_program].values())[cluster_dict_index][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            cluster_dict_index += 1\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_selected_tests:\n",
    "                    final_selected_tests.append(selected_test)\n",
    "        i+=1\n",
    "        #now we have to build the pareto front\n",
    "        print(\"Final Selected Test Cases: \" + str(final_selected_tests))\n",
    "        print(len(final_selected_tests))\n",
    "        start = time.time()\n",
    "        pareto_front = build_pareto_front(sir_program, final_selected_tests)\n",
    "        end = time.time()\n",
    "        json_data[\"pareto_front_\" + str(i)] = pareto_front\n",
    "        pareto_front_building_time = (end - start) * 1000\n",
    "        pareto_fronts_building_times.append(pareto_front_building_time)\n",
    "\n",
    "    #compute the average time needed for the construction of a pareto frontier and run time\n",
    "    mean_qpu_run_time = statistics.mean(qpu_run_times)\n",
    "    mean_pareto_fronts_building_time = statistics.mean(pareto_fronts_building_times)\n",
    "    json_data[\"mean_qpu_run_time(ms)\"] = mean_qpu_run_time\n",
    "    json_data[\"stdev_qpu_run_time(ms)\"] = statistics.stdev(qpu_run_times)\n",
    "    json_data[\"all_qpu_run_times(ms)\"] = qpu_run_times\n",
    "    json_data[\"mean_pareto_fronts_building_time(ms)\"] = mean_pareto_fronts_building_time\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(json_data, file)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b50efcb97700f8a",
   "metadata": {},
   "source": [
    "noise_dep = NoiseModel()\n",
    "\n",
    "# Define a 1% depolarizing error for single-qubit and two-qubit gates\n",
    "depolarizing_error_1q = depolarizing_error(0.02, 1)  # 1% depolarizing error for single-qubit gates\n",
    "depolarizing_error_2q = depolarizing_error(0.02, 2)  # 1% depolarizing error for two-qubit gates\n",
    "\n",
    "# Add the 1% depolarizing noise to the single-qubit gates (rx and rz)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_1q, ['rx', 'rz'])\n",
    "\n",
    "# Add the 1% depolarizing noise to the two-qubit gate (cx)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_2q, ['cx'])\n",
    "\n",
    "sim_dep = AerSimulator(noise_model=noise_dep)\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "\n",
    "#I want to run the sampler 30 times to obtain different results for each sir program\n",
    "for sir_program in sir_programs:\n",
    "    #the fronts will be saved into files\n",
    "    print(sir_program)\n",
    "    file_path = \"results/selectqaoa/depolarizing_sim/02/\" + sir_program + \"-data.json\"\n",
    "    json_data = {}\n",
    "    response = None\n",
    "    qpu_run_times = []\n",
    "    pareto_fronts_building_times = []\n",
    "    for i in range(experiments):\n",
    "        final_selected_tests = []\n",
    "        cluster_dict_index = 0\n",
    "        for qubo in qubos_dictionary[sir_program]:\n",
    "            print(\"Experiment Number: \" + str(i))\n",
    "            print(\"QUBO Problem: \" + str(qubo) + \"\\nNumber: \" + str(cluster_dict_index))\n",
    "            print(\"Cluster's Test Cases: \" +str(list(clusters_dictionary[sir_program].values())[cluster_dict_index]))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(qubo)\n",
    "            print(\"RESULTS: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            qpu_run_times.append((e - s) * 1000)\n",
    "            #let's extract the selected tests\n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_tests = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_tests))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_tests:\n",
    "                selected_tests.append(list(clusters_dictionary[sir_program].values())[cluster_dict_index][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            cluster_dict_index += 1\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_selected_tests:\n",
    "                    final_selected_tests.append(selected_test)\n",
    "        i+=1\n",
    "        #now we have to build the pareto front\n",
    "        print(\"Final Selected Test Cases: \" + str(final_selected_tests))\n",
    "        print(len(final_selected_tests))\n",
    "        start = time.time()\n",
    "        pareto_front = build_pareto_front(sir_program, final_selected_tests)\n",
    "        end = time.time()\n",
    "        json_data[\"pareto_front_\" + str(i)] = pareto_front\n",
    "        pareto_front_building_time = (end - start) * 1000\n",
    "        pareto_fronts_building_times.append(pareto_front_building_time)\n",
    "\n",
    "    #compute the average time needed for the construction of a pareto frontier and run time\n",
    "    mean_qpu_run_time = statistics.mean(qpu_run_times)\n",
    "    mean_pareto_fronts_building_time = statistics.mean(pareto_fronts_building_times)\n",
    "    json_data[\"mean_qpu_run_time(ms)\"] = mean_qpu_run_time\n",
    "    json_data[\"stdev_qpu_run_time(ms)\"] = statistics.stdev(qpu_run_times)\n",
    "    json_data[\"all_qpu_run_times(ms)\"] = qpu_run_times\n",
    "    json_data[\"mean_pareto_fronts_building_time(ms)\"] = mean_pareto_fronts_building_time\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(json_data, file)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "41e0dc50b3f44546",
   "metadata": {},
   "source": [
    "noise_dep = NoiseModel()\n",
    "\n",
    "# Define a 1% depolarizing error for single-qubit and two-qubit gates\n",
    "depolarizing_error_1q = depolarizing_error(0.05, 1)  # 1% depolarizing error for single-qubit gates\n",
    "depolarizing_error_2q = depolarizing_error(0.05, 2)  # 1% depolarizing error for two-qubit gates\n",
    "\n",
    "# Add the 1% depolarizing noise to the single-qubit gates (rx and rz)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_1q, ['rx', 'rz'])\n",
    "\n",
    "# Add the 1% depolarizing noise to the two-qubit gate (cx)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_2q, ['cx'])\n",
    "\n",
    "sim_dep = AerSimulator(noise_model=noise_dep)\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "\n",
    "#I want to run the sampler 30 times to obtain different results for each sir program\n",
    "for sir_program in sir_programs:\n",
    "    #the fronts will be saved into files\n",
    "    print(sir_program)\n",
    "    file_path = \"results/selectqaoa/depolarizing_sim/05/\" + sir_program + \"-data.json\"\n",
    "    json_data = {}\n",
    "    response = None\n",
    "    qpu_run_times = []\n",
    "    pareto_fronts_building_times = []\n",
    "    for i in range(experiments):\n",
    "        final_selected_tests = []\n",
    "        cluster_dict_index = 0\n",
    "        for qubo in qubos_dictionary[sir_program]:\n",
    "            print(\"Experiment Number: \" + str(i))\n",
    "            print(\"QUBO Problem: \" + str(qubo) + \"\\nNumber: \" + str(cluster_dict_index))\n",
    "            print(\"Cluster's Test Cases: \" +str(list(clusters_dictionary[sir_program].values())[cluster_dict_index]))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(qubo)\n",
    "            print(\"RESULTS: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            qpu_run_times.append((e - s) * 1000)\n",
    "            #let's extract the selected tests\n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_tests = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_tests))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_tests:\n",
    "                selected_tests.append(list(clusters_dictionary[sir_program].values())[cluster_dict_index][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            cluster_dict_index += 1\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_selected_tests:\n",
    "                    final_selected_tests.append(selected_test)\n",
    "        i+=1\n",
    "        #now we have to build the pareto front\n",
    "        print(\"Final Selected Test Cases: \" + str(final_selected_tests))\n",
    "        print(len(final_selected_tests))\n",
    "        start = time.time()\n",
    "        pareto_front = build_pareto_front(sir_program, final_selected_tests)\n",
    "        end = time.time()\n",
    "        json_data[\"pareto_front_\" + str(i)] = pareto_front\n",
    "        pareto_front_building_time = (end - start) * 1000\n",
    "        pareto_fronts_building_times.append(pareto_front_building_time)\n",
    "\n",
    "    #compute the average time needed for the construction of a pareto frontier and run time\n",
    "    mean_qpu_run_time = statistics.mean(qpu_run_times)\n",
    "    mean_pareto_fronts_building_time = statistics.mean(pareto_fronts_building_times)\n",
    "    json_data[\"mean_qpu_run_time(ms)\"] = mean_qpu_run_time\n",
    "    json_data[\"stdev_qpu_run_time(ms)\"] = statistics.stdev(qpu_run_times)\n",
    "    json_data[\"all_qpu_run_times(ms)\"] = qpu_run_times\n",
    "    json_data[\"mean_pareto_fronts_building_time(ms)\"] = mean_pareto_fronts_building_time\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(json_data, file)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "927ce932-68b7-4a3b-a8ed-edc0e7ded093",
   "metadata": {},
   "source": [
    "## Empirical Evaluations\n",
    "From the pareto fronts obtained on 10 different repetitions (for each programme under examination), the non-dominated samples were extrapolated. In this way, for each repetition of each program, a reference front was constructed to allow comparison between the algorithms: quantum annealing, additional greedy and DIV-GA.\n",
    "For each algorithm, divided by programmes, the average number (and std. dev.) of samples in their pareto fronts was calculated. Likewise, the average number (and std. dev.) of samples from their own front present in the reference front was also calculated.\n",
    "The latter metric was subjected to the Mann-Whitney's statistical U test and then to the Vargha-Delaney's $\\hat{A}_{12}$ effect size calculation to establish its validity and statistical magnitude.\n",
    "\n",
    "The four different algorithms were compared also in terms of Hypervolume. This metric quantify the effectiveness of Pareto frontiers comparing them against an ideal one. The closer they are to the ideal frontier, the more effective they are in terms, in this implementation, of percentage of faults detection loss.\n",
    "\n",
    "Also, the execution times of the three different algorithms were stored and confronted. Since the classical and quantum components of the D-Wave's hybrid solver work synchronously, the only metric available for such a comparison was the total \"run-time\"."
   ]
  },
  {
   "cell_type": "code",
   "id": "fd4f851336f7e0fc",
   "metadata": {},
   "source": [
    "#the other sizes are uniform\n",
    "#this static information can be easily obtained from the pareto .json files\n",
    "\n",
    "qtcs_flex_pareto_sizes = [187,187,187,187,187,187,187,187,187,187]\n",
    "divga_flex_pareto_sizes = [140,140,140,140,140,140,140,140,140,140]\n",
    "qaoa_statevector_flex_pareto_sizes = [447,434,413,409,434,455,446,410,416,427]\n",
    "qaoa_ideal_flex_pareto_sizes = [517,515,518,523,516,518,505,514,518,526]\n",
    "qaoa_fakevigo_flex_pareto_sizes = [540,540,540,540,540,540,540,539,539,539]\n",
    "qaoa_noise1_flex_pareto_sizes = [539,540,540,539,540,540,539,539,539,539]\n",
    "qaoa_noise2_flex_pareto_sizes = [540,539,540,539,540,540,539,540,539,540]\n",
    "qaoa_noise5_flex_pareto_sizes = [539,539,540,540,540,539,540,540,540,539]\n",
    "greedy_flex_size = 567\n",
    "\n",
    "qtcs_grep_pareto_sizes = [229,229,230,229,230,229,230.229,230,230]\n",
    "divga_grep_pareto_sizes = [70,70,70,70,70,70,70,70,70,70]\n",
    "qaoa_statevector_grep_pareto_sizes = [485,507,504,505,489,492,489,493,489,470]\n",
    "qaoa_ideal_grep_pareto_sizes = [343,345,343,341,346,345,345,346,340,348]\n",
    "qaoa_fakevigo_grep_pareto_sizes = [321,321,321,321,321,321,321,321,321,321]\n",
    "qaoa_noise1_grep_pareto_sizes = [321,321,321,321,321,321,321,321,321,321]\n",
    "qaoa_noise2_grep_pareto_sizes = [321,321,321,321,321,321,321,321,321,321]\n",
    "qaoa_noise5_grep_pareto_sizes = [321,321,321,321,321,321,321,321,321,321]\n",
    "greedy_grep_size = 802\n",
    "\n",
    "qtcs_gzip_pareto_sizes = [87,86,85,86,87,87,86,87,85,87]\n",
    "divga_gzip_pareto_sizes = [105,105,105,105,105,105,105,105,105,105]\n",
    "qaoa_statevector_gzip_pareto_sizes = [137,143,146,144,164,143,157,144,141,169]\n",
    "qaoa_ideal_gzip_pareto_sizes = [147,146,145,146,151,155,155,151,154,156]\n",
    "qaoa_fakevigo_gzip_pareto_sizes = [168,168,166,169,168,167,167,168,168,167]\n",
    "qaoa_noise1_gzip_pareto_sizes = [167,167,167,166,168,167,166,166,168,166]\n",
    "qaoa_noise2_gzip_pareto_sizes = [166,166,168,167,166,166,166,167,167,166]\n",
    "qaoa_noise5_gzip_pareto_sizes = [169,167,167,169,168,168,168,165,167,167]\n",
    "greedy_gzip_size = 199\n",
    "\n",
    "qtcs_sed_pareto_sizes = [131,131,131,131,131,131,131,131,131,131]\n",
    "divga_sed_pareto_sizes = [105,62,105,105,102,105,105,97,105,105]\n",
    "qaoa_statevector_sed_pareto_sizes = [249,241,252,226,245,231,248,241,245,237]\n",
    "qaoa_ideal_sed_pareto_sizes = [260,251,253,263,252,263,260,256,250,253]\n",
    "qaoa_fakevigo_sed_pareto_sizes = [235,235,236,235,236,236,235,236,236,236]\n",
    "qaoa_noise1_sed_pareto_sizes = [236,235,235,235,236,236,236,235,236,235]\n",
    "qaoa_noise2_sed_pareto_sizes = [235,235,236,235,235,236,236,236,236,236]\n",
    "qaoa_noise5_sed_pareto_sizes = [236,236,235,236,236,235,235,236,236,235]\n",
    "greedy_sed_size = 356"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9ada78e44c97be4",
   "metadata": {},
   "source": [
    "def total_cost(sir_program,solution):\n",
    "    solution_cost = 0\n",
    "    \n",
    "    for test_case in solution:\n",
    "        solution_cost += test_cases_costs[sir_program][test_case]\n",
    "\n",
    "    return solution_cost\n",
    "        \n",
    "def total_coverage(sir_program,solution):\n",
    "    covered_lines = set()\n",
    "    \n",
    "    for test_case in solution:\n",
    "        try:\n",
    "            for covered_line in test_coverage_line_by_line[sir_program][test_case]:\n",
    "                covered_lines.add(covered_line)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return len(covered_lines)\n",
    "    \n",
    "def total_faults(sir_program,solution):\n",
    "    covered_faults = 0\n",
    "    \n",
    "    for test_case in solution:\n",
    "        covered_faults += faults_dictionary[sir_program][test_case]\n",
    "    \n",
    "    return covered_faults\n",
    "\n",
    "def pareto_dominance(tuple1, tuple2):\n",
    "    # Check if all conditions are satisfied\n",
    "    dominates = (\n",
    "        (tuple2[0] <= tuple1[0]) and \n",
    "        (tuple2[1] >= tuple1[1]) and \n",
    "        (tuple2[2] >= tuple1[2])\n",
    "    )\n",
    "    \n",
    "    # Check if at least one condition is strict\n",
    "    strict = (\n",
    "        (tuple2[0] < tuple1[0]) or \n",
    "        (tuple2[1] > tuple1[1]) or \n",
    "        (tuple2[2] > tuple1[2])\n",
    "    )\n",
    "    \n",
    "    # Return 1 if the second tuple dominates the first, otherwise 0\n",
    "    return 1 if dominates and strict else 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37611d4d066cd05b",
   "metadata": {},
   "source": [
    "with open('./results/add-greedy/grep_data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "    \n",
    "greedy_pareto_front = pareto_fronts_json['pareto_front']\n",
    "\n",
    "#each solution of the pareto front is a subset of the test suite\n",
    "greedy_pareto_vectors = []\n",
    "for front_solution in greedy_pareto_front:\n",
    "    #compute the fitness scores of each single solution\n",
    "    greedy_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62693154-2df4-44c5-98d4-54b1b2b2a34d",
   "metadata": {},
   "source": [
    "#here we make the same but for each of the fronts built by SelectQA and DIV-GA\n",
    "\n",
    "#the following 2 lists will contain much tuples as solutions in each of the 10 pareto fronts\n",
    "#each tuple represent the fitness value for each solution\n",
    "qtcs_pareto_vectors = []\n",
    "divga_pareto_vectors = []\n",
    "qaoa_statevector_pareto_vectors = []\n",
    "qaoa_ideal_pareto_vectors = []\n",
    "qaoa_fakevigo_pareto_vectors = []\n",
    "qaoa_noise1_pareto_vectors = []\n",
    "qaoa_noise2_pareto_vectors = []\n",
    "qaoa_noise5_pareto_vectors = []\n",
    "\n",
    "for index in range(0,10):\n",
    "    # Load the JSON file\n",
    "    with open('results/selectqa/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qtcs_pareto_front = pareto_fronts_json['pareto_front_'+str(index)]\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qtcs_pareto_front:\n",
    "        qtcs_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qtcs_pareto_vectors))\n",
    "    \n",
    "    with open('./results/divga/grep_pareto_fronts_divga.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    divga_pareto_front = pareto_fronts_json['grep_pareto_front_'+str(index)]\n",
    "    for front_solution in divga_pareto_front:\n",
    "        divga_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(divga_pareto_vectors))\n",
    "    \n",
    "    with open('results/selectqaoa/statevector_sim/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        qaoa_statevector_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    print(len(qaoa_statevector_pareto_vectors))\n",
    "    \n",
    "    with open('results/selectqaoa/ideal/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        qaoa_ideal_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qaoa_ideal_pareto_vectors))\n",
    "    \n",
    "    with open('results/selectqaoa/fake_vigo/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        qaoa_fakevigo_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qaoa_fakevigo_pareto_vectors))\n",
    "    \n",
    "    with open('results/selectqaoa/depolarizing_sim/01/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        qaoa_noise1_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qaoa_noise1_pareto_vectors))\n",
    "    \n",
    "    with open('results/selectqaoa/depolarizing_sim/02/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        qaoa_noise2_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qaoa_noise2_pareto_vectors))\n",
    "    \n",
    "    with open('results/selectqaoa/depolarizing_sim/05/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        qaoa_noise5_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qaoa_noise5_pareto_vectors))\n",
    "\n",
    "#once we have the pareto vectors from each pareto front obtained by each run, we extract \n",
    "#just the solution not dominated by anyone else\n",
    "#qtcs_pareto_vectors,divga_pareto_vectors,greedy_pareto_vectors,qaoa_ideal_pareto_vectors,qaoa_fakevigo_pareto_vectors,qaoa_noise1_pareto_vectors,qaoa_noise2_pareto_vectors,qaoa_noise5_pareto_vectors\n",
    "total_fronts = [qtcs_pareto_vectors,divga_pareto_vectors,greedy_pareto_vectors,qaoa_noise5_pareto_vectors]\n",
    "reference_pareto = []\n",
    "portions = [0,0,0,0]\n",
    "\n",
    "# get the reference frontier\n",
    "for index, front1 in enumerate(total_fronts):\n",
    "    for front_solution1 in front1:\n",
    "        is_dominated = 0\n",
    "        other_fronts = total_fronts[:index] + total_fronts[index+1:]\n",
    "        for front2 in other_fronts:\n",
    "            for front_solution2 in front2:\n",
    "                if pareto_dominance(front_solution1,front_solution2):\n",
    "                    is_dominated = 1\n",
    "                    break\n",
    "            if is_dominated:\n",
    "                break\n",
    "        if not is_dominated:\n",
    "            reference_pareto.append(front_solution1)\n",
    "            portions[index] = portions[index] + 1\n",
    "\n",
    "print(portions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "77d824ace461716a",
   "metadata": {},
   "source": [
    "# For SelectQA and DIV-GA we want to compute, for each of the 10 iterations, how many of the solutions of the i-th pareto front were selected by the reference front\n",
    "\n",
    "qtcs_non_dominated_values = []\n",
    "divga_non_dominated_values = []\n",
    "qaoa_statevector_non_dominated_values = []\n",
    "qaoa_ideal_non_dominated_values = []\n",
    "qaoa_fakevigo_non_dominated_values = []\n",
    "qaoa_noise1_non_dominated_values = []\n",
    "qaoa_noise2_non_dominated_values = []\n",
    "qaoa_noise5_non_dominated_values = []\n",
    "greedy_non_dominated = 0\n",
    "\n",
    "for index in range(0,10):\n",
    "    #print(\"Iteratrion: \" + str(index))\n",
    "    \n",
    "    qtcs_non_dominated = 0\n",
    "    divga_non_dominated = 0\n",
    "    qaoa_statevector_non_dominated = 0\n",
    "    qaoa_ideal_non_dominated = 0\n",
    "    qaoa_fakevigo_non_dominated = 0\n",
    "    qaoa_noise1_non_dominated = 0\n",
    "    qaoa_noise2_non_dominated = 0\n",
    "    qaoa_noise5_non_dominated = 0\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open('results/selectqa/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qtcs_pareto_front = pareto_fronts_json['pareto_front_'+str(index)]\n",
    "    for front_solution in qtcs_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            qtcs_non_dominated += 1\n",
    "    \n",
    "    qtcs_non_dominated_values.append(qtcs_non_dominated)\n",
    "    #print(qtcs_non_dominated)\n",
    "    \n",
    "    with open('./results/divga/grep_pareto_fronts_divga.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    divga_pareto_front = pareto_fronts_json['grep_pareto_front_'+str(index)]\n",
    "    for front_solution in divga_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            divga_non_dominated += 1\n",
    "            \n",
    "    divga_non_dominated_values.append(divga_non_dominated)\n",
    "    #print(divga_non_dominated)\n",
    "    \n",
    "    with open('results/selectqaoa/statevector_sim/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            qaoa_statevector_non_dominated += 1\n",
    "    \n",
    "    qaoa_statevector_non_dominated_values.append(qaoa_statevector_non_dominated)\n",
    "    print(qaoa_statevector_non_dominated)\n",
    "    \n",
    "    with open('results/selectqaoa/ideal/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            qaoa_ideal_non_dominated += 1\n",
    "    \n",
    "    qaoa_ideal_non_dominated_values.append(qaoa_ideal_non_dominated)\n",
    "    #print(qaoa_statevector_non_dominated)\n",
    "    \n",
    "    with open('results/selectqaoa/fake_vigo/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            qaoa_fakevigo_non_dominated += 1\n",
    "    \n",
    "    qaoa_fakevigo_non_dominated_values.append(qaoa_fakevigo_non_dominated)\n",
    "    #print(qaoa_statevector_non_dominated)\n",
    "    \n",
    "    with open('results/selectqaoa/depolarizing_sim/01/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            qaoa_noise1_non_dominated += 1\n",
    "    \n",
    "    qaoa_noise1_non_dominated_values.append(qaoa_noise1_non_dominated)\n",
    "    #print(qaoa_statevector_non_dominated)\n",
    "    \n",
    "    with open('results/selectqaoa/depolarizing_sim/02/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            qaoa_noise2_non_dominated += 1\n",
    "    \n",
    "    qaoa_noise2_non_dominated_values.append(qaoa_noise2_non_dominated)\n",
    "    #print(qaoa_statevector_non_dominated)\n",
    "    \n",
    "    with open('results/selectqaoa/depolarizing_sim/05/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(index+1)]\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "            qaoa_noise5_non_dominated += 1\n",
    "    \n",
    "    qaoa_noise5_non_dominated_values.append(qaoa_noise5_non_dominated)\n",
    "    #print(qaoa_statevector_non_dominated)\n",
    "    \n",
    "for front_solution in greedy_pareto_front:\n",
    "    if (total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)) in reference_pareto:\n",
    "        greedy_non_dominated += 1\n",
    "print(greedy_non_dominated)\n",
    "\n",
    "print(\"QTCS/DIVGA/ADD GREEDY\")\n",
    "print(\"SelectQA Non Dominated Values\")\n",
    "print(qtcs_non_dominated_values)\n",
    "print(\"SelectQA Non Dominated Mean\")\n",
    "print(statistics.mean(qtcs_non_dominated_values))\n",
    "print(\"SelectQA Non Dominated StDev\")\n",
    "print(statistics.stdev(qtcs_non_dominated_values))\n",
    "\n",
    "print(\"DIV-GA Non Dominated Values\")\n",
    "print(divga_non_dominated_values)\n",
    "print(\"DIV-GA Non Dominated Mean\")\n",
    "print(statistics.mean(divga_non_dominated_values))\n",
    "print(\"DIV-GA Non Dominated StDev\")\n",
    "print(statistics.stdev(divga_non_dominated_values))\n",
    "\n",
    "print(\"SelectQAOA Non Dominated Values (Statevector)\")\n",
    "print(qtcs_non_dominated_values)\n",
    "print(\"SelectQAOA Non Dominated Mean (Statevector)\")\n",
    "print(statistics.mean(qtcs_non_dominated_values))\n",
    "print(\"SelectQAOA Non Dominated StDev (Statevector)\")\n",
    "print(statistics.stdev(qtcs_non_dominated_values))\n",
    "\n",
    "print(\"SelectQAOA Non Dominated Values (Ideal)\")\n",
    "print(qaoa_ideal_non_dominated_values)\n",
    "print(\"SelectQAOA Non Dominated Mean (Ideal)\")\n",
    "print(statistics.mean(qaoa_ideal_non_dominated_values))\n",
    "print(\"SelectQAOA Non Dominated StDev (Ideal)\")\n",
    "print(statistics.stdev(qaoa_ideal_non_dominated_values))\n",
    "\n",
    "print(\"SelectQAOA Non Dominated Values (Fake Vigo)\")\n",
    "print(qaoa_fakevigo_non_dominated_values)\n",
    "print(\"SelectQAOA Non Dominated Mean (Fake Vigo)\")\n",
    "print(statistics.mean(qaoa_fakevigo_non_dominated_values))\n",
    "print(\"SelectQAOA Non Dominated StDev (Fake Vigo)\")\n",
    "print(statistics.stdev(qaoa_fakevigo_non_dominated_values))\n",
    "\n",
    "print(\"SelectQAOA Non Dominated Values (Depolarizing Error 1%)\")\n",
    "print(qaoa_noise1_non_dominated_values)\n",
    "print(\"SelectQAOA Non Dominated Mean (Depolarizing Error 1%)\")\n",
    "print(statistics.mean(qaoa_noise1_non_dominated_values))\n",
    "print(\"SelectQAOA Non Dominated StDev (Depolarizing Error 1%)\")\n",
    "print(statistics.stdev(qaoa_noise1_non_dominated_values))\n",
    "\n",
    "print(\"SelectQAOA Non Dominated Values (Depolarizing Error 2%)\")\n",
    "print(qaoa_noise2_non_dominated_values)\n",
    "print(\"SelectQAOA Non Dominated Mean (Depolarizing Error 2%)\")\n",
    "print(statistics.mean(qaoa_noise2_non_dominated_values))\n",
    "print(\"SelectQAOA Non Dominated StDev (Depolarizing Error 2%)\")\n",
    "print(statistics.stdev(qaoa_noise2_non_dominated_values))\n",
    "\n",
    "print(\"SelectQAOA Non Dominated Values (Depolarizing Error 5%)\")\n",
    "print(qaoa_noise5_non_dominated_values)\n",
    "print(\"SelectQAOA Non Dominated Mean (Depolarizing Error 5%)\")\n",
    "print(statistics.mean(qaoa_noise5_non_dominated_values))\n",
    "print(\"SelectQAOA Non Dominated StDev (Depolarizing Error 5%)\")\n",
    "print(statistics.stdev(qaoa_noise5_non_dominated_values))\n",
    "\n",
    "print(\"Greedy Non Dominated Values\")\n",
    "print(greedy_non_dominated)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01879508-5e39-4f21-9b83-d67f52da655b",
   "metadata": {},
   "source": [
    "# Unpack the tuples for each list\n",
    "def unpack_tuples(data):\n",
    "    return zip(*data)\n",
    "\n",
    "#qtcs_pareto_vectors,divga_pareto_vectors,greedy_pareto_vectors\n",
    "\n",
    "#x1, y1, z1 = unpack_tuples(qtcs_pareto_vectors)\n",
    "#x2, y2, z2 = unpack_tuples(divga_pareto_vectors)\n",
    "#x3, y3, z3 = unpack_tuples(greedy_pareto_vectors)\n",
    "x4, y4, z4 = unpack_tuples(qaoa_noise5_pareto_vectors)\n",
    "x5, y5, z5 = unpack_tuples(reference_pareto)\n",
    "\n",
    "# Create 3D scatter plots\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "\n",
    "\"\"\"# First plot: list1 vs list5\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(x1, y1, z1, c='r', marker='s', s=100, label='QA')\n",
    "ax1.scatter(x5, y5, z5, c='b', marker='o', s=50, label='Reference Pareto')\n",
    "ax1.set_xlabel('Cost')\n",
    "ax1.set_ylabel('Statement Coverage')\n",
    "ax1.set_zlabel('Past Faults',labelpad=0.2)\n",
    "ax1.set_title('QA vs Reference')\n",
    "ax1.legend()\n",
    "\n",
    "# Second plot: list2 vs list5\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax2.scatter(x2, y2, z2, c='g', marker='s', s=100, label='DIV-GA')\n",
    "ax2.scatter(x5, y5, z5, c='b', marker='o', s=50, label='Reference Pareto')\n",
    "ax2.set_xlabel('Cost')\n",
    "ax2.set_ylabel('Statement Coverage')\n",
    "ax2.set_zlabel('Past Faults',labelpad=0.2)\n",
    "ax2.set_title('DIV-GA vs Reference Pareto')\n",
    "ax2.legend()\n",
    "\n",
    "# Third plot: list3 vs list5\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "ax3.scatter(x3, y3, z3, c='m', marker='s', s=100, label='Add. Greedy')\n",
    "ax3.scatter(x5, y5, z5, c='b', marker='o', s=50, label='Reference Pareto')\n",
    "ax3.set_xlabel('Cost')\n",
    "ax3.set_ylabel('Statement Coverage')\n",
    "ax3.set_zlabel('Past Faults',labelpad=0.2)\n",
    "ax3.set_title('Add. Greedy vs Reference Pareto')\n",
    "ax3.legend()\"\"\"\n",
    "\n",
    "# Third plot: list4 vs list5\n",
    "ax4 = fig.add_subplot(133, projection='3d')\n",
    "ax4.scatter(x4, y4, z4, c='m', marker='s', s=100, label='QAOA')\n",
    "ax4.scatter(x5, y5, z5, c='b', marker='o', s=50, label='Reference Pareto')\n",
    "ax4.set_xlabel('Cost')\n",
    "ax4.set_ylabel('Statement Coverage')\n",
    "ax4.set_zlabel('Past Faults',labelpad=0.2)\n",
    "ax4.set_title('Ideal QAOA vs Reference Pareto')\n",
    "ax4.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf9a970b85ec96bc",
   "metadata": {},
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def interpolate_curve(curve, num_points):\n",
    "    \"\"\"Interpolate a 3D curve to have a specified number of points.\"\"\"\n",
    "    curve = np.array(curve)\n",
    "    t = np.linspace(0, 1, len(curve))\n",
    "    interp_func = interp1d(t, curve, axis=0, kind='linear')\n",
    "    t_new = np.linspace(0, 1, num_points)\n",
    "    return interp_func(t_new)\n",
    "\n",
    "def compute_area_between_curves(curve1, curve2):\n",
    "    \"\"\"Compute the approximate area between two 3D curves with different numbers of points.\"\"\"\n",
    "    # Determine the target number of points\n",
    "    num_points = max(len(curve1), len(curve2))\n",
    "    \n",
    "    # Interpolate both curves to have the same number of points\n",
    "    curve1_resampled = interpolate_curve(curve1, num_points)\n",
    "    curve2_resampled = interpolate_curve(curve2, num_points)\n",
    "    \n",
    "    # Calculate the distance between corresponding points on the two curves\n",
    "    distances = np.linalg.norm(curve1_resampled - curve2_resampled, axis=1)\n",
    "    \n",
    "    # Calculate the distance between consecutive points on the curves\n",
    "    segment_lengths = np.linalg.norm(np.diff(curve1_resampled, axis=0), axis=1)\n",
    "    \n",
    "    # Compute the approximate area using the trapezoidal rule\n",
    "    area = np.sum((distances[:-1] + distances[1:]) / 2 * segment_lengths)\n",
    "    \n",
    "    return area\n",
    "\n",
    "area_between_curves = compute_area_between_curves(qtcs_pareto_vectors, reference_pareto)\n",
    "print(\"Approximate area between the two curves:\", area_between_curves)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b43d1121f3de8f72",
   "metadata": {},
   "source": [
    "# greedy has just one frontier\n",
    "#print(\"Greedy Pareto Vectors: \" + str(greedy_pareto_vectors))\n",
    "#print(\"DIV-GA Pareto Vectors: \" + str(divga_pareto_vectors))\n",
    "#print(\"SelectQA Pareto Vectors: \" + str(qtcs_pareto_vectors))\n",
    "#total_fronts has fronts, each front has different solutions\n",
    "IH_add_greedy = greedy_pareto_vectors[0][0]\n",
    "for index, solution in enumerate(greedy_pareto_vectors):\n",
    "    if index == len(greedy_pareto_vectors) - 2:\n",
    "        break\n",
    "    IH_add_greedy += (greedy_pareto_vectors[index+1][0] - greedy_pareto_vectors[index][0]) * (1 - (greedy_pareto_vectors[index][2]/len(greedy_pareto_front[index])))\n",
    "IEC_add_greedy = IH_add_greedy/greedy_pareto_vectors[len(greedy_pareto_vectors)-1][0]\n",
    "print(\"IH Additional Greedy: \" + str(IH_add_greedy))\n",
    "print(\"IEC Additional Greedy: \" + str(IEC_add_greedy))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e472857a97fdc3a",
   "metadata": {},
   "source": [
    "IECs_qtcs = []\n",
    "IECs_divga = []\n",
    "IECs_qaoa = []\n",
    "\n",
    "for front_index in range(0,10):\n",
    "    print(\"IT Number: \" + str(front_index))\n",
    "    IH_qtcs = 0\n",
    "    IH_divga = 0\n",
    "    IEC_qtcs = 0\n",
    "    IEC_divga = 0\n",
    "    IH_qaoa = 0\n",
    "    IEC_qaoa = 0\n",
    "    # Load the JSON file\n",
    "    with open('results/selectqa/old/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qtcs_pareto_front = pareto_fronts_json['pareto_front_'+str(front_index)]\n",
    "    qtcs_pareto_vectors = []\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qtcs_pareto_front:\n",
    "        qtcs_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qtcs_pareto_vectors))\n",
    "    \n",
    "    for index, solution in enumerate(qtcs_pareto_vectors):\n",
    "        if index == len(qtcs_pareto_vectors) - 2:\n",
    "            break\n",
    "        IH_qtcs += (qtcs_pareto_vectors[index+1][0] - qtcs_pareto_vectors[index][0]) * (1 - (qtcs_pareto_vectors[index][2]/len(qtcs_pareto_front[index])))\n",
    "    IEC_qtcs = IH_qtcs/qtcs_pareto_vectors[len(qtcs_pareto_vectors)-1][0]\n",
    "    IECs_qtcs.append(IEC_qtcs)\n",
    "    qtcs_pareto_vectors = sorted(qtcs_pareto_vectors, key=lambda x: x[0])\n",
    "    print(\"IH SelectQA: \" + str(IH_qtcs))\n",
    "    print(\"IEC SelectQA: \" + str(IEC_qtcs))\n",
    "    \n",
    "    with open('./results/divga/grep_pareto_fronts_divga.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    divga_pareto_front = pareto_fronts_json['grep_pareto_front_'+str(front_index)]\n",
    "    divga_pareto_vectors = []\n",
    "    for front_solution in divga_pareto_front:\n",
    "        divga_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    divga_pareto_vectors = sorted(divga_pareto_vectors, key=lambda x: x[0])\n",
    "    #print(len(divga_pareto_vectors))\n",
    "    \n",
    "    for index, solution in enumerate(divga_pareto_vectors):\n",
    "        if index == len(divga_pareto_vectors) - 2:\n",
    "            break\n",
    "        IH_divga += (divga_pareto_vectors[index+1][0] - divga_pareto_vectors[index][0]) * (1 - (divga_pareto_vectors[index][2]/len(faults_dictionary[\"grep\"])))\n",
    "    IEC_divga = IH_divga/divga_pareto_vectors[len(divga_pareto_vectors)-1][0]\n",
    "    IECs_divga.append(IEC_divga)\n",
    "    print(\"IH DIV-GA: \" + str(IH_divga))\n",
    "    print(\"IEC DIV-GA: \" + str(IEC_divga))\n",
    "    \n",
    "    # Load the JSON file\n",
    "    with open('results/selectqaoa/statevector_sim/grep-data.json', 'r') as file:\n",
    "        pareto_fronts_json = json.load(file)\n",
    "    \n",
    "    qaoa_pareto_front = pareto_fronts_json['pareto_front_'+str(front_index+1)]\n",
    "    qaoa_pareto_vectors = []\n",
    "    #a single solution is a subset of the initial test suite\n",
    "    for front_solution in qaoa_pareto_front:\n",
    "        qaoa_pareto_vectors.append((total_cost(\"grep\",front_solution),total_coverage(\"grep\",front_solution),total_faults(\"grep\",front_solution)))\n",
    "    #print(len(qaoa_pareto_vectors))\n",
    "    \n",
    "    for index, solution in enumerate(qaoa_pareto_vectors):\n",
    "        if index == len(qaoa_pareto_vectors) - 2:\n",
    "            break\n",
    "        IH_qaoa += (qaoa_pareto_vectors[index+1][0] - qaoa_pareto_vectors[index][0]) * (1 - (qaoa_pareto_vectors[index][2]/len(qaoa_pareto_front[index])))\n",
    "    IEC_qaoa = IH_qaoa/qaoa_pareto_vectors[len(qaoa_pareto_vectors)-1][0]\n",
    "    IECs_qaoa.append(IEC_qaoa)\n",
    "    qaoa_pareto_vectors = sorted(qaoa_pareto_vectors, key=lambda x: x[0])\n",
    "    print(\"IH SelectQAOA: \" + str(IH_qaoa))\n",
    "    print(\"IEC SelectQAOA: \" + str(IEC_qaoa))\n",
    "    \n",
    "print(\"Mean IECs_qtcs: \" + str(statistics.mean(IECs_qtcs)))\n",
    "print(\"Mean IECs_divga: \" + str(statistics.mean(IECs_divga)))\n",
    "print(\"Mean IECs_qaoa: \" + str(statistics.mean(IECs_qaoa)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c077798f217ea21b",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "NON DOM SEQUENCES \n",
    "IDEAL\n",
    "qtcs_nondom_flex = [187, 187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
    "div_ga_nondom_flex = [140, 140, 140, 140, 140, 140, 140, 140, 140, 139]\n",
    "qaoa_nondom_flex = [471, 479, 479, 487, 478, 478, 468, 478, 473, 482]\n",
    "add_greedy_nondom_flex = [205,205,205,205,205,205,205,205,205,205]\n",
    "\n",
    "qtcs_nondom_grep = [10, 10, 11, 10, 11, 10, 11, 10, 11, 11]\n",
    "div_ga_nondom_grep = [70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n",
    "qaoa_nondom_grep = [376, 316, 370, 348, 327, 338, 350, 316, 358, 405]\n",
    "add_greedy_nondom_grep = [171,171,171,171,171,171,171,171,171,171]\n",
    "\n",
    "qtcs_nondom_gzip = [38, 37, 36, 37, 38, 38, 37, 38, 36, 38]\n",
    "div_ga_nondom_gzip = [105, 105, 105, 105, 105, 105, 105, 105, 105, 105]\n",
    "qaoa_nondom_gzip = [343, 345, 343, 341, 346, 345, 345, 346, 340, 348]\n",
    "add_greedy_nondom_gzip = [33,33,33,33,33,33,33,33,33,33]\n",
    "\n",
    "qtcs_nondom_sed = [110, 110, 110, 110, 110, 110, 110, 110, 110, 110]\n",
    "div_ga_nondom_sed = [95, 62, 99, 105, 90, 100, 98, 93, 103, 104]\n",
    "qaoa_nondom_sed = [192, 196, 198, 188, 194, 188, 196, 189, 195, 199]\n",
    "add_greedy_nondom_sed = [80,80,80,80,80,80,80,80,80,80]\n",
    "\n",
    "FAKE VIGO\n",
    "qtcs_nondom_flex = [187, 187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
    "div_ga_nondom_flex = [140, 140, 140, 140, 140, 140, 140, 140, 140, 140]\n",
    "qaoa_nondom_flex = [492, 492, 492, 492, 492, 492, 492, 491, 491, 491]\n",
    "add_greedy_nondom_flex = [205,205,205,205,205,205,205,205,205,205]\n",
    "\n",
    "qtcs_nondom_grep = [192, 192, 193, 192, 193, 192, 193, 192, 193, 193]\n",
    "div_ga_nondom_grep = [70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n",
    "qaoa_nondom_grep = [321, 321, 321, 321, 321, 321, 321, 321, 321, 321]\n",
    "add_greedy_nondom_grep = [177,177,177,177,177,177,177,177,177,177]\n",
    "\n",
    "qtcs_nondom_gzip = [41, 40, 39, 40, 41, 41, 40, 41, 39, 41]\n",
    "div_ga_nondom_gzip = [105, 105, 105, 105, 105, 105, 105, 105, 105, 105]\n",
    "qaoa_nondom_gzip = [95, 95, 103, 96, 95, 104, 104, 95, 95, 104]\n",
    "add_greedy_nondom_gzip = [26,26,26,26,26,26,26,26,26,26]\n",
    "\n",
    "qtcs_nondom_sed = [86, 86, 86, 86, 86, 86, 86, 86, 86, 86]\n",
    "div_ga_nondom_sed = [89, 62, 103, 101, 89, 97, 97, 94, 101, 103]\n",
    "qaoa_nondom_sed = [183, 183, 183, 183, 183, 183, 183, 183, 183, 183]\n",
    "add_greedy_nondom_sed = [80,80,80,80,80,80,80,80,80,80]\n",
    "\n",
    "NOISE 1%\n",
    "qtcs_nondom_flex = [187, 187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
    "div_ga_nondom_flex = [140, 140, 140, 140, 140, 140, 140, 140, 140, 140]\n",
    "qaoa_nondom_flex = [491, 492, 492, 491, 492, 492, 491, 491, 491, 491]\n",
    "add_greedy_nondom_flex = [205,205,205,205,205,205,205,205,205,205]\n",
    "\n",
    "qtcs_nondom_grep = [192, 192, 193, 192, 193, 192, 193, 192, 193, 193]\n",
    "div_ga_nondom_grep = [70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n",
    "qaoa_nondom_grep = [321, 321, 321, 321, 321, 321, 321, 321, 321, 321]\n",
    "add_greedy_nondom_grep = [177,177,177,177,177,177,177,177,177,177]\n",
    "\n",
    "qtcs_nondom_gzip = [41, 40, 39, 40, 41, 41, 40, 41, 39, 41]\n",
    "div_ga_nondom_gzip = [105, 105, 105, 105, 105, 105, 105, 105, 105, 105]\n",
    "qaoa_nondom_gzip = [100, 100, 76, 99, 101, 76, 99, 99, 101, 99]\n",
    "add_greedy_nondom_gzip = [26,26,26,26,26,26,26,26,26,26]\n",
    "\n",
    "qtcs_nondom_sed = [86, 86, 86, 86, 86, 86, 86, 86, 86, 86]\n",
    "div_ga_nondom_sed = [89, 62, 103, 101, 89, 97, 97, 94, 101, 103]\n",
    "qaoa_nondom_sed = [183, 183, 183, 183, 183, 183, 183, 183, 183, 183]\n",
    "add_greedy_nondom_sed = [80,80,80,80,80,80,80,80,80,80]\n",
    "\n",
    "NOISE 2%\n",
    "qtcs_nondom_flex = [187, 187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
    "div_ga_nondom_flex = [140, 140, 140, 140, 140, 140, 140, 140, 140, 140]\n",
    "qaoa_nondom_flex = [492, 491, 492, 491, 492, 492, 491, 492, 491, 492]\n",
    "add_greedy_nondom_flex = [205,205,205,205,205,205,205,205,205,205]\n",
    "\n",
    "qtcs_nondom_grep = [192, 192, 193, 192, 193, 192, 193, 192, 193, 193]\n",
    "div_ga_nondom_grep = [70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n",
    "qaoa_nondom_grep = [321, 321, 321, 321, 321, 321, 321, 321, 321, 321]\n",
    "add_greedy_nondom_grep = [177,177,177,177,177,177,177,177,177,177]\n",
    "\n",
    "qtcs_nondom_gzip = [41, 40, 39, 40, 41, 41, 40, 41, 39, 41]\n",
    "div_ga_nondom_gzip = [105, 105, 105, 105, 105, 105, 105, 105, 105, 105]\n",
    "qaoa_nondom_gzip = [99, 75, 77, 76, 99, 99, 99, 76, 76, 99]\n",
    "add_greedy_nondom_gzip = [26,26,26,26,26,26,26,26,26,26]\n",
    "\n",
    "qtcs_nondom_sed = [86, 86, 86, 86, 86, 86, 86, 86, 86, 86]\n",
    "div_ga_nondom_sed = [89, 62, 103, 101, 89, 97, 97, 94, 101, 103]\n",
    "qaoa_nondom_sed = [183, 183, 183, 183, 183, 183, 183, 183, 183, 183]\n",
    "add_greedy_nondom_sed = [80,80,80,80,80,80,80,80,80,80]\n",
    "\n",
    "NOISE 5%\n",
    "qtcs_nondom_flex = [187, 187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
    "div_ga_nondom_flex = [140, 140, 140, 140, 140, 140, 140, 140, 140, 140]\n",
    "qaoa_nondom_flex = [492, 491, 492, 491, 492, 492, 491, 492, 491, 492]\n",
    "add_greedy_nondom_flex = [205,205,205,205,205,205,205,205,205,205]\n",
    "\n",
    "qtcs_nondom_grep = [192, 192, 193, 192, 193, 192, 193, 192, 193, 193]\n",
    "div_ga_nondom_grep = [70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n",
    "qaoa_nondom_grep = [321, 321, 321, 321, 321, 321, 321, 321, 321, 321]\n",
    "add_greedy_nondom_grep = [177,177,177,177,177,177,177,177,177,177]\n",
    "\n",
    "qtcs_nondom_gzip = [41, 40, 39, 40, 41, 41, 40, 41, 39, 41]\n",
    "div_ga_nondom_gzip = [105, 105, 105, 105, 105, 105, 105, 105, 105, 105]\n",
    "qaoa_nondom_gzip = [78, 76, 100, 78, 77, 77, 77, 98, 76, 100]\n",
    "add_greedy_nondom_gzip = [26,26,26,26,26,26,26,26,26,26]\n",
    "\n",
    "qtcs_nondom_sed = [86, 86, 86, 86, 86, 86, 86, 86, 86, 86]\n",
    "div_ga_nondom_sed = [89, 62, 103, 101, 89, 97, 97, 94, 101, 103]\n",
    "qaoa_nondom_sed = [183, 183, 183, 183, 183, 183, 183, 183, 183, 183]\n",
    "add_greedy_nondom_sed = [80,80,80,80,80,80,80,80,80,80]\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4cc05bbf4e37a2",
   "metadata": {},
   "source": [
    "#the static values below have been manually stored after each run of the experiments\n",
    "\n",
    "qtcs_nondom_flex = [187, 187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
    "div_ga_nondom_flex = [140, 140, 140, 140, 140, 140, 140, 140, 140, 140]\n",
    "qaoa_nondom_flex = [492, 491, 492, 491, 492, 492, 491, 492, 491, 492]\n",
    "add_greedy_nondom_flex = [205,205,205,205,205,205,205,205,205,205]\n",
    "\n",
    "qtcs_nondom_grep = [192, 192, 193, 192, 193, 192, 193, 192, 193, 193]\n",
    "div_ga_nondom_grep = [70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n",
    "qaoa_nondom_grep = [321, 321, 321, 321, 321, 321, 321, 321, 321, 321]\n",
    "add_greedy_nondom_grep = [177,177,177,177,177,177,177,177,177,177]\n",
    "\n",
    "qtcs_nondom_gzip = [41, 40, 39, 40, 41, 41, 40, 41, 39, 41]\n",
    "div_ga_nondom_gzip = [105, 105, 105, 105, 105, 105, 105, 105, 105, 105]\n",
    "qaoa_nondom_gzip = [78, 76, 100, 78, 77, 77, 77, 98, 76, 100]\n",
    "add_greedy_nondom_gzip = [26,26,26,26,26,26,26,26,26,26]\n",
    "\n",
    "qtcs_nondom_sed = [86, 86, 86, 86, 86, 86, 86, 86, 86, 86]\n",
    "div_ga_nondom_sed = [89, 62, 103, 101, 89, 97, 97, 94, 101, 103]\n",
    "qaoa_nondom_sed = [183, 183, 183, 183, 183, 183, 183, 183, 183, 183]\n",
    "add_greedy_nondom_sed = [80,80,80,80,80,80,80,80,80,80]\n",
    "\n",
    "lists = [qtcs_nondom_flex,div_ga_nondom_flex,qaoa_nondom_flex,qtcs_nondom_grep,div_ga_nondom_grep,qaoa_nondom_grep,qtcs_nondom_gzip,div_ga_nondom_gzip,qaoa_nondom_gzip,qtcs_nondom_sed,div_ga_nondom_sed,qaoa_nondom_sed]\n",
    "\n",
    "# we are interested in knowing if the obtained sequences are normally distributed to decide what statistical test we should apply\n",
    "for i, list in enumerate(lists, start=1):\n",
    "    stat, p_value = shapiro(list)\n",
    "    print(f\"List {i}: Statistic = {stat:.5f}, P-value = {p_value:.5f}\")\n",
    "    \n",
    "    # check if the sequence is normally distributed (using 0.05 as threshold)\n",
    "    if p_value > 0.05:\n",
    "        print(f\"List {i} seems to be normally distributed (p-value = {p_value:.5f})\")\n",
    "    else:\n",
    "        print(f\"List {i} NOT seems to be normally distributed (p-value = {p_value:.5f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1363080a",
   "metadata": {},
   "source": [
    "def a12(lst1,lst2,rev=True):\n",
    "  \"how often is x in lst1 more than y in lst2?\"\n",
    "  more = same = 0.0\n",
    "  for x in lst1:\n",
    "    for y in lst2:\n",
    "      if x==y : same += 1\n",
    "      elif rev and x > y : more += 1\n",
    "      elif not rev and x < y : more += 1\n",
    "  return (more + 0.5*same)  / (len(lst1)*len(lst2))\n",
    "\n",
    "def stat_test(app1, app2):\n",
    "    statistic, pvalue = mannwhitneyu(app1, app2, alternative='greater')\n",
    "\n",
    "    # Calculate the A12 effect size using Vargha and Delaney's formula\n",
    "    a12_effect_size = a12(app1, app2)\n",
    "\n",
    "    return pvalue, a12_effect_size\n",
    "\n",
    "p_value, a_12 = stat_test(div_ga_nondom_gzip,qaoa_nondom_gzip)\n",
    "print(\"p_value: \" + str(p_value))\n",
    "print(\"a12: \" + str(a_12))\n",
    "#5.8493119157503726e-05"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5adc0727-1230-43c8-8e54-e3de645c1029",
   "metadata": {},
   "source": [
    "with open('./results/add-greedy/sed_data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "greedy_execution_time = pareto_fronts_json['resolution_time(ms)']\n",
    "print(\"Greedy Execution Time\")\n",
    "print(greedy_execution_time)\n",
    "\n",
    "with open('results/selectqa/old/sed-data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "qtcs_qpu_execution_time = pareto_fronts_json['mean_qpu_run_time(ms)']\n",
    "qtcs_pareto_building_time = pareto_fronts_json['mean_pareto_fronts_building_time(ms)']\n",
    "print(\"SelectQA QPU Execution Time\")\n",
    "print(qtcs_qpu_execution_time)\n",
    "print(\"SelectQA Pareto Building Time\")\n",
    "print(qtcs_pareto_building_time)\n",
    "\n",
    "with open('./results/divga/sed_pareto_fronts_divga.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "divga_execution_time = pareto_fronts_json['DIVGA_II_mean_execution_time_ms']\n",
    "print(\"DIV-GA Execution Time\")\n",
    "print(divga_execution_time)\n",
    "\n",
    "\"\"\"with open('results/selectqaoa/statevector_sim/sed-data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "qaoa_qpu_execution_time = pareto_fronts_json['mean_qpu_run_time(ms)']\n",
    "qaoa_pareto_building_time = pareto_fronts_json['mean_pareto_fronts_building_time(ms)']\n",
    "print(qaoa_qpu_execution_time)\n",
    "print(qaoa_pareto_building_time)\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e389bcaa1ac9dc93",
   "metadata": {},
   "source": [
    "with open('results/selectqaoa/ideal/sed-data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "qaoa_qpu_execution_time = pareto_fronts_json['mean_qpu_run_time(ms)']\n",
    "qaoa_pareto_building_time = pareto_fronts_json['mean_pareto_fronts_building_time(ms)']\n",
    "print(\"SelectQAOA Execution Time (Ideal)\")\n",
    "print(qaoa_qpu_execution_time)\n",
    "print(\"SelectQAOA Pareto Building Time (Ideal)\")\n",
    "print(qaoa_pareto_building_time)\n",
    "\n",
    "with open('results/selectqaoa/fake_vigo/sed-data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "qaoa_qpu_execution_time = pareto_fronts_json['mean_qpu_run_time(ms)']\n",
    "qaoa_pareto_building_time = pareto_fronts_json['mean_pareto_fronts_building_time(ms)']\n",
    "print(\"SelectQAOA Execution Time (Fake Vigo)\")\n",
    "print(qaoa_qpu_execution_time)\n",
    "print(\"SelectQAOA Pareto Building Time (Fake Vigo)\")\n",
    "print(qaoa_pareto_building_time)\n",
    "\n",
    "with open('results/selectqaoa/depolarizing_sim/01/sed-data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "qaoa_qpu_execution_time = pareto_fronts_json['mean_qpu_run_time(ms)']\n",
    "qaoa_pareto_building_time = pareto_fronts_json['mean_pareto_fronts_building_time(ms)']\n",
    "print(\"SelectQAOA Execution Time (Depolarizing Error 1%)\")\n",
    "print(qaoa_qpu_execution_time)\n",
    "print(\"SelectQAOA Pareto Building Time (Depolarizing Error 1%)\")\n",
    "print(qaoa_pareto_building_time)\n",
    "\n",
    "with open('results/selectqaoa/depolarizing_sim/02/sed-data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "qaoa_qpu_execution_time = pareto_fronts_json['mean_qpu_run_time(ms)']\n",
    "qaoa_pareto_building_time = pareto_fronts_json['mean_pareto_fronts_building_time(ms)']\n",
    "print(\"SelectQAOA Execution Time (Depolarizing Error 2%)\")\n",
    "print(qaoa_qpu_execution_time)\n",
    "print(\"SelectQAOA Pareto Building Time (Depolarizing Error 2%)\")\n",
    "print(qaoa_pareto_building_time)\n",
    "\n",
    "with open('results/selectqaoa/depolarizing_sim/05/sed-data.json', 'r') as file:\n",
    "    pareto_fronts_json = json.load(file)\n",
    "\n",
    "qaoa_qpu_execution_time = pareto_fronts_json['mean_qpu_run_time(ms)']\n",
    "qaoa_pareto_building_time = pareto_fronts_json['mean_pareto_fronts_building_time(ms)']\n",
    "print(\"SelectQAOA Execution Time (Depolarizing Error 5%)\")\n",
    "print(qaoa_qpu_execution_time)\n",
    "print(\"SelectQAOA Pareto Building Time (Depolarizing Error 5%)\")\n",
    "print(qaoa_pareto_building_time)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ed58fef23cbc91f",
   "metadata": {},
   "source": [
    "## BootQA\n",
    "\n",
    "BootQA is the first approach to a test case optimization problem using quantum computing. BootQA relies on real-world industrial datasets:\n",
    "\n",
    "- PaintControl: dataset gathered from ABB Robotics Norway;\n",
    "- GSDTSR: dataset gathered from Google.\n",
    "\n",
    " Each test case in both the datasets has values related to the properties:\n",
    " \n",
    "- \"execution time\": time needed by the test case to be executed;\n",
    "- \"failure rate\": the ability, in percentage, of a test case to spot a failure.\n",
    "\n",
    "To deal with physical limitations of quantum annealers, BootQA randomly divides the problem into m sub-problems of size n; once it has obtained the m sub-solutions, BootQA merges them into one final solution.\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "To compare SelectQA and BootQA were executed 10 indipendent experiments for each dataset. The resulting suites (10 for each dataset) were directly confronted in terms of \"execution time\" and \"failure rate\". The statistical tests used the same methods used for the previous comparisons.\n",
    "\n",
    "To compare the efficiency of the two methods, has been use the \"QPU Access Time\" metric."
   ]
  },
  {
   "cell_type": "code",
   "id": "5cce857b18a69eed",
   "metadata": {},
   "source": [
    "def bootstrap_confidence_interval(data, num_samples, confidence_alpha=0.95):\n",
    "    \"\"\"This function determines the statistical range within we would expect the mean value of execution times to fall; it relies on the bootstrapping strategy, which allows the calculation of the confidence interval by repeated sampling (with replacement) from the existing data to obtain an estimate of the confidence interval.\"\"\"\n",
    "    sample_means = []\n",
    "    for _ in range(num_samples):\n",
    "        bootstrap_sample = [random.choice(data) for _ in range(len(data))]\n",
    "        sample_mean = np.mean(bootstrap_sample)\n",
    "        sample_means.append(sample_mean)\n",
    "    \n",
    "    lower_percentile = (1 - confidence_alpha) / 2 * 100\n",
    "    upper_percentile = (confidence_alpha + (1 - confidence_alpha) / 2) * 100\n",
    "    lower_bound = np.percentile(sample_means, lower_percentile)\n",
    "    upper_bound = np.percentile(sample_means, upper_percentile)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "846f18771ca2956d",
   "metadata": {},
   "source": [
    "def make_linear_terms_bootqa(cluster_test_cases, test_cases_costs, test_cases_rates, alpha):\n",
    "    max_cost = max(test_cases_costs)\n",
    "    \n",
    "    estimated_costs = []\n",
    "\n",
    "    #linear coefficients, that are the diagonal of the matrix encoding the QUBO\n",
    "    for test_case in cluster_test_cases:\n",
    "        estimated_costs.append((alpha * ((test_cases_costs[test_case])/max_cost)) - ((1-alpha)*test_cases_rates[test_case]))\n",
    "    \n",
    "    return np.array(estimated_costs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d5209356b015e7dd",
   "metadata": {},
   "source": [
    "def create_linear_qubo(linear_terms):\n",
    "    \"\"\"This function is the one that has to encode the QUBO problem that QAOA will have to solve. The QUBO problem specifies the optimization to solve and a quadratic binary unconstrained problem\"\"\"\n",
    "    qubo = QuadraticProgram()\n",
    "    \n",
    "    for i in range(0,len(linear_terms)):\n",
    "        qubo.binary_var('x%s' % (i))\n",
    "\n",
    "    qubo.minimize(linear=linear_terms)\n",
    "\n",
    "    return qubo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3f636fd6c3c18d3",
   "metadata": {},
   "source": [
    "def get_data(data_name):\n",
    "    data = pd.read_csv(\"datasets/boot_qa_datasets/\" + data_name + \".csv\", dtype={\"time\": float, \"rate\": float})\n",
    "    data = data[data['rate'] > 0]\n",
    "    return data\n",
    "\n",
    "bootqa_programs = [\"gsdtsr\",\"paintcontrol\"]\n",
    "bootqa_clusters = dict()\n",
    "\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    \n",
    "    # Total suite metrics\n",
    "    test_cases_costs = data[\"time\"].tolist()\n",
    "    test_cases_rates = data[\"rate\"].tolist()\n",
    "    print(f\"Tot suite cost: {sum(test_cases_costs)}\")\n",
    "    print(f\"Tot suite rate: {sum(test_cases_rates)}\")\n",
    "        \n",
    "    # Normalize data\n",
    "    cluster_data = np.column_stack((test_cases_costs, test_cases_rates))\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(cluster_data)\n",
    "    \n",
    "    if bootqa_program == \"gsdtsr\":\n",
    "        num_clusters = 40\n",
    "    else:\n",
    "        num_clusters = 20\n",
    "    \n",
    "    start = time.time()\n",
    "    linkage_matrix = linkage(normalized_data, method='ward')\n",
    "    clusters = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "    \n",
    "    # Organize test cases by cluster and split large clusters\n",
    "    clustered_data = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        clustered_data[cluster_id].append(idx)\n",
    "        \n",
    "    # Process clusters to split large ones into 3 parts if they exceed 30 elements\n",
    "    new_cluster_id = max(clustered_data.keys()) + 1  # Start new IDs after existing ones\n",
    "    to_add = []  # To collect new smaller clusters for adding\n",
    "    \n",
    "    for cluster_id, elements in list(clustered_data.items()):  # Use list() to avoid modifying during iteration\n",
    "        if len(elements) > 24:\n",
    "            # Split into 3 parts\n",
    "            split_size = max(1, len(elements) // 3)  # Calculate split size, ensuring minimum size of 1\n",
    "            parts = [elements[i:i + split_size] for i in range(0, len(elements), split_size)]\n",
    "    \n",
    "            # Ensure we end up with exactly 3 parts\n",
    "            while len(parts) < 3:\n",
    "                parts.append([])  # Add empty parts if fewer than 3\n",
    "    \n",
    "            # Add new parts to to_add list\n",
    "            to_add.extend(parts[:3])\n",
    "    \n",
    "            # Remove original large cluster\n",
    "            del clustered_data[cluster_id]\n",
    "    \n",
    "    # Add new clusters to clustered_data with new IDs\n",
    "    for part in to_add:\n",
    "        if part:  # Only add if the part is non-empty\n",
    "            clustered_data[new_cluster_id] = part\n",
    "            new_cluster_id += 1\n",
    "    end = time.time()\n",
    "    print(\"SelectQAOA Decomposition Time(ms): \" + str((end-start)*1000))\n",
    "    \n",
    "    bootqa_clusters[bootqa_program] = clustered_data\n",
    "    \n",
    "    # Step 3: Calculate the metrics for each refined cluster\n",
    "    cluster_metrics = {}\n",
    "    for cluster_id, members in clustered_data.items():\n",
    "        tot_cluster_costs = sum(test_cases_costs[i] for i in members)\n",
    "        tot_cluster_rates = sum(test_cases_rates[i] for i in members)\n",
    "        cluster_metrics[cluster_id] = {\n",
    "            \"tot_cluster_cost\": tot_cluster_costs,\n",
    "            \"tot_cluster_rates\": tot_cluster_rates\n",
    "        }\n",
    "        print(f\"Cluster {cluster_id + 1} metrics:\")\n",
    "        print(f\"Test Cases: {members}\")\n",
    "        print(f\" - Num. Test Cases: {len(members):.2f}\")\n",
    "        print(f\" - Execution Cost: {tot_cluster_costs:.2f}\")\n",
    "        print(f\" - Failure Rate: {tot_cluster_rates}\")\n",
    "    \n",
    "    print(\"===========================================================================\")    \n",
    "    \n",
    "    for cluster_id in clustered_data.keys():\n",
    "        if len(clustered_data[cluster_id]) > 24:\n",
    "            print(\"Program: \" + bootqa_program)\n",
    "            print(\"Test cases of cluster \" + str(cluster_id) + \": \" + str(len(clustered_data[cluster_id])))\n",
    "    \n",
    "    # Plotting the clusters in 3D space\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Extracting data for plotting\n",
    "    exec_costs = np.array(test_cases_costs)\n",
    "    rates = np.array(test_cases_rates)\n",
    "    \n",
    "    # Plot each refined cluster with a different color\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(clustered_data))  # A colormap with as many colors as clusters\n",
    "    for cluster_id, members in clustered_data.items():\n",
    "        ax.scatter(\n",
    "            exec_costs[members], \n",
    "            rates[members], \n",
    "            color=colors(cluster_id % 10), \n",
    "            label=f\"Cluster {cluster_id + 1}\"\n",
    "        )\n",
    "    \n",
    "    # Label the axes\n",
    "    ax.set_xlabel(\"Execution Cost\")\n",
    "    ax.set_ylabel(\"Failure Rate\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Test Case Clustering Visualization\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "95b138e553222615",
   "metadata": {},
   "source": [
    "### Statevector Simulator"
   ]
  },
  {
   "cell_type": "code",
   "id": "1dc0f4aa-da57-42e3-9dc2-de9f8089400c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "bootqa_alphas = {\"gsdtsr\": 98,\"paintcontrol\": 0.90}\n",
    "run_times_dictionary = {\"gsdtsr\": [],\"paintcontrol\": []}\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "backend = Aer.get_backend(\"statevector_simulator\")\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=backend), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)\n",
    "\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    # Total suite metrics\n",
    "    test_cases_costs = data[\"time\"].tolist()\n",
    "    test_cases_rates = data[\"rate\"].tolist()\n",
    "    \n",
    "    final_test_suite_costs = []\n",
    "    final_failure_rates = []\n",
    "    for i in range(10):\n",
    "        final_selected_cases = []\n",
    "        cluster_number = 0\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "            linear_terms = make_linear_terms_bootqa(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(linear_qubo)\n",
    "            print(\"QAOA Result: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            run_times_dictionary[bootqa_program].append((e-s)*1000)\n",
    "            \n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_cases = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_cases))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_cases:\n",
    "                selected_tests.append(bootqa_clusters[bootqa_program][cluster_id][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_test_suite_costs:\n",
    "                    final_selected_cases.append(selected_test)\n",
    "            \n",
    "        #compute the final test suite cost\n",
    "        final_test_suite_cost = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_test_suite_cost += test_cases_costs[selected_test_case]\n",
    "        final_test_suite_costs.append(final_test_suite_cost)\n",
    "            \n",
    "        #compute the total failure rate\n",
    "        final_failure_rate = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_failure_rate += test_cases_rates[selected_test_case]\n",
    "        final_failure_rates.append(final_failure_rate)\n",
    "    \n",
    "    print(\"Final Test Suite: \" + str(final_selected_cases))\n",
    "    #compute the qpu access times\n",
    "    qpu_run_times_without_zeros = []\n",
    "    for access_time in run_times_dictionary[bootqa_program]:\n",
    "      if access_time != 0:\n",
    "        qpu_run_times_without_zeros.append(access_time)\n",
    "    lower_bound, upper_bound = bootstrap_confidence_interval(qpu_run_times_without_zeros, 1000, 0.95)\n",
    "    for i in range(len(run_times_dictionary[bootqa_program])):\n",
    "      if run_times_dictionary[bootqa_program][i] == 0:\n",
    "          run_times_dictionary[bootqa_program][i] = upper_bound\n",
    "    average_qpu_access_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    \n",
    "    var_names = [\"final_test_suite_costs\", \"final_failure_rates\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound()\"]\n",
    "    values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "              statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "              lower_bound, upper_bound]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = \"results/selectqaoa/statevector_sim\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to save the file\n",
    "    file_path = os.path.join(output_dir, f\"{bootqa_program}.csv\")\n",
    "    \n",
    "    # Writing results to the file\n",
    "    with open(file_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "    print(f\"Results saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c603089358add45",
   "metadata": {},
   "source": [
    "## Ideal Aer Simulator"
   ]
  },
  {
   "cell_type": "code",
   "id": "12bc23d05ffe997c",
   "metadata": {},
   "source": [
    "bootqa_alphas = {\"gsdtsr\": 0.98,\"paintcontrol\": 0.90}\n",
    "run_times_dictionary = {\"gsdtsr\": [],\"paintcontrol\": []}\n",
    "\n",
    "sim_ideal = AerSimulator()\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_ideal), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    # Total suite metrics\n",
    "    test_cases_costs = data[\"time\"].tolist()\n",
    "    test_cases_rates = data[\"rate\"].tolist()\n",
    "    \n",
    "    final_test_suite_costs = []\n",
    "    final_failure_rates = []\n",
    "    for i in range(10):\n",
    "        final_selected_cases = []\n",
    "        cluster_number = 0\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "            linear_terms = make_linear_terms_bootqa(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(linear_qubo)\n",
    "            print(\"QAOA Result: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            run_times_dictionary[bootqa_program].append((e-s)*1000)\n",
    "            \n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_cases = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_cases))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_cases:\n",
    "                selected_tests.append(bootqa_clusters[bootqa_program][cluster_id][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_test_suite_costs:\n",
    "                    final_selected_cases.append(selected_test)\n",
    "            \n",
    "        #compute the final test suite cost\n",
    "        final_test_suite_cost = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_test_suite_cost += test_cases_costs[selected_test_case]\n",
    "        final_test_suite_costs.append(final_test_suite_cost)\n",
    "            \n",
    "        #compute the total failure rate\n",
    "        final_failure_rate = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_failure_rate += test_cases_rates[selected_test_case]\n",
    "        final_failure_rates.append(final_failure_rate)\n",
    "    \n",
    "    print(\"Final Test Suite: \" + str(final_selected_cases))\n",
    "    #compute the qpu access times\n",
    "    qpu_run_times_without_zeros = []\n",
    "    for access_time in run_times_dictionary[bootqa_program]:\n",
    "      if access_time != 0:\n",
    "        qpu_run_times_without_zeros.append(access_time)\n",
    "    lower_bound, upper_bound = bootstrap_confidence_interval(qpu_run_times_without_zeros, 1000, 0.95)\n",
    "    for i in range(len(run_times_dictionary[bootqa_program])):\n",
    "      if run_times_dictionary[bootqa_program][i] == 0:\n",
    "          run_times_dictionary[bootqa_program][i] = upper_bound\n",
    "    average_qpu_access_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    \n",
    "    var_names = [\"final_test_suite_costs\", \"final_failure_rates\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound()\"]\n",
    "    values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "              statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "              lower_bound, upper_bound]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = \"results/selectqaoa/ideal\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to save the file\n",
    "    file_path = os.path.join(output_dir, f\"{bootqa_program}.csv\")\n",
    "    \n",
    "    # Writing results to the file\n",
    "    with open(file_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "    print(f\"Results saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "61af3d3afde081b",
   "metadata": {},
   "source": [
    "## Fake Vigo Noise Simulator"
   ]
  },
  {
   "cell_type": "code",
   "id": "edab03cf4dfcc5f6",
   "metadata": {},
   "source": [
    "bootqa_alphas = {\"gsdtsr\": 0.98,\"paintcontrol\": 0.90}\n",
    "run_times_dictionary = {\"gsdtsr\": [],\"paintcontrol\": []}\n",
    "\n",
    "device_backend = FakeVigoV2()\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=device_backend), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "bootqa_programs = [\"gsdtsr\"]\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    # Total suite metrics\n",
    "    test_cases_costs = data[\"time\"].tolist()\n",
    "    test_cases_rates = data[\"rate\"].tolist()\n",
    "    \n",
    "    final_test_suite_costs = []\n",
    "    final_failure_rates = []\n",
    "    for i in range(10):\n",
    "        final_selected_cases = []\n",
    "        cluster_number = 0\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "            linear_terms = make_linear_terms_bootqa(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(linear_qubo)\n",
    "            print(\"Program: \" + str(bootqa_program) + \". It: \" + str(i))\n",
    "            print(\"QAOA Result: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            run_times_dictionary[bootqa_program].append((e-s)*1000)\n",
    "            \n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_cases = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_cases))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_cases:\n",
    "                selected_tests.append(bootqa_clusters[bootqa_program][cluster_id][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_test_suite_costs:\n",
    "                    final_selected_cases.append(selected_test)\n",
    "            \n",
    "        #compute the final test suite cost\n",
    "        final_test_suite_cost = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_test_suite_cost += test_cases_costs[selected_test_case]\n",
    "        final_test_suite_costs.append(final_test_suite_cost)\n",
    "            \n",
    "        #compute the total failure rate\n",
    "        final_failure_rate = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_failure_rate += test_cases_rates[selected_test_case]\n",
    "        final_failure_rates.append(final_failure_rate)\n",
    "    \n",
    "    print(\"Final Test Suite: \" + str(final_selected_cases))\n",
    "    #compute the qpu access times\n",
    "    qpu_run_times_without_zeros = []\n",
    "    for access_time in run_times_dictionary[bootqa_program]:\n",
    "      if access_time != 0:\n",
    "        qpu_run_times_without_zeros.append(access_time)\n",
    "    lower_bound, upper_bound = bootstrap_confidence_interval(qpu_run_times_without_zeros, 1000, 0.95)\n",
    "    for i in range(len(run_times_dictionary[bootqa_program])):\n",
    "      if run_times_dictionary[bootqa_program][i] == 0:\n",
    "          run_times_dictionary[bootqa_program][i] = upper_bound\n",
    "    average_qpu_access_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    \n",
    "    var_names = [\"final_test_suite_costs\", \"final_failure_rates\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound()\"]\n",
    "    values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "              statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "              lower_bound, upper_bound]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = \"results/selectqaoa/fake_vigo\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to save the file\n",
    "    file_path = os.path.join(output_dir, f\"{bootqa_program}.csv\")\n",
    "    \n",
    "    # Writing results to the file\n",
    "    with open(file_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "    print(f\"Results saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bdaac2eb4df95a77",
   "metadata": {},
   "source": [
    "## Depolarizing Error Simulator"
   ]
  },
  {
   "cell_type": "code",
   "id": "59773f7ef37eb27f",
   "metadata": {},
   "source": [
    "bootqa_alphas = {\"gsdtsr\": 0.98,\"paintcontrol\": 0.90}\n",
    "run_times_dictionary = {\"gsdtsr\": [],\"paintcontrol\": []}\n",
    "\n",
    "noise_dep = NoiseModel()\n",
    "\n",
    "# Define a 1% depolarizing error for single-qubit and two-qubit gates\n",
    "depolarizing_error_1q = depolarizing_error(0.01, 1)  # 1% depolarizing error for single-qubit gates\n",
    "depolarizing_error_2q = depolarizing_error(0.01, 2)  # 1% depolarizing error for two-qubit gates\n",
    "\n",
    "# Add the 1% depolarizing noise to the single-qubit gates (rx and rz)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_1q, ['rx', 'rz'])\n",
    "\n",
    "# Add the 1% depolarizing noise to the two-qubit gate (cx)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_2q, ['cx'])\n",
    "\n",
    "sim_dep = AerSimulator(noise_model=noise_dep)\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "bootqa_programs = [\"gsdtsr\"]\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    # Total suite metrics\n",
    "    test_cases_costs = data[\"time\"].tolist()\n",
    "    test_cases_rates = data[\"rate\"].tolist()\n",
    "    \n",
    "    final_test_suite_costs = []\n",
    "    final_failure_rates = []\n",
    "    for i in range(10):\n",
    "        final_selected_cases = []\n",
    "        cluster_number = 0\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "            linear_terms = make_linear_terms_bootqa(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(linear_qubo)\n",
    "            print(\"Program: \" + str(bootqa_program) + \". It: \" + str(i))\n",
    "            print(\"QAOA Result: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            run_times_dictionary[bootqa_program].append((e-s)*1000)\n",
    "            \n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_cases = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_cases))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_cases:\n",
    "                selected_tests.append(bootqa_clusters[bootqa_program][cluster_id][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_test_suite_costs:\n",
    "                    final_selected_cases.append(selected_test)\n",
    "            \n",
    "        #compute the final test suite cost\n",
    "        final_test_suite_cost = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_test_suite_cost += test_cases_costs[selected_test_case]\n",
    "        final_test_suite_costs.append(final_test_suite_cost)\n",
    "            \n",
    "        #compute the total failure rate\n",
    "        final_failure_rate = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_failure_rate += test_cases_rates[selected_test_case]\n",
    "        final_failure_rates.append(final_failure_rate)\n",
    "    \n",
    "    print(\"Final Test Suite: \" + str(final_selected_cases))\n",
    "    #compute the qpu access times\n",
    "    qpu_run_times_without_zeros = []\n",
    "    for access_time in run_times_dictionary[bootqa_program]:\n",
    "      if access_time != 0:\n",
    "        qpu_run_times_without_zeros.append(access_time)\n",
    "    lower_bound, upper_bound = bootstrap_confidence_interval(qpu_run_times_without_zeros, 1000, 0.95)\n",
    "    for i in range(len(run_times_dictionary[bootqa_program])):\n",
    "      if run_times_dictionary[bootqa_program][i] == 0:\n",
    "          run_times_dictionary[bootqa_program][i] = upper_bound\n",
    "    average_qpu_access_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    \n",
    "    var_names = [\"final_test_suite_costs\", \"final_failure_rates\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound()\"]\n",
    "    values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "              statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "              lower_bound, upper_bound]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = \"results/selectqaoa/depolarizing_sim/01\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to save the file\n",
    "    file_path = os.path.join(output_dir, f\"{bootqa_program}.csv\")\n",
    "    \n",
    "    # Writing results to the file\n",
    "    with open(file_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "    print(f\"Results saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1866e5d1144d73d7",
   "metadata": {},
   "source": [
    "bootqa_alphas = {\"gsdtsr\": 0.98,\"paintcontrol\": 0.90}\n",
    "run_times_dictionary = {\"gsdtsr\": [],\"paintcontrol\": []}\n",
    "\n",
    "noise_dep = NoiseModel()\n",
    "\n",
    "# Define a 1% depolarizing error for single-qubit and two-qubit gates\n",
    "depolarizing_error_1q = depolarizing_error(0.02, 1)  # 2% depolarizing error for single-qubit gates\n",
    "depolarizing_error_2q = depolarizing_error(0.02, 2)  # 2% depolarizing error for two-qubit gates\n",
    "\n",
    "# Add the 1% depolarizing noise to the single-qubit gates (rx and rz)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_1q, ['rx', 'rz'])\n",
    "\n",
    "# Add the 1% depolarizing noise to the two-qubit gate (cx)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_2q, ['cx'])\n",
    "\n",
    "sim_dep = AerSimulator(noise_model=noise_dep)\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "bootqa_programs = [\"gsdtsr\"]\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    # Total suite metrics\n",
    "    test_cases_costs = data[\"time\"].tolist()\n",
    "    test_cases_rates = data[\"rate\"].tolist()\n",
    "    \n",
    "    final_test_suite_costs = []\n",
    "    final_failure_rates = []\n",
    "    for i in range(10):\n",
    "        final_selected_cases = []\n",
    "        cluster_number = 0\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "            linear_terms = make_linear_terms_bootqa(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(linear_qubo)\n",
    "            print(\"Program: \" + str(bootqa_program) + \". It: \" + str(i))\n",
    "            print(\"QAOA Result: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            run_times_dictionary[bootqa_program].append((e-s)*1000)\n",
    "            \n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_cases = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_cases))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_cases:\n",
    "                selected_tests.append(bootqa_clusters[bootqa_program][cluster_id][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_test_suite_costs:\n",
    "                    final_selected_cases.append(selected_test)\n",
    "            \n",
    "        #compute the final test suite cost\n",
    "        final_test_suite_cost = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_test_suite_cost += test_cases_costs[selected_test_case]\n",
    "        final_test_suite_costs.append(final_test_suite_cost)\n",
    "            \n",
    "        #compute the total failure rate\n",
    "        final_failure_rate = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_failure_rate += test_cases_rates[selected_test_case]\n",
    "        final_failure_rates.append(final_failure_rate)\n",
    "    \n",
    "    print(\"Final Test Suite: \" + str(final_selected_cases))\n",
    "    #compute the qpu access times\n",
    "    qpu_run_times_without_zeros = []\n",
    "    for access_time in run_times_dictionary[bootqa_program]:\n",
    "      if access_time != 0:\n",
    "        qpu_run_times_without_zeros.append(access_time)\n",
    "    lower_bound, upper_bound = bootstrap_confidence_interval(qpu_run_times_without_zeros, 1000, 0.95)\n",
    "    for i in range(len(run_times_dictionary[bootqa_program])):\n",
    "      if run_times_dictionary[bootqa_program][i] == 0:\n",
    "          run_times_dictionary[bootqa_program][i] = upper_bound\n",
    "    average_qpu_access_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    \n",
    "    var_names = [\"final_test_suite_costs\", \"final_failure_rates\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound()\"]\n",
    "    values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "              statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "              lower_bound, upper_bound]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = \"results/selectqaoa/depolarizing_sim/02\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to save the file\n",
    "    file_path = os.path.join(output_dir, f\"{bootqa_program}.csv\")\n",
    "    \n",
    "    # Writing results to the file\n",
    "    with open(file_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "    print(f\"Results saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3831e7f5a8bae7e2",
   "metadata": {},
   "source": [
    "bootqa_alphas = {\"gsdtsr\": 0.98,\"paintcontrol\": 0.90}\n",
    "run_times_dictionary = {\"gsdtsr\": [],\"paintcontrol\": []}\n",
    "\n",
    "noise_dep = NoiseModel()\n",
    "\n",
    "# Define a 1% depolarizing error for single-qubit and two-qubit gates\n",
    "depolarizing_error_1q = depolarizing_error(0.05, 1)  # 5% depolarizing error for single-qubit gates\n",
    "depolarizing_error_2q = depolarizing_error(0.05, 2)  # 5% depolarizing error for two-qubit gates\n",
    "\n",
    "# Add the 1% depolarizing noise to the single-qubit gates (rx and rz)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_1q, ['rx', 'rz'])\n",
    "\n",
    "# Add the 1% depolarizing noise to the two-qubit gate (cx)\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_2q, ['cx'])\n",
    "\n",
    "sim_dep = AerSimulator(noise_model=noise_dep)\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=1)\n",
    "qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "bootqa_programs = [\"gsdtsr\"]\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    # Total suite metrics\n",
    "    test_cases_costs = data[\"time\"].tolist()\n",
    "    test_cases_rates = data[\"rate\"].tolist()\n",
    "    \n",
    "    final_test_suite_costs = []\n",
    "    final_failure_rates = []\n",
    "    for i in range(10):\n",
    "        final_selected_cases = []\n",
    "        cluster_number = 0\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "            linear_terms = make_linear_terms_bootqa(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(linear_qubo)\n",
    "            print(\"Program: \" + str(bootqa_program) + \". It: \" + str(i))\n",
    "            print(\"QAOA Result: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            run_times_dictionary[bootqa_program].append((e-s)*1000)\n",
    "            \n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_cases = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_cases))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_cases:\n",
    "                selected_tests.append(bootqa_clusters[bootqa_program][cluster_id][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_test_suite_costs:\n",
    "                    final_selected_cases.append(selected_test)\n",
    "            \n",
    "        #compute the final test suite cost\n",
    "        final_test_suite_cost = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_test_suite_cost += test_cases_costs[selected_test_case]\n",
    "        final_test_suite_costs.append(final_test_suite_cost)\n",
    "            \n",
    "        #compute the total failure rate\n",
    "        final_failure_rate = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_failure_rate += test_cases_rates[selected_test_case]\n",
    "        final_failure_rates.append(final_failure_rate)\n",
    "    \n",
    "    print(\"Final Test Suite: \" + str(final_selected_cases))\n",
    "    #compute the qpu access times\n",
    "    qpu_run_times_without_zeros = []\n",
    "    for access_time in run_times_dictionary[bootqa_program]:\n",
    "      if access_time != 0:\n",
    "        qpu_run_times_without_zeros.append(access_time)\n",
    "    lower_bound, upper_bound = bootstrap_confidence_interval(qpu_run_times_without_zeros, 1000, 0.95)\n",
    "    for i in range(len(run_times_dictionary[bootqa_program])):\n",
    "      if run_times_dictionary[bootqa_program][i] == 0:\n",
    "          run_times_dictionary[bootqa_program][i] = upper_bound\n",
    "    average_qpu_access_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    \n",
    "    var_names = [\"final_test_suite_costs\", \"final_failure_rates\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound()\"]\n",
    "    values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "              statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "              lower_bound, upper_bound]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = \"results/selectqaoa/depolarizing_sim/05\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to save the file\n",
    "    file_path = os.path.join(output_dir, f\"{bootqa_program}.csv\")\n",
    "    \n",
    "    # Writing results to the file\n",
    "    with open(file_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "    print(f\"Results saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
