{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics\n",
    "import csv\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "from qiskit.primitives import BackendSampler\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_ibm_runtime.fake_provider import FakeVigoV2\n",
    "from qiskit_optimization.converters import QuadraticProgramToQubo\n",
    "from qiskit.circuit.library import QAOAAnsatz\n",
    "\n",
    "from mitiq import zne\n",
    "from mitiq.zne.inference import RichardsonFactory\n",
    "from mitiq.zne.scaling import fold_global\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from collections import defaultdict"
   ],
   "id": "fdabd2c01c2fb1f1"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bootqa_programs = [\"gsdtsr\",\"paintcontrol\", \"iofrol\", \"elevator\", \"elevator2\"]\n",
    "bootqa_programs_rep_values = {\"gsdtsr\":1,\"paintcontrol\":1,\"iofrol\":2, \"elevator\":4, \"elevator2\":4}\n",
    "experiments = 10"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_data(data_name):\n",
    "    \"\"\"Read the datasets\"\"\"\n",
    "    if data_name == \"elevator\":\n",
    "        data = pd.read_csv(\"datasets/quantum_sota_datasets/elevator.csv\", dtype={\"cost\": int, \"input_div\": float})\n",
    "    elif data_name == \"elevator2\":\n",
    "        data = pd.read_csv(\"datasets/quantum_sota_datasets/elevator.csv\", dtype={\"cost\": int, \"pcount\": int, \"dist\": int})\n",
    "    else:\n",
    "        data = pd.read_csv(\"datasets/quantum_sota_datasets/\" + data_name + \".csv\", dtype={\"time\": float, \"rate\": float})\n",
    "        data = data[data['rate'] > 0]\n",
    "    return data"
   ],
   "id": "f3eb992a73c5acd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bootqa_clusters = dict()\n",
    "\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    \n",
    "    # Total suite metrics\n",
    "    if bootqa_program == \"elevator\" or bootqa_program == \"elevator2\":\n",
    "        test_cases_costs = data[\"cost\"].tolist()\n",
    "    else:\n",
    "        test_cases_costs = data[\"time\"].tolist()\n",
    "    \n",
    "    if bootqa_program == \"elevator\":\n",
    "        test_cases_effectiveness = data[\"input_div\"].tolist()\n",
    "        print(f\"Tot suite cost: {sum(test_cases_costs)}\")\n",
    "        print(f\"Tot suite input div: {sum(test_cases_effectiveness)}\")\n",
    "    elif bootqa_program == \"elevator2\":\n",
    "        test_cases_pcount = data[\"pcount\"].tolist()\n",
    "        test_cases_dist = data[\"dist\"].tolist()\n",
    "        print(f\"Tot suite cost: {sum(test_cases_costs)}\")\n",
    "        print(f\"Tot suite pcount: {sum(test_cases_pcount)}\")\n",
    "        print(f\"Tot suite dist: {sum(test_cases_dist)}\")\n",
    "    else:\n",
    "        test_cases_effectiveness = data[\"rate\"].tolist()\n",
    "        print(f\"Tot suite cost: {sum(test_cases_costs)}\")\n",
    "        print(f\"Tot suite rate: {sum(test_cases_effectiveness)}\")\n",
    "        \n",
    "    # Normalize data\n",
    "    if bootqa_program != \"elevator2\":\n",
    "        cluster_data = np.column_stack((test_cases_costs, test_cases_effectiveness))\n",
    "    else:\n",
    "        cluster_data = np.column_stack((test_cases_costs, test_cases_pcount, test_cases_dist))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(cluster_data)\n",
    "    \n",
    "    if bootqa_program == \"elevator\" or bootqa_program == \"elevator2\":\n",
    "        num_clusters = 389\n",
    "    if bootqa_program == \"gsdtsr\":\n",
    "        num_clusters = 58\n",
    "    if bootqa_program == \"iofrol\":\n",
    "        num_clusters = 389\n",
    "    if bootqa_program == \"paintcontrol\":\n",
    "        num_clusters = 20\n",
    "        \n",
    "    max_cluster_dim = 5\n",
    "    \n",
    "    # Step 2: Perform K-Means Clustering\n",
    "    start = time.time()\n",
    "    linkage_matrix = linkage(normalized_data, method='ward')\n",
    "    clusters = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "    \n",
    "    # Organize test cases by cluster\n",
    "    clustered_data = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        clustered_data[cluster_id].append(idx)\n",
    "    \n",
    "    # Process clusters to ensure none exceed max_cluster_dim\n",
    "    new_cluster_id = max(clustered_data.keys()) + 1  # Start new IDs after existing ones\n",
    "    to_add = []  # Collect new smaller clusters\n",
    "    \n",
    "    for cluster_id, elements in list(clustered_data.items()):  # Avoid modifying dict during iteration\n",
    "        if len(elements) > max_cluster_dim:\n",
    "            num_splits = -(-len(elements) // max_cluster_dim)  # Ceiling division to get the required number of splits\n",
    "            split_size = -(-len(elements) // num_splits)  # Recalculate to distribute elements evenly\n",
    "            \n",
    "            # Split while keeping sizes balanced\n",
    "            parts = [elements[i:i + split_size] for i in range(0, len(elements), split_size)]\n",
    "    \n",
    "            # Ensure all new clusters are within max_cluster_dim\n",
    "            for part in parts:\n",
    "                if len(part) > max_cluster_dim:\n",
    "                    raise ValueError(f\"A split cluster still exceeds max_cluster_dim ({len(part)} > {max_cluster_dim})!\")\n",
    "    \n",
    "            # Add new parts to the new clusters\n",
    "            to_add.extend(parts)\n",
    "    \n",
    "            # Remove original large cluster\n",
    "            del clustered_data[cluster_id]\n",
    "    \n",
    "    # Assign new IDs to split parts\n",
    "    for part in to_add:\n",
    "        if part:  # Only add if the part is non-empty\n",
    "            clustered_data[new_cluster_id] = part\n",
    "            new_cluster_id += 1\n",
    "    end = time.time()\n",
    "    print(\"SelectQAOA Decomposition Time(ms): \" + str((end-start)*1000))\n",
    "    \n",
    "    bootqa_clusters[bootqa_program] = clustered_data\n",
    "    \n",
    "    # Step 3: Calculate the metrics for each refined cluster\n",
    "    cluster_metrics = {}\n",
    "    for cluster_id, members in clustered_data.items():\n",
    "        tot_cluster_costs = sum(test_cases_costs[i] for i in members)\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            tot_cluster_effectiveness = sum(test_cases_effectiveness[i] for i in members)\n",
    "        else:\n",
    "            tot_cluster_pcount = sum(test_cases_pcount[i] for i in members)\n",
    "            tot_cluster_dist = sum(test_cases_dist[i] for i in members)\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            cluster_metrics[cluster_id] = {\n",
    "                \"tot_cluster_cost\": tot_cluster_costs,\n",
    "                \"tot_cluster_rates\": tot_cluster_effectiveness\n",
    "            }\n",
    "        else:\n",
    "            cluster_metrics[cluster_id] = {\n",
    "                \"tot_cluster_cost\": tot_cluster_costs,\n",
    "                \"tot_cluster_pcount\": tot_cluster_pcount,\n",
    "                \"tot_cluster_dist\": tot_cluster_dist\n",
    "            }\n",
    "        print(f\"Cluster {cluster_id + 1} metrics:\")\n",
    "        print(f\"Test Cases: {members}\")\n",
    "        print(f\" - Num. Test Cases: {len(members):.2f}\")\n",
    "        print(f\" - Execution Cost: {tot_cluster_costs:.2f}\")\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            print(f\" - Failure Rate: {tot_cluster_effectiveness}\")\n",
    "        else:\n",
    "            print(f\" - PCount: {tot_cluster_pcount}\")\n",
    "            print(f\" - Dist: {tot_cluster_dist}\")\n",
    "    \n",
    "    print(\"===========================================================================\")    \n",
    "    \n",
    "    for cluster_id in clustered_data.keys():\n",
    "        if len(clustered_data[cluster_id]) > max_cluster_dim:\n",
    "            print(\"Program: \" + bootqa_program)\n",
    "            print(\"Test cases of cluster \" + str(cluster_id) + \": \" + str(len(clustered_data[cluster_id])))\n",
    "    \n",
    "    # Plotting the clusters in 3D space\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    if bootqa_program != \"elevator2\":\n",
    "        ax = fig.add_subplot(111)\n",
    "    else:\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Extracting data for plotting\n",
    "    exec_costs = np.array(test_cases_costs)\n",
    "    if bootqa_program != \"elevator2\":\n",
    "        effectiveness = np.array(test_cases_effectiveness)\n",
    "    else:\n",
    "        pcounts = np.array(test_cases_pcount)\n",
    "        dists = np.array(test_cases_dist)\n",
    "    \n",
    "    # Plot each refined cluster with a different color\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(clustered_data))  # A colormap with as many colors as clusters\n",
    "    for cluster_id, members in clustered_data.items():\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            ax.scatter(\n",
    "                exec_costs[members], \n",
    "                effectiveness[members], \n",
    "                color=colors(cluster_id % 10), \n",
    "                label=f\"Cluster {cluster_id + 1}\"\n",
    "            )\n",
    "        else:\n",
    "            ax.scatter(\n",
    "                exec_costs[members], \n",
    "                pcounts[members], \n",
    "                dists[members],\n",
    "                color=colors(cluster_id % 10), \n",
    "                label=f\"Cluster {cluster_id + 1}\"\n",
    "            )\n",
    "    \n",
    "    # Label the axes\n",
    "    ax.set_xlabel(\"Execution Cost\")\n",
    "    if bootqa_program != \"elevator2\":\n",
    "        ax.set_ylabel(\"Effectiveness\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Passengers Count\")\n",
    "        ax.set_zlabel(\"Travel Distance\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Test Case Clustering Visualization for: \" + bootqa_program)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ],
   "id": "63dc8c177f1d0f53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def make_linear_terms_bootqa(cluster_test_cases, test_cases_costs, test_cases_rates, alpha):\n",
    "    \"\"\"Making the linear terms of the QUBO\"\"\"\n",
    "    max_cost = max(test_cases_costs)\n",
    "    \n",
    "    estimated_costs = []\n",
    "\n",
    "    #linear coefficients, that are the diagonal of the matrix encoding the QUBO\n",
    "    for test_case in cluster_test_cases:\n",
    "        estimated_costs.append((alpha * ((test_cases_costs[test_case])/max_cost)) - ((1-alpha)*test_cases_rates[test_case]))\n",
    "    \n",
    "    return np.array(estimated_costs)\n",
    "\n",
    "def make_linear_terms_bootqa2(cluster_test_cases, test_cases_costs, pcount, dist, alpha):\n",
    "    \"\"\"Making the linear terms of the QUBO for the elevator2 problem\"\"\"\n",
    "    max_cost = max(test_cases_costs)\n",
    "    max_pcount = max(pcount)\n",
    "    max_dist = max(dist)\n",
    "    \n",
    "    estimated_costs = []\n",
    "\n",
    "    #linear coefficients, that are the diagonal of the matrix encoding the QUBO\n",
    "    for test_case in cluster_test_cases:\n",
    "        estimated_costs.append(((alpha/3) * ((test_cases_costs[test_case])/max_cost)) - ((alpha/3) * ((pcount[test_case])/max_pcount)) - ((alpha/3) * ((dist[test_case])/max_dist)))\n",
    "    \n",
    "    return np.array(estimated_costs)"
   ],
   "id": "e17728fa2785483f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_linear_qubo(linear_terms):\n",
    "    \"\"\"This function is the one that has to encode the QUBO problem that QAOA will have to solve. The QUBO problem specifies the optimization to solve and a quadratic binary unconstrained problem\"\"\"\n",
    "    qubo = QuadraticProgram()\n",
    "    \n",
    "    for i in range(0,len(linear_terms)):\n",
    "        qubo.binary_var('x%s' % (i))\n",
    "\n",
    "    qubo.minimize(linear=linear_terms)\n",
    "\n",
    "    return qubo"
   ],
   "id": "79d4c36abd4eec27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def bootstrap_confidence_interval(data, num_samples, confidence_alpha=0.95):\n",
    "    \"\"\"This function determines the statistical range within we would expect the mean value of execution times to fall; it relies on the bootstrapping strategy, which allows the calculation of the confidence interval by repeated sampling (with replacement) from the existing data to obtain an estimate of the confidence interval.\"\"\"\n",
    "    sample_means = []\n",
    "    for _ in range(num_samples):\n",
    "        bootstrap_sample = [random.choice(data) for _ in range(len(data))]\n",
    "        sample_mean = np.mean(bootstrap_sample)\n",
    "        sample_means.append(sample_mean)\n",
    "    \n",
    "    lower_percentile = (1 - confidence_alpha) / 2 * 100\n",
    "    upper_percentile = (confidence_alpha + (1 - confidence_alpha) / 2) * 100\n",
    "    lower_bound = np.percentile(sample_means, lower_percentile)\n",
    "    upper_bound = np.percentile(sample_means, upper_percentile)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ],
   "id": "9454ae295da8cf76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bootqa_alphas = {\"gsdtsr\": 0.05,\"paintcontrol\": 0.55, \"iofrol\": 0.50, \"elevator\": 0.20, \"elevator2\": 5}",
   "id": "c7282ad6fdcf7679"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def expectation_from_distribution(distribution, operator):\n",
    "    \"\"\"Calcola ⟨H⟩ da distribuzione e SparsePauliOp (solo Z/I).\"\"\"\n",
    "    expectation = 0.0\n",
    "    for pauli, coeff in zip(operator.paulis, operator.coeffs):\n",
    "        pauli_str = pauli.to_label()\n",
    "        if any(p in pauli_str for p in \"XY\"):  # ignora se contiene X o Y\n",
    "            continue\n",
    "        for bitstring, prob in distribution.items():\n",
    "            if len(pauli_str) < len(bitstring):\n",
    "                pauli_str = pauli_str.rjust(len(bitstring), \"I\")\n",
    "            parity = 1\n",
    "            for i in range(len(bitstring)):\n",
    "                p = pauli_str[-(i + 1)]  # allineato da destra (qubit 0 a dx)\n",
    "                if p == 'Z':\n",
    "                    parity *= 1 if bitstring[-(i + 1)] == '0' else -1\n",
    "            expectation += coeff.real * prob * parity\n",
    "    return expectation.real\n",
    "\n",
    "device_backend = FakeVigoV2()\n",
    "\n",
    "# Config\n",
    "run_times_dictionary = {k: [] for k in bootqa_alphas}\n",
    "algorithm_globals.random_seed = 10598\n",
    "\n",
    "scale_factors = [1.0, 3.0, 5.0]\n",
    "factory = RichardsonFactory(scale_factors=scale_factors)\n",
    "\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    test_cases_costs = data[\"time\"].tolist() if bootqa_program not in [\"elevator\", \"elevator2\"] else data[\"cost\"].tolist()\n",
    "    if bootqa_program == \"elevator\":\n",
    "        test_cases_rates = data[\"input_div\"].tolist()\n",
    "    elif bootqa_program != \"elevator2\":\n",
    "        test_cases_rates = data[\"rate\"].tolist()\n",
    "    else:\n",
    "        test_cases_pcount = data[\"pcount\"].tolist()\n",
    "        test_cases_dist = data[\"dist\"].tolist()\n",
    "\n",
    "    final_test_suite_costs = []\n",
    "    final_effectivenesses = []\n",
    "    final_pcounts = []\n",
    "    final_dists = []\n",
    "\n",
    "    for i in range(experiments):\n",
    "        final_selected_cases = []\n",
    "\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            cluster = bootqa_clusters[bootqa_program][cluster_id]\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "\n",
    "            # QUBO creation\n",
    "            if bootqa_program != \"elevator2\":\n",
    "                linear_terms = make_linear_terms_bootqa(cluster, test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            else:\n",
    "                linear_terms = make_linear_terms_bootqa2(cluster, test_cases_costs, test_cases_pcount, test_cases_dist, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "\n",
    "            # QAOA to build the circuit needs an Ising Hamiltonian as input\n",
    "            # Since the problem is a QuadraticProgram object, we must convert it into an Ising\n",
    "            qp2qubo = QuadraticProgramToQubo()\n",
    "            qubo_problem = qp2qubo.convert(linear_qubo)\n",
    "            hamiltonian, _ = qubo_problem.to_ising()\n",
    "            backend = FakeVigoV2()\n",
    "\n",
    "            # QAOAAnsatz builds a circuit with defined repetitions \n",
    "            reps = bootqa_programs_rep_values[bootqa_program]\n",
    "            ansatz = QAOAAnsatz(hamiltonian, reps=reps)\n",
    "\n",
    "            # Returns the 0 noise expected value of H with given params\n",
    "            def zne_expectation(params):\n",
    "                # Assigns params to γ and β (2*reps params)\n",
    "                circuit = ansatz.assign_parameters(params)\n",
    "                circuit.measure_all() # the circuit will produce a result in terms of bitstrings\n",
    "            \n",
    "                # Running the circuit on FakeVigo, getting the expected value for Hamiltonian \n",
    "                def run_expectation(circ):\n",
    "                    sampler = BackendSampler(backend=device_backend)\n",
    "                    result = sampler.run(circ).result()\n",
    "                    dist = result.quasi_dists[0].binary_probabilities()\n",
    "                    return expectation_from_distribution(dist, hamiltonian)\n",
    "            \n",
    "                # Running the the circuit at different noise levels, to extrapolate 0 noise H exp value\n",
    "                factory = RichardsonFactory(scale_factors=[1.0, 3.0, 5.0])\n",
    "                return zne.execute_with_zne(circuit, run_expectation, scale_noise=fold_global, factory=factory)\n",
    "            \n",
    "            # Initialize params\n",
    "            initial_params = np.array([0.5] * ansatz.num_parameters)\n",
    "            # Tries different params, calling for any trial zne_expectation, updates params based on H expected value retuned any time, until it converges\n",
    "            result = minimize(zne_expectation, initial_params, method=\"COBYLA\")\n",
    "            \n",
    "            # Get the optimal params\n",
    "            optimal_params = result.x\n",
    "                \n",
    "            # Build the final circuit with the optimal params\n",
    "            final_circuit = ansatz.assign_parameters(optimal_params)\n",
    "            final_circuit.measure_all()\n",
    "            \n",
    "            # Execute the final circuite to get the final result\n",
    "            sampler = BackendSampler(backend=device_backend)\n",
    "            start = time.time()\n",
    "            final_result = sampler.run(final_circuit).result()\n",
    "            end = time.time()\n",
    "            counts = final_result.quasi_dists[0].binary_probabilities()\n",
    "            best_bitstring = max(counts.items(), key=lambda x: x[1])[0]\n",
    "            \n",
    "            # Ora puoi estrarre gli indici dei test selezionati\n",
    "            selected_tests = [cluster[i] for i, b in enumerate(best_bitstring[::-1]) if b == \"1\"]\n",
    "            print(f\"[{bootqa_program}] Iter {i} - Best bitstring: {best_bitstring} -> {selected_tests}\")\n",
    "\n",
    "            for test in selected_tests:\n",
    "                if test not in final_selected_cases:\n",
    "                    final_selected_cases.append(test)\n",
    "\n",
    "            run_times_dictionary[bootqa_program].append((end-start)*1000)\n",
    "\n",
    "        cost = sum(test_cases_costs[t] for t in final_selected_cases)\n",
    "        final_test_suite_costs.append(cost)\n",
    "\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            effectiveness = sum(test_cases_rates[t] for t in final_selected_cases)\n",
    "            final_effectivenesses.append(effectiveness)\n",
    "        else:\n",
    "            pcount = sum(test_cases_pcount[t] for t in final_selected_cases)\n",
    "            dist = sum(test_cases_dist[t] for t in final_selected_cases)\n",
    "            final_pcounts.append(pcount)\n",
    "            final_dists.append(dist)\n",
    "\n",
    "    avg_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    std_time = statistics.stdev(run_times_dictionary[bootqa_program]) \n",
    "\n",
    "    # Export results\n",
    "    if bootqa_program == \"elevator2\":\n",
    "        var_names = [\"final_test_suite_costs\", \"final_pcounts\", \"final_dists\",\n",
    "                     \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\",\n",
    "                     \"qpu_run_times(ms)\"]\n",
    "        values = [final_test_suite_costs, final_pcounts, final_dists, avg_time,\n",
    "                  std_time, run_times_dictionary[bootqa_program]]\n",
    "    else:\n",
    "        var_names = [\"final_test_suite_costs\", \"final_effectivenesses\",\n",
    "                     \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\",\n",
    "                     \"qpu_run_times(ms)\"]\n",
    "        values = [final_test_suite_costs, final_effectivenesses, avg_time,\n",
    "                  std_time, run_times_dictionary[bootqa_program]]\n",
    "\n",
    "    os.makedirs(\"results/selectqaoa/fake_vigo_zne\", exist_ok=True)\n",
    "    file_path = f\"results/selectqaoa/fake_vigo_zne/{bootqa_program}-effectiveness-focus.csv\"\n",
    "    with open(file_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "\n",
    "    print(f\"Results saved to {file_path}\")\n"
   ],
   "id": "a55823f2ca3cd95b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
