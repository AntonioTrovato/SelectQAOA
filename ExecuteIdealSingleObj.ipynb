{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T17:15:47.939542Z",
     "start_time": "2025-03-11T17:15:46.947174Z"
    }
   },
   "source": [
    "#this cell contains all the imports needed by the pipeline\n",
    "#to run it on the browser: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics\n",
    "import csv\n",
    "\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.primitives import BackendSampler\n",
    "from qiskit_algorithms import QAOA\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "from qiskit_aer import AerSimulator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T17:15:47.944516Z",
     "start_time": "2025-03-11T17:15:47.942732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bootqa_programs = [\"gsdtsr\",\"paintcontrol\", \"iofrol\", \"elevator\", \"elevator2\"]\n",
    "bootqa_programs_rep_values = {\"gsdtsr\":1,\"paintcontrol\":1,\"iofrol\":1, \"elevator\":1, \"elevator2\":1}\n",
    "experiments = 10"
   ],
   "id": "5694d6e780374c2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T17:15:47.976918Z",
     "start_time": "2025-03-11T17:15:47.974438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bootstrap_confidence_interval(data, num_samples, confidence_alpha=0.95):\n",
    "    \"\"\"This function determines the statistical range within we would expect the mean value of execution times to fall; it relies on the bootstrapping strategy, which allows the calculation of the confidence interval by repeated sampling (with replacement) from the existing data to obtain an estimate of the confidence interval.\"\"\"\n",
    "    sample_means = []\n",
    "    for _ in range(num_samples):\n",
    "        bootstrap_sample = [random.choice(data) for _ in range(len(data))]\n",
    "        sample_mean = np.mean(bootstrap_sample)\n",
    "        sample_means.append(sample_mean)\n",
    "    \n",
    "    lower_percentile = (1 - confidence_alpha) / 2 * 100\n",
    "    upper_percentile = (confidence_alpha + (1 - confidence_alpha) / 2) * 100\n",
    "    lower_bound = np.percentile(sample_means, lower_percentile)\n",
    "    upper_bound = np.percentile(sample_means, upper_percentile)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ],
   "id": "bfe680181698590b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T17:15:47.984306Z",
     "start_time": "2025-03-11T17:15:47.981315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_linear_terms_bootqa(cluster_test_cases, test_cases_costs, test_cases_rates, alpha):\n",
    "    \"\"\"Making the linear terms of the QUBO\"\"\"\n",
    "    max_cost = max(test_cases_costs)\n",
    "    \n",
    "    estimated_costs = []\n",
    "\n",
    "    #linear coefficients, that are the diagonal of the matrix encoding the QUBO\n",
    "    for test_case in cluster_test_cases:\n",
    "        estimated_costs.append((alpha * ((test_cases_costs[test_case])/max_cost)) - ((1-alpha)*test_cases_rates[test_case]))\n",
    "    \n",
    "    return np.array(estimated_costs)\n",
    "\n",
    "def make_linear_terms_bootqa2(cluster_test_cases, test_cases_costs, test_cases_pcounts, test_cases_dists, alpha):\n",
    "    \"\"\"Making the linear terms of the QUBO\"\"\"\n",
    "    max_cost = max(test_cases_costs)\n",
    "    max_pcount = max(test_cases_pcounts)\n",
    "    max_dist = max(test_cases_dists)\n",
    "    \n",
    "    estimated_costs = []\n",
    "\n",
    "    #linear coefficients, that are the diagonal of the matrix encoding the QUBO\n",
    "    for test_case in cluster_test_cases:\n",
    "        estimated_costs.append(((alpha/3) * ((test_cases_costs[test_case])/max_cost)) - ((alpha/3) * ((test_cases_pcounts[test_case])/max_pcount)) - ((alpha/3) * ((test_cases_dists[test_case])/max_dist)))\n",
    "    \n",
    "    return np.array(estimated_costs)"
   ],
   "id": "f061150b06c1f1bc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T17:15:47.991062Z",
     "start_time": "2025-03-11T17:15:47.988525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_linear_qubo(linear_terms):\n",
    "    \"\"\"This function is the one that has to encode the QUBO problem that QAOA will have to solve. The QUBO problem specifies the optimization to solve and a quadratic binary unconstrained problem\"\"\"\n",
    "    qubo = QuadraticProgram()\n",
    "    \n",
    "    for i in range(0,len(linear_terms)):\n",
    "        qubo.binary_var('x%s' % (i))\n",
    "\n",
    "    qubo.minimize(linear=linear_terms)\n",
    "\n",
    "    return qubo"
   ],
   "id": "c9c4256a026c9949",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_data(data_name):\n",
    "    \"\"\"Read the datasets\"\"\"\n",
    "    if data_name == \"elevator\":\n",
    "        data = pd.read_csv(\"datasets/quantum_sota_datasets/elevator.csv\", dtype={\"cost\": int, \"input_div\": float})\n",
    "    elif data_name == \"elevator2\":\n",
    "        data = pd.read_csv(\"datasets/quantum_sota_datasets/elevator.csv\", dtype={\"cost\": int, \"pcount\": int, \"dist\": int})\n",
    "    else:\n",
    "        data = pd.read_csv(\"datasets/quantum_sota_datasets/\" + data_name + \".csv\", dtype={\"time\": float, \"rate\": float})\n",
    "        data = data[data['rate'] > 0]\n",
    "    return data\n",
    "\n",
    "bootqa_clusters = dict()\n",
    "\n",
    "for bootqa_program in bootqa_programs:\n",
    "    data = get_data(bootqa_program)\n",
    "    \n",
    "    # Total suite metrics\n",
    "    if bootqa_program == \"elevator\" or bootqa_program == \"elevator2\":\n",
    "        test_cases_costs = data[\"cost\"].tolist()\n",
    "    else:\n",
    "        test_cases_costs = data[\"time\"].tolist()\n",
    "    if bootqa_program == \"elevator\":\n",
    "        test_cases_rates = data[\"input_div\"].tolist()\n",
    "        print(f\"Tot suite cost: {sum(test_cases_costs)}\")\n",
    "        print(f\"Tot suite input div: {sum(test_cases_rates)}\")\n",
    "    elif bootqa_program == \"elevator2\":\n",
    "        test_cases_pcount = data[\"pcount\"].tolist()\n",
    "        test_cases_dist = data[\"dist\"].tolist()\n",
    "        print(f\"Tot suite cost: {sum(test_cases_costs)}\")\n",
    "        print(f\"Tot suite pcount: {sum(test_cases_pcount)}\")\n",
    "        print(f\"Tot suite dist: {sum(test_cases_dist)}\")\n",
    "    else:\n",
    "        test_cases_rates = data[\"rate\"].tolist()\n",
    "        print(f\"Tot suite cost: {sum(test_cases_costs)}\")\n",
    "        print(f\"Tot suite rate: {sum(test_cases_rates)}\")\n",
    "        \n",
    "    # Normalize data\n",
    "    if bootqa_program != \"elevator2\":\n",
    "        cluster_data = np.column_stack((test_cases_costs, test_cases_rates))\n",
    "    else:\n",
    "        cluster_data = np.column_stack((test_cases_costs, test_cases_pcount, test_cases_dist))\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(cluster_data)\n",
    "    \n",
    "    num_clusters = 50\n",
    "        \n",
    "    max_cluster_dim = 10\n",
    "    \n",
    "    start = time.time()\n",
    "    linkage_matrix = linkage(normalized_data, method='ward')\n",
    "    clusters = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "    \n",
    "    # Organize test cases by cluster\n",
    "    clustered_data = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        clustered_data[cluster_id].append(idx)\n",
    "    \n",
    "    # Process clusters to ensure none exceed max_cluster_dim\n",
    "    new_cluster_id = max(clustered_data.keys()) + 1  # Start new IDs after existing ones\n",
    "    to_add = []  # Collect new smaller clusters\n",
    "    \n",
    "    for cluster_id, elements in list(clustered_data.items()):  # Avoid modifying dict during iteration\n",
    "        if len(elements) > max_cluster_dim:\n",
    "            num_splits = -(-len(elements) // max_cluster_dim)  # Ceiling division to get the required number of splits\n",
    "            split_size = -(-len(elements) // num_splits)  # Recalculate to distribute elements evenly\n",
    "            \n",
    "            # Split while keeping sizes balanced\n",
    "            parts = [elements[i:i + split_size] for i in range(0, len(elements), split_size)]\n",
    "    \n",
    "            # Ensure all new clusters are within max_cluster_dim\n",
    "            for part in parts:\n",
    "                if len(part) > max_cluster_dim:\n",
    "                    raise ValueError(f\"A split cluster still exceeds max_cluster_dim ({len(part)} > {max_cluster_dim})!\")\n",
    "    \n",
    "            # Add new parts to the new clusters\n",
    "            to_add.extend(parts)\n",
    "    \n",
    "            # Remove original large cluster\n",
    "            del clustered_data[cluster_id]\n",
    "    \n",
    "    # Assign new IDs to split parts\n",
    "    for part in to_add:\n",
    "        if part:  # Only add if the part is non-empty\n",
    "            clustered_data[new_cluster_id] = part\n",
    "            new_cluster_id += 1\n",
    "    end = time.time()\n",
    "    print(\"SelectQAOA Decomposition Time(ms): \" + str((end-start)*1000))\n",
    "    \n",
    "    bootqa_clusters[bootqa_program] = clustered_data\n",
    "    \n",
    "    # Step 3: Calculate the metrics for each refined cluster\n",
    "    cluster_metrics = {}\n",
    "    for cluster_id, members in clustered_data.items():\n",
    "        tot_cluster_costs = sum(test_cases_costs[i] for i in members)\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            tot_cluster_rates = sum(test_cases_rates[i] for i in members)\n",
    "        else:\n",
    "            tot_cluster_pcount = sum(test_cases_pcount[i] for i in members)\n",
    "            tot_cluster_dist = sum(test_cases_dist[i] for i in members)\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            cluster_metrics[cluster_id] = {\n",
    "                \"tot_cluster_cost\": tot_cluster_costs,\n",
    "                \"tot_cluster_rates\": tot_cluster_rates\n",
    "            }\n",
    "        else:\n",
    "            cluster_metrics[cluster_id] = {\n",
    "                \"tot_cluster_cost\": tot_cluster_costs,\n",
    "                \"tot_cluster_pcount\": tot_cluster_pcount,\n",
    "                \"tot_cluster_dist\": tot_cluster_dist\n",
    "            }\n",
    "        print(f\"Cluster {cluster_id + 1} metrics:\")\n",
    "        print(f\"Test Cases: {members}\")\n",
    "        print(f\" - Num. Test Cases: {len(members):.2f}\")\n",
    "        print(f\" - Execution Cost: {tot_cluster_costs:.2f}\")\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            print(f\" - Failure Rate: {tot_cluster_rates}\")\n",
    "        else:\n",
    "            print(f\" - PCount: {tot_cluster_pcount}\")\n",
    "            print(f\" - Dist: {tot_cluster_dist}\")\n",
    "    \n",
    "    print(\"===========================================================================\")    \n",
    "    \n",
    "    for cluster_id in clustered_data.keys():\n",
    "        if len(clustered_data[cluster_id]) > max_cluster_dim:\n",
    "            print(\"Program: \" + bootqa_program)\n",
    "            print(\"Test cases of cluster \" + str(cluster_id) + \": \" + str(len(clustered_data[cluster_id])))\n",
    "    \n",
    "    # Plotting the clusters in 3D space\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Extracting data for plotting\n",
    "    exec_costs = np.array(test_cases_costs)\n",
    "    if bootqa_program != \"elevator2\":\n",
    "        rates = np.array(test_cases_rates)\n",
    "    else:\n",
    "        pcounts = np.array(test_cases_pcount)\n",
    "        dists = np.array(test_cases_dist)\n",
    "    \n",
    "    # Plot each refined cluster with a different color\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(clustered_data))  # A colormap with as many colors as clusters\n",
    "    for cluster_id, members in clustered_data.items():\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            ax.scatter(\n",
    "                exec_costs[members], \n",
    "                rates[members], \n",
    "                color=colors(cluster_id % 10), \n",
    "                label=f\"Cluster {cluster_id + 1}\"\n",
    "            )\n",
    "        else:\n",
    "            ax.scatter(\n",
    "                exec_costs[members], \n",
    "                pcounts[members], \n",
    "                dists[members],\n",
    "                color=colors(cluster_id % 10), \n",
    "                label=f\"Cluster {cluster_id + 1}\"\n",
    "            )\n",
    "    \n",
    "    # Label the axes\n",
    "    ax.set_xlabel(\"Execution Cost\")\n",
    "    ax.set_ylabel(\"Failure Rate\")\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Test Case Clustering Visualization\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ],
   "id": "b967832657e68c47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-11T17:15:52.248011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bootqa_alphas = {\"gsdtsr\": 0.2,\"paintcontrol\": 0.80, \"iofrol\": 0.82, \"elevator\": 0.50, \"elevator2\": 2.9}\n",
    "run_times_dictionary = {\"gsdtsr\": [],\"paintcontrol\": [], \"iofrol\": [], \"elevator\": [], \"elevator2\": []}\n",
    "\n",
    "noise_dep = NoiseModel()\n",
    "\n",
    "# Define a 5% depolarizing error for single-qubit and two-qubit gates\n",
    "depolarizing_error_1q = depolarizing_error(0.05, 1)  # 5% depolarizing error for single-qubit gates\n",
    "depolarizing_error_2q = depolarizing_error(0.05, 2)  # 5% depolarizing error for two-qubit gates\n",
    "\n",
    "# Apply depolarizing noise to single-qubit gates\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_1q, ['rx', 'rz', 'sx', 'x', 'h'])\n",
    "\n",
    "# Apply depolarizing noise to two-qubit gates\n",
    "noise_dep.add_all_qubit_quantum_error(depolarizing_error_2q, ['cx', 'cz', 'swap'])\n",
    "\n",
    "sim_dep = AerSimulator(noise_model=noise_dep)\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "\n",
    "for bootqa_program in bootqa_programs:\n",
    "    qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=bootqa_programs_rep_values[bootqa_program])\n",
    "    qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "    data = get_data(bootqa_program)\n",
    "    # Total suite metrics\n",
    "    if bootqa_program != \"elevator2\" and bootqa_program != \"elevator\":\n",
    "        test_cases_costs = data[\"time\"].tolist()\n",
    "    else:\n",
    "        test_cases_costs = data[\"cost\"].tolist()\n",
    "    test_cases_rates = None\n",
    "    test_cases_pcount = None\n",
    "    test_cases_dist = None\n",
    "    if bootqa_program != \"elevator2\":\n",
    "        test_cases_rates = data[\"input_div\"].tolist() if bootqa_program == \"elevator\" else data[\"rate\"].tolist()\n",
    "    else:\n",
    "        test_cases_pcount = data[\"pcount\"].tolist()\n",
    "        test_cases_dist = data[\"dist\"].tolist()\n",
    "    \n",
    "    final_test_suite_costs = []\n",
    "    final_failure_rates = []\n",
    "    final_pcounts = []\n",
    "    final_dists = []\n",
    "    for i in range(experiments):\n",
    "        final_selected_cases = []\n",
    "        cluster_number = 0\n",
    "        for cluster_id in bootqa_clusters[bootqa_program]:\n",
    "            print(\"Cluster: \" + str(bootqa_clusters[bootqa_program][cluster_id]))\n",
    "            linear_terms = None\n",
    "            if bootqa_program != \"elevator2\":\n",
    "                linear_terms = make_linear_terms_bootqa(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs, test_cases_rates, bootqa_alphas[bootqa_program])\n",
    "            else:\n",
    "                linear_terms = make_linear_terms_bootqa2(bootqa_clusters[bootqa_program][cluster_id], test_cases_costs,test_cases_pcount, test_cases_dist, bootqa_alphas[bootqa_program])\n",
    "            linear_qubo = create_linear_qubo(linear_terms)\n",
    "            print(\"Linear QUBO: \" + str(linear_qubo))\n",
    "            #for each iteration get the result\n",
    "            s = time.time()\n",
    "            qaoa_result = qaoa.solve(linear_qubo)\n",
    "            print(\"Program: \" + str(bootqa_program) + \". It: \" + str(i))\n",
    "            print(\"QAOA Result: \" + str(qaoa_result))\n",
    "            e = time.time()\n",
    "            run_times_dictionary[bootqa_program].append((e-s)*1000)\n",
    "            \n",
    "            variable_values = qaoa_result.x\n",
    "            indexes_selected_cases = [index for index, value in enumerate(variable_values) if value == 1]\n",
    "            print(\"Indexes of selected tests to convert. \" + str(indexes_selected_cases))\n",
    "            selected_tests = []\n",
    "            for index in indexes_selected_cases:\n",
    "                selected_tests.append(bootqa_clusters[bootqa_program][cluster_id][index])\n",
    "            print(\"Selected tests: \" + str(selected_tests))\n",
    "            for selected_test in selected_tests:\n",
    "                if selected_test not in final_test_suite_costs:\n",
    "                    final_selected_cases.append(selected_test)\n",
    "            \n",
    "        #compute the final test suite cost\n",
    "        final_test_suite_cost = 0\n",
    "        for selected_test_case in final_selected_cases:\n",
    "            final_test_suite_cost += test_cases_costs[selected_test_case]\n",
    "        final_test_suite_costs.append(final_test_suite_cost)\n",
    "            \n",
    "        #compute the total failure rate\n",
    "        if bootqa_program != \"elevator2\":\n",
    "            final_failure_rate = 0\n",
    "            for selected_test_case in final_selected_cases:\n",
    "                final_failure_rate += test_cases_rates[selected_test_case]\n",
    "            final_failure_rates.append(final_failure_rate)\n",
    "        else:\n",
    "            final_pcount = 0\n",
    "            for selected_test_case in final_selected_cases:\n",
    "                final_pcount += test_cases_pcount[selected_test_case]\n",
    "            final_pcounts.append(final_pcount)\n",
    "            \n",
    "            final_dist = 0\n",
    "            for selected_test_case in final_selected_cases:\n",
    "                final_dist += test_cases_dist[selected_test_case]\n",
    "            final_dists.append(final_dist)\n",
    "    \n",
    "    print(\"Final Test Suite: \" + str(final_selected_cases))\n",
    "    #compute the qpu access times\n",
    "    qpu_run_times_without_zeros = []\n",
    "    for access_time in run_times_dictionary[bootqa_program]:\n",
    "      if access_time != 0:\n",
    "        qpu_run_times_without_zeros.append(access_time)\n",
    "    lower_bound, upper_bound = bootstrap_confidence_interval(qpu_run_times_without_zeros, 1000, 0.95)\n",
    "    for i in range(len(run_times_dictionary[bootqa_program])):\n",
    "      if run_times_dictionary[bootqa_program][i] == 0:\n",
    "          run_times_dictionary[bootqa_program][i] = upper_bound\n",
    "    average_qpu_access_time = statistics.mean(run_times_dictionary[bootqa_program]) \n",
    "    \n",
    "    if bootqa_program == \"elevator\":\n",
    "        var_names = [\"final_test_suite_costs\", \"final_input_divs\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound(ms)\", \"qpu_run_times(ms)\"]\n",
    "        values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "                  statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "                  lower_bound, upper_bound, run_times_dictionary[bootqa_program]]\n",
    "    if bootqa_program == \"elevator2\":\n",
    "        var_names = [\"final_test_suite_costs\", \"final_pcounts\", \"final_dists\",\n",
    "                 \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                 \"qpu_lower_bound(ms)\", \"qpu_upper_bound(ms)\", \"qpu_run_times(ms)\"]\n",
    "        values = [final_test_suite_costs, final_pcounts, final_dists, average_qpu_access_time, \n",
    "                  statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "                  lower_bound, upper_bound, run_times_dictionary[bootqa_program]]\n",
    "    else:\n",
    "        var_names = [\"final_test_suite_costs\", \"final_failure_rates\",\n",
    "                     \"average_qpu_access_time(ms)\", \"stdev_qpu_access_time(ms)\", \"all_qpu_access_times(ms)\",\n",
    "                     \"qpu_lower_bound(ms)\", \"qpu_upper_bound(ms)\", \"qpu_run_times(ms)\"]\n",
    "        values = [final_test_suite_costs, final_failure_rates, average_qpu_access_time, \n",
    "                  statistics.stdev(run_times_dictionary[bootqa_program]), run_times_dictionary[bootqa_program],\n",
    "                  lower_bound, upper_bound, run_times_dictionary[bootqa_program]]\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = \"results/selectqaoa/depolarizing_sim/05\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Path to save the file\n",
    "    file_path = os.path.join(output_dir, f\"{bootqa_program}.csv\")\n",
    "    \n",
    "    # Writing results to the file\n",
    "    with open(file_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(var_names)\n",
    "        writer.writerow(values)\n",
    "    print(f\"Results saved to {file_path}\")"
   ],
   "id": "2cf8590be0753819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: [6]\n",
      "Linear QUBO: minimize -0.29955299381886735*x0 (1 variables, 0 constraints, '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/kd67nwcs41113fgwjn39d7fm0000gn/T/ipykernel_2766/824647394.py:21: DeprecationWarning: The class ``qiskit.primitives.backend_sampler.BackendSampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `BackendSampler` class is `BackendSamplerV2`.\n",
      "  qaoa_mes = QAOA(sampler=BackendSampler(backend=sim_dep), optimizer=COBYLA(100), reps=bootqa_programs_rep_values[bootqa_program])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program: gsdtsr. It: 0\n",
      "QAOA Result: fval=-0.29955299381886735, x0=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0]\n",
      "Selected tests: [6]\n",
      "Cluster: [8, 104, 139, 247, 271]\n",
      "Linear QUBO: minimize -0.008515799490323302*x0 - 0.012441738325510326*x1 - 0.00890115948340612*x2 - 0.017257251338785563*x3 - 0.00774263647196537*x4 (5 variables, 0 constraints, '')\n",
      "Program: gsdtsr. It: 0\n",
      "QAOA Result: fval=-0.054858585109990685, x0=1.0, x1=1.0, x2=1.0, x3=1.0, x4=1.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. [0, 1, 2, 3, 4]\n",
      "Selected tests: [8, 104, 139, 247, 271]\n",
      "Cluster: [9, 32, 83, 127, 180]\n",
      "Linear QUBO: minimize 0.0036492422216990953*x0 + 0.006582698841021259*x1 + 0.01028352758028979*x2 + 0.010867999105857576*x3 + 0.0012733309574669265*x4 (5 variables, 0 constraints, '')\n",
      "Program: gsdtsr. It: 0\n",
      "QAOA Result: fval=0.0, x0=0.0, x1=0.0, x2=0.0, x3=0.0, x4=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "Cluster: [10, 41, 205, 206, 233]\n",
      "Linear QUBO: minimize 0.0287791405414662*x0 + 0.022951706096250826*x1 + 0.02780466235151967*x2 + 0.020924185240739072*x3 + 0.02156716310845977*x4 (5 variables, 0 constraints, '')\n",
      "Program: gsdtsr. It: 0\n",
      "QAOA Result: fval=0.0, x0=0.0, x1=0.0, x2=0.0, x3=0.0, x4=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "Cluster: [11, 34, 136, 144, 235]\n",
      "Linear QUBO: minimize 0.018241035036567294*x0 + 0.00950735894738723*x1 + 0.0072958992524229434*x2 + 0.014826166364314473*x3 + 0.009766212168488317*x4 (5 variables, 0 constraints, '')\n",
      "Program: gsdtsr. It: 0\n",
      "QAOA Result: fval=0.0, x0=0.0, x1=0.0, x2=0.0, x3=0.0, x4=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "Cluster: [13, 38, 40, 203, 265]\n",
      "Linear QUBO: minimize 0.010565405514021055*x0 + 0.004626640068408842*x1 + 0.006324233673589472*x2 + 0.010130546328520522*x3 + 0.010949688467388946*x4 (5 variables, 0 constraints, '')\n",
      "Program: gsdtsr. It: 0\n",
      "QAOA Result: fval=0.0, x0=0.0, x1=0.0, x2=0.0, x3=0.0, x4=0.0, status=SUCCESS\n",
      "Indexes of selected tests to convert. []\n",
      "Selected tests: []\n",
      "Cluster: [14, 30]\n",
      "Linear QUBO: minimize 0.01628467407725603*x0 + 0.02319539263050819*x1 (2 variables, 0 constraints, '')\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fb676475accffd36",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
